{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 376,
      "metadata": {
        "id": "pGGkE4BAep1f"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "np.set_printoptions(suppress=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# #Binary classification\n",
        "# import matplotlib.pyplot as plt\n",
        "\n",
        "# # random dataset\n",
        "\n",
        "# NUM_SAMPLES_PER_CLASS = 200\n",
        "# INNER_RADIUS = 2\n",
        "# OUTER_RADIUS = 5\n",
        "# NOISE_STD_DEV = 0.5\n",
        "\n",
        "# theta_inner = 2 * np.pi * np.random.rand(NUM_SAMPLES_PER_CLASS)\n",
        "\n",
        "# radius_inner = INNER_RADIUS * np.random.rand(NUM_SAMPLES_PER_CLASS) + np.random.normal(0, NOISE_STD_DEV, NUM_SAMPLES_PER_CLASS)\n",
        "# x0 = radius_inner * np.cos(theta_inner)\n",
        "# y0 = radius_inner * np.sin(theta_inner)\n",
        "# class0_points = np.vstack([x0, y0]).T\n",
        "# class0_labels = np.zeros(NUM_SAMPLES_PER_CLASS)\n",
        "\n",
        "# theta_outer = 2 * np.pi * np.random.rand(NUM_SAMPLES_PER_CLASS)\n",
        "\n",
        "# radius_outer = np.random.uniform(INNER_RADIUS + 1, OUTER_RADIUS, NUM_SAMPLES_PER_CLASS) + np.random.normal(0, NOISE_STD_DEV, NUM_SAMPLES_PER_CLASS)\n",
        "# x1 = radius_outer * np.cos(theta_outer)\n",
        "# y1 = radius_outer * np.sin(theta_outer)\n",
        "# class1_points = np.vstack([x1, y1]).T\n",
        "# class1_labels = np.ones(NUM_SAMPLES_PER_CLASS)\n",
        "\n",
        "\n",
        "# X = np.vstack([class0_points, class1_points])\n",
        "# y = np.hstack([class0_labels, class1_labels])\n",
        "# y = y.reshape(-1, 1) # stupid broadcasting bug that i spent an hour on -.-\n",
        "\n",
        "\n",
        "# plt.figure(figsize=(8, 6))\n",
        "\n",
        "# plt.scatter(class0_points[:, 0], class0_points[:, 1], c='blue', label='Class 0 (Inner)', alpha=0.7)\n",
        "\n",
        "# plt.scatter(class1_points[:, 0], class1_points[:, 1], c='red', label='Class 1 (Outer)', alpha=0.7)\n",
        "# plt.title('Concentric Rings Dataset')\n",
        "# plt.xlabel('Feature 1')\n",
        "# plt.ylabel('Feature 2')\n",
        "# plt.legend()\n",
        "# plt.grid(True)\n",
        "# plt.gca().set_aspect('equal', adjustable='box')\n",
        "# plt.show()"
      ],
      "metadata": {
        "id": "0Wsu6mPtfNcy"
      },
      "execution_count": 377,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Mnist dataset\n",
        "import copy\n",
        "from tensorflow.keras.datasets import mnist\n",
        "\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "\n",
        "X_train = (X_train.astype('float64') / 255.0).reshape(-1,28*28)\n",
        "X_test = (X_test.astype('float64') / 255.0).reshape(-1,28*28)\n",
        "\n",
        "X_test_copy = copy.deepcopy(X_test)\n",
        "y_test_copy = copy.deepcopy(y_test)\n",
        "\n",
        "X = X_train#[:2000,:]\n",
        "y = y_train.reshape(60000, -1)#[:2000,:]\n",
        "X_test = X_test#[:1000,:]\n",
        "y_test = y_test.reshape(-1,1)#[:1000, :]"
      ],
      "metadata": {
        "id": "_rV-2-fY5Ske"
      },
      "execution_count": 378,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X.shape, y.shape, X_test.shape, y_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Z1MPju7fNj6",
        "outputId": "0c21e6f8-1a82-4ebb-d3f6-ad077f3b902a"
      },
      "execution_count": 379,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((60000, 784), (60000, 1), (10000, 784), (10000, 1))"
            ]
          },
          "metadata": {},
          "execution_count": 379
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def one_hot_encoding(vector):\n",
        "    vector = np.array(vector).astype(int).flatten()\n",
        "    # if vector.ndim == 1:\n",
        "    #     return vector\n",
        "    size=len(vector)\n",
        "    num_classes = max(np.max(vector) + 1, 10)\n",
        "\n",
        "    encoded_matrix = np.zeros((size, num_classes))\n",
        "    encoded_matrix[np.arange(size), vector] = 1\n",
        "    return encoded_matrix"
      ],
      "metadata": {
        "id": "wsCbSo0pwQ_l"
      },
      "execution_count": 380,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_test_split(X, y, test_size=0.2):\n",
        "    num_samples = X.shape[0]\n",
        "    train_size = int(np.ceil(num_samples * (1-test_size)))\n",
        "    test_size = int(np.floor(num_samples * test_size))\n",
        "\n",
        "    shuffled_indices = np.arange(num_samples)\n",
        "    np.random.shuffle(shuffled_indices)\n",
        "    X = X[shuffled_indices]\n",
        "    y= y[shuffled_indices]\n",
        "\n",
        "    X_train = X[:train_size, :]\n",
        "    y_train = y[:train_size,]\n",
        "    X_test = X[train_size:]\n",
        "    y_test = y[train_size:]\n",
        "\n",
        "    return X_train, y_train, X_test, y_test"
      ],
      "metadata": {
        "id": "fQo6YdzuK3sk"
      },
      "execution_count": 381,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# X_train, y_train, X_test, y_test = train_test_split(X, y)"
      ],
      "metadata": {
        "id": "DTUH6FEGOrcz"
      },
      "execution_count": 382,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def initialize_weights_and_biases(m_inputs, layer_sizes:list, initialization='scaled'):\n",
        "    weights = {}\n",
        "    biases = {}\n",
        "\n",
        "    layers = [m_inputs] + layer_sizes\n",
        "\n",
        "    if initialization == 'scaled':\n",
        "        for i in range(len(layers)-1):\n",
        "            weights[\"W\" + str(i+1)] = np.random.randn(layers[i], layers[i+1]) * 0.01\n",
        "            biases[\"b\" + str(i+1)] = np.zeros((1, layers[i+1]))\n",
        "\n",
        "    elif initialization == 'xavier':\n",
        "        for i in range(len(layers)-1):\n",
        "            variance = 2 / (layers[i] + layers[i+1])\n",
        "            weights[\"W\" + str(i+1)] = np.random.randn(layers[i], layers[i+1]) * np.sqrt(variance)\n",
        "            biases[\"b\" + str(i+1)] = np.zeros((1, layers[i+1]))\n",
        "\n",
        "    elif initialization == 'he':\n",
        "        for i in range(len(layers)-1):\n",
        "            variance = 2 / (layers[i])\n",
        "            weights[\"W\" + str(i+1)] = np.random.randn(layers[i], layers[i+1]) * np.sqrt(variance)\n",
        "            biases[\"b\" + str(i+1)] = np.zeros((1, layers[i+1]))\n",
        "\n",
        "    else:\n",
        "        for i in range(len(layers)-1):\n",
        "            weights[\"W\" + str(i+1)] = np.random.randn(layers[i], layers[i+1])\n",
        "            biases[\"b\" + str(i+1)] = np.zeros((1, layers[i+1]))\n",
        "\n",
        "    # print(f\"Successfully initialized weights and biases for {len(layer_sizes)} layers\")\n",
        "    return weights, biases\n"
      ],
      "metadata": {
        "id": "pOIC9U5BfNo3"
      },
      "execution_count": 383,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sigmoid(z):\n",
        "    return 1 / (1 + np.exp(-z))\n",
        "\n",
        "def relu(z):\n",
        "    return np.maximum(0,z)\n",
        "\n",
        "def softmax(z):\n",
        "    exponent_values = np.exp(z - np.max(z, axis=1, keepdims=True))\n",
        "    return exponent_values / np.sum(exponent_values, axis=1, keepdims=True)"
      ],
      "metadata": {
        "id": "9NQVMamKbrlu"
      },
      "execution_count": 384,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def forward(A, weights, biases, activation_function, dropout=False, keep_prob=1):\n",
        "    Z_dict = {}\n",
        "    A_dict = {}\n",
        "    A_dict[\"A0\"] = A\n",
        "    l_dict = {}\n",
        "    dropouts = {}\n",
        "\n",
        "    if activation_function == 'relu':\n",
        "        activation_function = relu\n",
        "    else:\n",
        "        activation_function = sigmoid\n",
        "\n",
        "    for i in range(len(weights)-1): #loop through hidden layers\n",
        "        a_prev = A\n",
        "        Z = np.dot(a_prev, weights[\"W\" + str(i+1)]) + biases[\"b\" + str(i+1)]\n",
        "        Z_dict[\"Z\" + str(i+1)] = Z\n",
        "        A = activation_function(Z)\n",
        "\n",
        "        if dropout == True:\n",
        "            dropout_mask = (np.random.rand(A.shape[0], A.shape[1]) < keep_prob).astype(int)\n",
        "            A *= dropout_mask\n",
        "            A /= keep_prob\n",
        "            dropouts['A' + str(i+1)] = dropout_mask\n",
        "\n",
        "        A_dict[\"A\" + str(i+1)] = A\n",
        "        l_dict['layer' + str(i+1)] = activation_function.__name__\n",
        "\n",
        "    last_index = len(weights)\n",
        "\n",
        "    if weights[list(weights.keys())[-1]].shape[1] == 1:\n",
        "        output_activation = sigmoid\n",
        "    else:\n",
        "        output_activation = softmax\n",
        "\n",
        "    a_prev = A\n",
        "    Z = np.dot(a_prev, weights[\"W\" + str(last_index)]) + biases[\"b\" + str(last_index)]\n",
        "    Z_dict[\"Z\" + str(last_index)] = Z\n",
        "    A = output_activation(Z)\n",
        "    A_dict[\"A\" + str(last_index)] = A\n",
        "    l_dict['layer' + str(last_index)] = output_activation.__name__\n",
        "\n",
        "\n",
        "    dropouts['keep_prob'] = keep_prob\n",
        "\n",
        "    cache = {\"Z\":Z_dict,\n",
        "             \"A\":A_dict,\n",
        "             'layer_activations':l_dict,\n",
        "             'dropouts' : dropouts}\n",
        "\n",
        "    # print(\"Successfully computed a forward pass\")\n",
        "    return cache"
      ],
      "metadata": {
        "id": "A_sdeVp1fNq3"
      },
      "execution_count": 385,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_loss(y_pred, y_true, weights, loss='binary_cross_entropy', regularization='l2', reg_lambda=0):\n",
        "    epsilon = 1e-8\n",
        "    num_samples = y_pred.shape[0]\n",
        "    weight_loss = 0\n",
        "\n",
        "    if regularization == 'l2':\n",
        "        weight_loss = (reg_lambda / (2*num_samples))* np.sum([np.sum(weight ** 2) for _, weight in weights.items()])\n",
        "\n",
        "    if loss == 'cross_entropy':\n",
        "        return - np.mean(np.sum(y_true * np.log(y_pred + epsilon), axis=1)) + weight_loss\n",
        "    else:\n",
        "        return - np.mean(y_true * np.log(y_pred + epsilon) + (1-y_true)*np.log(1-y_pred + epsilon)) + weight_loss # added 1e-8 to avoid log(0)"
      ],
      "metadata": {
        "id": "11iGNgXdoPaN"
      },
      "execution_count": 386,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sigmoid_derivative(z):\n",
        "    s = sigmoid(z)\n",
        "    return s * (1 - s)\n",
        "\n",
        "def relu_derivative(z):\n",
        "    return (z > 0).astype(float)"
      ],
      "metadata": {
        "id": "Cpa39xURvtTr"
      },
      "execution_count": 387,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def backpropagation(X, y, weights, biases, cache, regularization=None, reg_lambda=0):\n",
        "\n",
        "    activation_derivative = sigmoid_derivative\n",
        "\n",
        "    A_cache = cache['A']\n",
        "    Z_cache = cache['Z']\n",
        "    L_cache = cache['layer_activations']\n",
        "    dropouts = cache['dropouts']\n",
        "    keep_prob = dropouts['keep_prob']\n",
        "\n",
        "    Z_gradients = {}\n",
        "    A_gradients = {}\n",
        "    W_gradients = {}\n",
        "    b_gradients = {}\n",
        "\n",
        "    m = X.shape[0]\n",
        "\n",
        "    for i in reversed(range(len(weights))):\n",
        "        if L_cache['layer' + str(i+1)] == 'relu':\n",
        "            activation_derivative = relu_derivative\n",
        "        if L_cache['layer' + str(i+1)] == 'sigmoid':\n",
        "            activation_derivative = sigmoid_derivative\n",
        "\n",
        "\n",
        "        if i+1 == len(weights): #special case for first dZ\n",
        "            dZ = A_cache[\"A\" + str(i+1)] - y\n",
        "            Z_gradients[\"dZ\" + str(i+1)] = dZ\n",
        "            W_gradients[\"dW\" + str(i+1)] = np.dot(A_cache[\"A\" + str(i)].T,dZ) / m\n",
        "            b_gradients[\"db\" + str(i+1)] = np.sum(dZ, axis=0, keepdims=True) / m\n",
        "\n",
        "            #adding regularization gradient\n",
        "            if regularization == 'l2':\n",
        "                W_gradients[\"dW\" + str(i+1)] += (reg_lambda / m) * weights['W' + str(i+1)]\n",
        "\n",
        "        else: #hidden layers\n",
        "\n",
        "            dZ = np.dot(Z_gradients[\"dZ\" + str(i+2)], weights[\"W\" + str(i+2)].T) * activation_derivative(Z_cache[\"Z\" + str(i+1)])\n",
        "\n",
        "            if regularization == 'dropout':\n",
        "                if 'A' + str(i+1) in dropouts:\n",
        "                    dZ *= dropouts['A' + str(i+1)]\n",
        "                    dZ /= keep_prob\n",
        "\n",
        "            Z_gradients[\"dZ\" + str(i+1)] = dZ\n",
        "            W_gradients[\"dW\" + str(i+1)] = np.dot(A_cache[\"A\" + str(i)].T, dZ) / m\n",
        "            b_gradients[\"db\" + str(i+1)] = np.sum(dZ, axis=0, keepdims=True) / m\n",
        "\n",
        "\n",
        "            #adding regularization gradient\n",
        "            if regularization == 'l2':\n",
        "                W_gradients[\"dW\" + str(i+1)] += (reg_lambda / m) * weights['W' + str(i+1)]\n",
        "\n",
        "        # print(f\"Layer {i+1} dW magnitude: {np.linalg.norm(W_gradients['dW' + str(i+1)])}\")\n",
        "        # print(f\"Layer {i+1} db magnitude: {np.linalg.norm(b_gradients['db' + str(i+1)])}\")\n",
        "\n",
        "    grads = {\"dW\" : W_gradients,\n",
        "             \"db\" : b_gradients}\n",
        "\n",
        "    return grads"
      ],
      "metadata": {
        "id": "oBO-AJcSpSct"
      },
      "execution_count": 388,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "weights, biases = initialize_weights_and_biases(m_inputs=784, layer_sizes=[256, 10], initialization='xavier')"
      ],
      "metadata": {
        "id": "h6yc6ghG8j84"
      },
      "execution_count": 389,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Vdw = {}\n",
        "Vdb = {}\n",
        "Sdw = {}\n",
        "Sdb = {}\n",
        "Vdw_corrected = {}\n",
        "Vdb_corrected = {}\n",
        "Sdw_corrected = {}\n",
        "Sdb_corrected = {}\n",
        "\n",
        "t = 1\n",
        "\n",
        "for i in range(len(weights)):\n",
        "    Vdw['w' + str(i+1)] = np.zeros_like(weights['W' + str(i+1)])\n",
        "    Vdb['b' + str(i+1)] = np.zeros_like(biases['b' + str(i+1)])\n",
        "\n",
        "    Sdw['w' + str(i+1)] = np.zeros_like(weights['W' + str(i+1)])\n",
        "    Sdb['b' + str(i+1)] = np.zeros_like(biases['b' + str(i+1)])\n",
        "\n",
        "\n",
        "def update_params(grads, weights, biases, learning_rate, optimizer='gd', beta1=0.9, beta2=0.999, epsilon=1e-8):\n",
        "\n",
        "    dw = grads['dW']\n",
        "    db = grads['db']\n",
        "\n",
        "    global t\n",
        "\n",
        "    if optimizer == 'momentum':\n",
        "      for i in range(len(weights)):\n",
        "        Vdw['w' + str(i+1)] = beta1 * Vdw['w' + str(i+1)] + ((1-beta1) * dw['dW' + str(i+1)])\n",
        "        weights[\"W\" + str(i+1)] = weights[\"W\" + str(i+1)] - learning_rate * Vdw['w' + str(i+1)]\n",
        "\n",
        "        Vdb['b' + str(i+1)] = beta1 * Vdb['b' + str(i+1)] + ((1-beta1) * db[\"db\" + str(i+1)])\n",
        "        biases[\"b\" + str(i+1)] = biases[\"b\" + str(i+1)] - learning_rate * Vdb['b' + str(i+1)]\n",
        "\n",
        "    elif optimizer == 'rmsprop':\n",
        "        for i in range(len(weights)):\n",
        "            Sdw['w' + str(i+1)] = beta2 * Sdw['w' + str(i+1)] + ((1-beta2) * (dw['dW' + str(i+1)])**2)\n",
        "            weights[\"W\" + str(i+1)] = weights[\"W\" + str(i+1)] - learning_rate * ((dw['dW' + str(i+1)])/(np.sqrt(Sdw['w' + str(i+1)] + epsilon)))\n",
        "\n",
        "            # print(np.sqrt(Sdw['w1'] + epsilon))\n",
        "\n",
        "            Sdb['b' + str(i+1)] = beta2 * Sdb['b' + str(i+1)] + ((1-beta2) * (db['db' + str(i+1)])**2)\n",
        "            biases[\"b\" + str(i+1)] = biases[\"b\" + str(i+1)] - learning_rate * ((db['db' + str(i+1)])/(np.sqrt(Sdb['b' + str(i+1)] + epsilon)))\n",
        "\n",
        "    elif optimizer == 'adam':\n",
        "        for i in range(len(weights)):\n",
        "            Vdw['w' + str(i+1)] = beta1 * Vdw['w' + str(i+1)] + ((1-beta1) * dw['dW' + str(i+1)])\n",
        "            Sdw['w' + str(i+1)] = beta2 * Sdw['w' + str(i+1)] + ((1-beta2) * (dw['dW' + str(i+1)])**2)\n",
        "\n",
        "            Vdb['b' + str(i+1)] = beta1 * Vdb['b' + str(i+1)] + ((1-beta1) * db[\"db\" + str(i+1)])\n",
        "            Sdb['b' + str(i+1)] = beta2 * Sdb['b' + str(i+1)] + ((1-beta2) * (db['db' + str(i+1)])**2)\n",
        "\n",
        "\n",
        "            #bias correction\n",
        "            Vdw_corrected['w' + str(i+1)] = Vdw['w' + str(i+1)] / (1-beta1**t)\n",
        "            Vdb_corrected['b' + str(i+1)] = Vdb['b' + str(i+1)] / (1-beta1**t)\n",
        "\n",
        "            Sdw_corrected['w' + str(i+1)] = Sdw['w' + str(i+1)] / (1-beta2**t)\n",
        "            Sdb_corrected['b' + str(i+1)] = Sdb['b' + str(i+1)] / (1-beta2**t)\n",
        "\n",
        "\n",
        "            weights[\"W\" + str(i+1)] = weights[\"W\" + str(i+1)] - learning_rate * (Vdw_corrected['w' + str(i+1)] / np.sqrt(Sdw_corrected['w' + str(i+1)] + epsilon))\n",
        "            biases['b' + str(i+1)] = biases['b' + str(i+1)] - learning_rate * (Vdb_corrected['b' + str(i+1)] / np.sqrt(Sdb_corrected['b' + str(i+1)] + epsilon))\n",
        "\n",
        "        t += 1\n",
        "\n",
        "    else: #normal gd\n",
        "        for i in range(len(weights)):\n",
        "            weights[\"W\" + str(i+1)] = weights[\"W\" + str(i+1)] - learning_rate * dw[\"dW\" + str(i+1)]\n",
        "            biases[\"b\" + str(i+1)] = biases[\"b\" + str(i+1)] - learning_rate * db[\"db\" + str(i+1)]\n",
        "\n",
        "    # print(\"Successfully updated params\")\n",
        "    return weights, biases"
      ],
      "metadata": {
        "id": "djF7hwUtxlyr"
      },
      "execution_count": 390,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(X, weights, biases):\n",
        "    cache = forward(X, weights, biases, activation_function='relu', dropout=False)\n",
        "    prediction = cache['A'][list(cache['A'].keys())[-1]]\n",
        "    return prediction"
      ],
      "metadata": {
        "id": "uLU5V7b0y80T"
      },
      "execution_count": 391,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if len(np.unique(y)) > 2:\n",
        "    y = one_hot_encoding(y)\n",
        "    y_test = one_hot_encoding(y_test)\n",
        "    classification_type = 'multi'\n",
        "else:\n",
        "    classification_type = 'single'\n",
        "\n",
        "\n",
        "def accuracy(prediction, labels):\n",
        "    total = len(labels)\n",
        "\n",
        "    if classification_type == 'single':\n",
        "        acc = np.sum((prediction > 0.5).astype(int) == labels) / total\n",
        "    else:\n",
        "        predicted_class = np.argmax(prediction, axis=1)\n",
        "        true_class = np.argmax(labels, axis=1)\n",
        "        acc = np.mean(predicted_class == true_class)\n",
        "    return acc\n"
      ],
      "metadata": {
        "id": "YAN6QKh0HlhD"
      },
      "execution_count": 392,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run(epochs, learning_rate, optimizer='gd', beta1=0.9, beta2=0.999, regularization='l2', reg_lambda=0, keep_prob=1):\n",
        "\n",
        "    dropout=False\n",
        "    if regularization == 'dropout':\n",
        "        dropout=True\n",
        "\n",
        "    for i in range(epochs):\n",
        "        cache = forward(X, weights, biases, activation_function='relu', dropout=dropout, keep_prob=keep_prob)\n",
        "        prediction = cache['A'][list(cache['A'].keys())[-1]]\n",
        "        grads = backpropagation(X, y, weights, biases, cache, regularization=regularization, reg_lambda=reg_lambda)\n",
        "\n",
        "        if i % 100 == 0:\n",
        "            dev_predictions = predict(X_test, weights, biases)\n",
        "            print(f\"epoch: {i}, loss= {calculate_loss(prediction, y, loss='cross_entropy' if classification_type=='multi' else 'binary_cross_entropy', weights=weights, regularization=regularization, reg_lambda=reg_lambda)}, training-set accuracy= {accuracy(prediction, y)}, dev-set accuracy= {accuracy(dev_predictions, y_test)}\")\n",
        "\n",
        "        update_params(grads, weights, biases, learning_rate, optimizer=optimizer, beta1=beta1, beta2=beta2)"
      ],
      "metadata": {
        "id": "bE-obYbZv2Lb"
      },
      "execution_count": 393,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run_mini_batches(epochs, learning_rate, mini_batch_size=64, optimizer='gd', beta1=0.9, beta2=0.999, regularization='l2', reg_lambda=0, keep_prob=1):\n",
        "\n",
        "    dropout=False\n",
        "    if regularization == 'dropout':\n",
        "        dropout=True\n",
        "\n",
        "    num_samples = X.shape[0]\n",
        "    div = int(num_samples / mini_batch_size)\n",
        "\n",
        "    divisible_by_mini_batch_size = mini_batch_size * div\n",
        "    not_divisible = num_samples - divisible_by_mini_batch_size\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        shuffled_indices = np.arange(num_samples)\n",
        "        np.random.shuffle(shuffled_indices)\n",
        "        X_shuffled = X[shuffled_indices]\n",
        "        y_shuffled = y[shuffled_indices]\n",
        "\n",
        "        start = 0\n",
        "        end = 0\n",
        "        for batch in range(start, divisible_by_mini_batch_size, mini_batch_size):\n",
        "            start = end\n",
        "            end = start + mini_batch_size\n",
        "            X_batch = X_shuffled[start:end, :]\n",
        "            y_batch = y_shuffled[start:end]\n",
        "\n",
        "            #forward\n",
        "            cache = forward(X_batch, weights, biases, activation_function='relu', dropout=dropout, keep_prob=keep_prob)\n",
        "            prediction = cache['A'][list(cache['A'].keys())[-1]]\n",
        "            #backward\n",
        "            grads = backpropagation(X_batch, y_batch, weights, biases, cache, regularization=regularization, reg_lambda=reg_lambda)\n",
        "            #update\n",
        "            update_params(grads, weights, biases, learning_rate, optimizer=optimizer, beta1=beta1, beta2=beta2)\n",
        "\n",
        "        if not_divisible != 0:\n",
        "            X_batch = X_shuffled[divisible_by_mini_batch_size:, :]\n",
        "            y_batch = y_shuffled[divisible_by_mini_batch_size:]\n",
        "            #forward\n",
        "            cache = forward(X_batch, weights, biases, activation_function='relu', dropout=dropout, keep_prob=keep_prob)\n",
        "            prediction = cache['A'][list(cache['A'].keys())[-1]]\n",
        "            #backward\n",
        "            grads = backpropagation(X_batch, y_batch, weights, biases, cache, regularization=regularization, reg_lambda=reg_lambda)\n",
        "            #update\n",
        "            update_params(grads, weights, biases, learning_rate, optimizer=optimizer, beta1=beta1, beta2=beta2)\n",
        "\n",
        "        cache = forward(X, weights, biases, activation_function='relu', dropout=False)\n",
        "        full_prediction = cache['A'][list(cache['A'].keys())[-1]]\n",
        "        dev_predictions = predict(X_test, weights, biases)\n",
        "        print(f\"epoch: {epoch+1}, loss= {calculate_loss(full_prediction, y, loss='cross_entropy' if classification_type=='multi' else 'binary_cross_entropy', weights=weights, regularization=regularization, reg_lambda=reg_lambda)}, training-set accuracy= {accuracy(full_prediction, y)}, dev-set accuracy= {accuracy(dev_predictions, y_test)}\")\n"
      ],
      "metadata": {
        "id": "AgzrO6SZBrIw"
      },
      "execution_count": 394,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# run(epochs=10000, learning_rate=0.005)"
      ],
      "metadata": {
        "id": "4oMThHvuwDdK"
      },
      "execution_count": 395,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "run_mini_batches(epochs=20, learning_rate=0.0001, mini_batch_size=50, optimizer='adam', beta1=0.9, beta2=0.999, regularization='dropout', reg_lambda=0.1, keep_prob=0.8)"
      ],
      "metadata": {
        "id": "zq_460UVTJVT",
        "outputId": "7208f61c-f37b-4945-aad7-d50edfc0082d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 396,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 1, loss= 0.32730494892195694, training-set accuracy= 0.9141333333333334, dev-set accuracy= 0.9154\n",
            "epoch: 2, loss= 0.24627293049087748, training-set accuracy= 0.9327, dev-set accuracy= 0.9319\n",
            "epoch: 3, loss= 0.2050363143327865, training-set accuracy= 0.9436333333333333, dev-set accuracy= 0.9422\n",
            "epoch: 4, loss= 0.1764231174521216, training-set accuracy= 0.9506166666666667, dev-set accuracy= 0.948\n",
            "epoch: 5, loss= 0.15490876962816405, training-set accuracy= 0.9563, dev-set accuracy= 0.9545\n",
            "epoch: 6, loss= 0.13721380639730937, training-set accuracy= 0.9615166666666667, dev-set accuracy= 0.959\n",
            "epoch: 7, loss= 0.12290265273825927, training-set accuracy= 0.96595, dev-set accuracy= 0.9627\n",
            "epoch: 8, loss= 0.11136842011299905, training-set accuracy= 0.9691666666666666, dev-set accuracy= 0.9648\n",
            "epoch: 9, loss= 0.10182361517718731, training-set accuracy= 0.9718666666666667, dev-set accuracy= 0.966\n",
            "epoch: 10, loss= 0.0924145387059967, training-set accuracy= 0.9751666666666666, dev-set accuracy= 0.9688\n",
            "epoch: 11, loss= 0.08565380580372878, training-set accuracy= 0.9769666666666666, dev-set accuracy= 0.9696\n",
            "epoch: 12, loss= 0.08017313045943358, training-set accuracy= 0.97825, dev-set accuracy= 0.9704\n",
            "epoch: 13, loss= 0.07319151749802712, training-set accuracy= 0.9802833333333333, dev-set accuracy= 0.9723\n",
            "epoch: 14, loss= 0.0679949245669006, training-set accuracy= 0.9818666666666667, dev-set accuracy= 0.9734\n",
            "epoch: 15, loss= 0.0633625058946267, training-set accuracy= 0.9825833333333334, dev-set accuracy= 0.9744\n",
            "epoch: 16, loss= 0.05938721690071278, training-set accuracy= 0.9842833333333333, dev-set accuracy= 0.974\n",
            "epoch: 17, loss= 0.05498057505823969, training-set accuracy= 0.9852833333333333, dev-set accuracy= 0.9754\n",
            "epoch: 18, loss= 0.052190764824891045, training-set accuracy= 0.9863, dev-set accuracy= 0.9761\n",
            "epoch: 19, loss= 0.048374569640854785, training-set accuracy= 0.9872833333333333, dev-set accuracy= 0.9768\n",
            "epoch: 20, loss= 0.04570601280599566, training-set accuracy= 0.9879333333333333, dev-set accuracy= 0.977\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "A1 = forward(X_test, weights, biases, activation_function='relu')['A']['A1']\n",
        "print(f\"A1 variance = {np.var(A1)}\")"
      ],
      "metadata": {
        "id": "4dm8WTHgItOn",
        "outputId": "c5f4ac09-bf42-46a3-ad84-690b01f431fc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 398,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A1 variance = 0.42541116944548923\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# np.savez('best_trained_model_params[32,16,10].npz', **weights, **biases)\n",
        "# data = np.load('trained_model_params.npz')"
      ],
      "metadata": {
        "id": "PDZUH2uAUaeD"
      },
      "execution_count": 399,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#visualize mnist\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_predictions(X, y, num_images=10):\n",
        "    num_samples = X.shape[0]\n",
        "    shuffled_indices = np.arange(num_samples)\n",
        "    np.random.shuffle(shuffled_indices)\n",
        "    X_shuffled = X[shuffled_indices]\n",
        "    y_shuffled = y[shuffled_indices]\n",
        "\n",
        "    random_picks = np.random.choice(np.arange(num_samples), size=num_images)\n",
        "\n",
        "    images = X_shuffled[random_picks]\n",
        "    labels = y_shuffled[random_picks]\n",
        "    predictions_probability_distribution = predict(images, weights, biases)\n",
        "    predicted_labels = np.argmax(predictions_probability_distribution, axis=1)\n",
        "\n",
        "\n",
        "    fig, axes = plt.subplots(2, num_images, figsize=(20,6))\n",
        "    for i in range(len(images)):\n",
        "        axes[0,i].imshow(images[i].reshape(28,28), cmap='gray')\n",
        "        axes[0,i].set_title(\"true: \" + str(labels[i]) + \"\\npredicted: \" + str(predicted_labels[i]))\n",
        "        axes[0,i].axis('off')\n",
        "        axes[1,i].bar(x=np.arange(10), height=predictions_probability_distribution[i])\n",
        "        axes[1,i].set_ylim(0,1)\n",
        "        axes[1,i].set_xticks(np.arange(10))\n",
        "\n",
        "plot_predictions(X_test_copy, y_test_copy, num_images=5)"
      ],
      "metadata": {
        "id": "U2S_jh2B9N5O",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "94a711e9-bd38-4fcc-ebf4-f637c1c75607"
      },
      "execution_count": 400,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 2000x600 with 10 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import numpy as np\n",
        "# import matplotlib.pyplot as plt\n",
        "\n",
        "# h = 0.05\n",
        "# x_min, x_max = X[:,0].min() - 1, X[:,0].max() + 1\n",
        "# y_min, y_max = X[:,1].min() - 1, X[:,1].max() + 1\n",
        "\n",
        "# xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n",
        "#                      np.arange(y_min, y_max, h))\n",
        "\n",
        "# grid_points = np.c_[xx.ravel(), yy.ravel()]\n",
        "\n",
        "# preds = predict(grid_points, weights, biases)\n",
        "\n",
        "# Z = (preds > 0.5).astype(int)\n",
        "# Z = Z.reshape(xx.shape)\n",
        "\n",
        "\n",
        "# plt.figure(figsize=(8,6))\n",
        "# plt.contourf(xx, yy, Z, alpha=0.3, cmap=plt.cm.RdBu)\n",
        "\n",
        "# plt.scatter(class0_points[:, 0], class0_points[:, 1], c='blue', label='Class 0 (Inner)', alpha=0.7)\n",
        "# plt.scatter(class1_points[:, 0], class1_points[:, 1], c='red', label='Class 1 (Outer)', alpha=0.7)\n",
        "\n",
        "# plt.title(\"Decision Boundary\")\n",
        "# plt.xlabel(\"Feature 1\")\n",
        "# plt.ylabel(\"Feature 2\")\n",
        "# plt.legend()\n",
        "# plt.grid(True)\n",
        "# plt.gca().set_aspect('equal', adjustable='box')\n",
        "# plt.show()\n"
      ],
      "metadata": {
        "id": "yoUkunx185nD"
      },
      "execution_count": 401,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2BUbd2vyiFKN"
      },
      "execution_count": 401,
      "outputs": []
    }
  ]
}