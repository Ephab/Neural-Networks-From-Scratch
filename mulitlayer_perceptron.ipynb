{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 310,
      "metadata": {
        "id": "pGGkE4BAep1f"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "np.set_printoptions(suppress=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# #Binary classification\n",
        "# import matplotlib.pyplot as plt\n",
        "\n",
        "# # random dataset\n",
        "\n",
        "# NUM_SAMPLES_PER_CLASS = 200\n",
        "# INNER_RADIUS = 2\n",
        "# OUTER_RADIUS = 5\n",
        "# NOISE_STD_DEV = 0.5\n",
        "\n",
        "# theta_inner = 2 * np.pi * np.random.rand(NUM_SAMPLES_PER_CLASS)\n",
        "\n",
        "# radius_inner = INNER_RADIUS * np.random.rand(NUM_SAMPLES_PER_CLASS) + np.random.normal(0, NOISE_STD_DEV, NUM_SAMPLES_PER_CLASS)\n",
        "# x0 = radius_inner * np.cos(theta_inner)\n",
        "# y0 = radius_inner * np.sin(theta_inner)\n",
        "# class0_points = np.vstack([x0, y0]).T\n",
        "# class0_labels = np.zeros(NUM_SAMPLES_PER_CLASS)\n",
        "\n",
        "# theta_outer = 2 * np.pi * np.random.rand(NUM_SAMPLES_PER_CLASS)\n",
        "\n",
        "# radius_outer = np.random.uniform(INNER_RADIUS + 1, OUTER_RADIUS, NUM_SAMPLES_PER_CLASS) + np.random.normal(0, NOISE_STD_DEV, NUM_SAMPLES_PER_CLASS)\n",
        "# x1 = radius_outer * np.cos(theta_outer)\n",
        "# y1 = radius_outer * np.sin(theta_outer)\n",
        "# class1_points = np.vstack([x1, y1]).T\n",
        "# class1_labels = np.ones(NUM_SAMPLES_PER_CLASS)\n",
        "\n",
        "\n",
        "# X = np.vstack([class0_points, class1_points])\n",
        "# y = np.hstack([class0_labels, class1_labels])\n",
        "# y = y.reshape(-1, 1) # stupid broadcasting bug that i spent an hour on -.-\n",
        "\n",
        "\n",
        "# plt.figure(figsize=(8, 6))\n",
        "\n",
        "# plt.scatter(class0_points[:, 0], class0_points[:, 1], c='blue', label='Class 0 (Inner)', alpha=0.7)\n",
        "\n",
        "# plt.scatter(class1_points[:, 0], class1_points[:, 1], c='red', label='Class 1 (Outer)', alpha=0.7)\n",
        "# plt.title('Concentric Rings Dataset')\n",
        "# plt.xlabel('Feature 1')\n",
        "# plt.ylabel('Feature 2')\n",
        "# plt.legend()\n",
        "# plt.grid(True)\n",
        "# plt.gca().set_aspect('equal', adjustable='box')\n",
        "# plt.show()"
      ],
      "metadata": {
        "id": "0Wsu6mPtfNcy"
      },
      "execution_count": 311,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Mnist dataset\n",
        "import copy\n",
        "from tensorflow.keras.datasets import mnist\n",
        "\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "\n",
        "X_train = (X_train.astype('float64') / 255.0).reshape(-1,28*28)\n",
        "X_test = (X_test.astype('float64') / 255.0).reshape(-1,28*28)\n",
        "\n",
        "X_train_copy = copy.deepcopy(X_train)\n",
        "y_train_copy = copy.deepcopy(y_train)\n",
        "\n",
        "X = X_train#[:2000,:]\n",
        "y = y_train.reshape(60000, -1)#[:2000,:]\n",
        "X_test = X_test#[:1000,:]\n",
        "y_test = y_test.reshape(-1,1)#[:1000, :]"
      ],
      "metadata": {
        "id": "_rV-2-fY5Ske"
      },
      "execution_count": 312,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X.shape, y.shape, X_test.shape, y_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Z1MPju7fNj6",
        "outputId": "0b081d4c-7dc6-490b-d825-31dcc9cd0a97"
      },
      "execution_count": 313,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((60000, 784), (60000, 1), (10000, 784), (10000, 1))"
            ]
          },
          "metadata": {},
          "execution_count": 313
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def one_hot_encoding(vector):\n",
        "    vector = np.array(vector).astype(int).flatten()\n",
        "    # if vector.ndim == 1:\n",
        "    #     return vector\n",
        "    size=len(vector)\n",
        "    num_classes = max(np.max(vector) + 1, 10)\n",
        "\n",
        "    encoded_matrix = np.zeros((size, num_classes))\n",
        "    encoded_matrix[np.arange(size), vector] = 1\n",
        "    return encoded_matrix"
      ],
      "metadata": {
        "id": "wsCbSo0pwQ_l"
      },
      "execution_count": 314,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_test_split(X, y, test_size=0.2):\n",
        "    num_samples = X.shape[0]\n",
        "    train_size = int(np.ceil(num_samples * (1-test_size)))\n",
        "    test_size = int(np.floor(num_samples * test_size))\n",
        "\n",
        "    shuffled_indices = np.arange(num_samples)\n",
        "    np.random.shuffle(shuffled_indices)\n",
        "    X = X[shuffled_indices]\n",
        "    y= y[shuffled_indices]\n",
        "\n",
        "    X_train = X[:train_size, :]\n",
        "    y_train = y[:train_size,]\n",
        "    X_test = X[train_size:]\n",
        "    y_test = y[train_size:]\n",
        "\n",
        "    return X_train, y_train, X_test, y_test"
      ],
      "metadata": {
        "id": "fQo6YdzuK3sk"
      },
      "execution_count": 315,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# X_train, y_train, X_test, y_test = train_test_split(X, y)"
      ],
      "metadata": {
        "id": "DTUH6FEGOrcz"
      },
      "execution_count": 316,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def initialize_weights_and_biases(m_inputs, layer_sizes:list):\n",
        "    weights = {}\n",
        "    biases = {}\n",
        "\n",
        "    layers = [m_inputs] + layer_sizes\n",
        "\n",
        "    for i in range(len(layers)-1):\n",
        "        weights[\"W\" + str(i+1)] = np.random.randn(layers[i], layers[i+1])# * 0.01 left out due to vanishing gradients\n",
        "        biases[\"b\" + str(i+1)] = np.zeros((1, layers[i+1]))\n",
        "\n",
        "    # print(f\"Successfully initialized weights and biases for {len(layer_sizes)} layers\")\n",
        "    return weights, biases\n"
      ],
      "metadata": {
        "id": "pOIC9U5BfNo3"
      },
      "execution_count": 317,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sigmoid(z):\n",
        "    return 1 / (1 + np.exp(-z))\n",
        "\n",
        "def relu(z):\n",
        "    return np.maximum(0,z)\n",
        "\n",
        "def softmax(z):\n",
        "    exponent_values = np.exp(z - np.max(z, axis=1, keepdims=True))\n",
        "    return exponent_values / np.sum(exponent_values, axis=1, keepdims=True)"
      ],
      "metadata": {
        "id": "9NQVMamKbrlu"
      },
      "execution_count": 318,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def forward(A, weights, biases, activation_function):\n",
        "    Z_dict = {}\n",
        "    A_dict = {}\n",
        "    A_dict[\"A0\"] = A\n",
        "    l_dict = {}\n",
        "\n",
        "    if activation_function == 'relu':\n",
        "        activation_function = relu\n",
        "    else:\n",
        "        activation_function = sigmoid\n",
        "\n",
        "\n",
        "    for i in range(len(weights)-1): #loop through hidden layers\n",
        "        a_prev = A\n",
        "        Z = np.dot(a_prev, weights[\"W\" + str(i+1)]) + biases[\"b\" + str(i+1)]\n",
        "        Z_dict[\"Z\" + str(i+1)] = Z\n",
        "        A = activation_function(Z)\n",
        "        A_dict[\"A\" + str(i+1)] = A\n",
        "        l_dict['layer' + str(i+1)] = activation_function.__name__\n",
        "\n",
        "    last_index = len(weights)\n",
        "\n",
        "    if weights[list(weights.keys())[-1]].shape[1] == 1:\n",
        "        output_activation = sigmoid\n",
        "    else:\n",
        "        output_activation = softmax\n",
        "\n",
        "    a_prev = A\n",
        "    Z = np.dot(a_prev, weights[\"W\" + str(last_index)]) + biases[\"b\" + str(last_index)]\n",
        "    Z_dict[\"Z\" + str(last_index)] = Z\n",
        "    A = output_activation(Z)\n",
        "    A_dict[\"A\" + str(last_index)] = A\n",
        "    l_dict['layer' + str(last_index)] = output_activation.__name__\n",
        "\n",
        "\n",
        "    cache = {\"Z\":Z_dict,\n",
        "             \"A\":A_dict,\n",
        "             'layer_activations':l_dict}\n",
        "\n",
        "    # print(\"Successfully computed a forward pass\")\n",
        "    return cache"
      ],
      "metadata": {
        "id": "A_sdeVp1fNq3"
      },
      "execution_count": 319,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_loss(y_pred, y_true, loss='binary_cross_entropy'):\n",
        "    epsilon = 1e-8\n",
        "\n",
        "    if loss == 'cross_entropy':\n",
        "        return - np.mean(np.sum(y_true * np.log(y_pred + epsilon), axis=1))\n",
        "    else:\n",
        "        return - np.mean(y_true * np.log(y_pred + epsilon) + (1-y_true)*np.log(1-y_pred + epsilon)) # added 1e-8 to avoid log(0)"
      ],
      "metadata": {
        "id": "11iGNgXdoPaN"
      },
      "execution_count": 320,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sigmoid_derivative(z):\n",
        "    s = sigmoid(z)\n",
        "    return s * (1 - s)\n",
        "\n",
        "def relu_derivative(z):\n",
        "    return (z > 0).astype(float)"
      ],
      "metadata": {
        "id": "Cpa39xURvtTr"
      },
      "execution_count": 321,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def backpropagation(X, y, weights, biases, cache):\n",
        "\n",
        "    activation_derivative = sigmoid_derivative\n",
        "\n",
        "    A_cache = cache['A']\n",
        "    Z_cache = cache['Z']\n",
        "    L_cache = cache['layer_activations']\n",
        "\n",
        "    Z_gradients = {}\n",
        "    A_gradients = {}\n",
        "    W_gradients = {}\n",
        "    b_gradients = {}\n",
        "\n",
        "    m = X.shape[0]\n",
        "\n",
        "    for i in reversed(range(len(weights))):\n",
        "        if L_cache['layer' + str(i+1)] == 'relu':\n",
        "            activation_derivative = relu_derivative\n",
        "        if L_cache['layer' + str(i+1)] == 'sigmoid':\n",
        "            activation_derivative = sigmoid_derivative\n",
        "\n",
        "\n",
        "        if i+1 == len(weights): #special case for first dZ\n",
        "            dZ = A_cache[\"A\" + str(i+1)] - y\n",
        "            Z_gradients[\"dZ\" + str(i+1)] = dZ\n",
        "            W_gradients[\"dW\" + str(i+1)] = np.dot(A_cache[\"A\" + str(i)].T,dZ) / m\n",
        "            b_gradients[\"db\" + str(i+1)] = np.sum(dZ, axis=0, keepdims=True) / m\n",
        "        else:\n",
        "            dZ = np.dot(Z_gradients[\"dZ\" + str(i+2)], weights[\"W\" + str(i+2)].T ) * activation_derivative(Z_cache[\"Z\" + str(i+1)])\n",
        "            Z_gradients[\"dZ\" + str(i+1)] = dZ\n",
        "            W_gradients[\"dW\" + str(i+1)] = np.dot(A_cache[\"A\" + str(i)].T,dZ) / m\n",
        "            b_gradients[\"db\" + str(i+1)] = np.sum(dZ, axis=0, keepdims=True) / m\n",
        "\n",
        "        # print(f\"Layer {i+1} dW magnitude: {np.linalg.norm(W_gradients['dW' + str(i+1)])}\")\n",
        "        # print(f\"Layer {i+1} db magnitude: {np.linalg.norm(b_gradients['db' + str(i+1)])}\")\n",
        "\n",
        "    grads = {\"dW\" : W_gradients,\n",
        "             \"db\" : b_gradients}\n",
        "\n",
        "    return grads"
      ],
      "metadata": {
        "id": "oBO-AJcSpSct"
      },
      "execution_count": 322,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def update_params(grads, weights, biases, learning_rate:float):\n",
        "\n",
        "    dw = grads['dW']\n",
        "    db = grads['db']\n",
        "\n",
        "    for i in range(len(weights)):\n",
        "        weights[\"W\" + str(i+1)] = weights[\"W\" + str(i+1)] - learning_rate * dw[\"dW\" + str(i+1)]\n",
        "        biases[\"b\" + str(i+1)] = biases[\"b\" + str(i+1)] - learning_rate * db[\"db\" + str(i+1)]\n",
        "\n",
        "    # print(\"Successfully updated params\")\n",
        "    return weights, biases"
      ],
      "metadata": {
        "id": "djF7hwUtxlyr"
      },
      "execution_count": 323,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(X, weights, biases):\n",
        "    cache = forward(X, weights, biases, activation_function='relu')\n",
        "    prediction = cache['A'][list(cache['A'].keys())[-1]]\n",
        "    return prediction"
      ],
      "metadata": {
        "id": "uLU5V7b0y80T"
      },
      "execution_count": 324,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "weights, biases = initialize_weights_and_biases(m_inputs=784, layer_sizes=[32, 16, 10])"
      ],
      "metadata": {
        "id": "h6yc6ghG8j84"
      },
      "execution_count": 325,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if len(np.unique(y)) > 2:\n",
        "    y = one_hot_encoding(y)\n",
        "    y_test = one_hot_encoding(y_test)\n",
        "    classification_type = 'multi'\n",
        "else:\n",
        "    classification_type = 'single'\n",
        "\n",
        "\n",
        "def accuracy(prediction, labels):\n",
        "    total = len(labels)\n",
        "\n",
        "    if classification_type == 'single':\n",
        "        acc = np.sum((prediction > 0.5).astype(int) == labels) / total\n",
        "    else:\n",
        "        predicted_class = np.argmax(prediction, axis=1)\n",
        "        true_class = np.argmax(labels, axis=1)\n",
        "        acc = np.mean(predicted_class == true_class)\n",
        "    return acc\n"
      ],
      "metadata": {
        "id": "YAN6QKh0HlhD"
      },
      "execution_count": 326,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run(epochs, learning_rate):\n",
        "    for i in range(epochs):\n",
        "        cache = forward(X, weights, biases, activation_function='relu')\n",
        "        prediction = cache['A'][list(cache['A'].keys())[-1]]\n",
        "        grads = backpropagation(X, y, weights, biases, cache)\n",
        "\n",
        "\n",
        "        if i % 100 == 0:\n",
        "            dev_predictions = predict(X_test, weights, biases)\n",
        "            print(f\"epoch: {i}, loss= {calculate_loss(prediction, y, loss='cross_entropy' if classification_type=='multi' else 'binary_cross_entropy')}, training-set accuracy= {accuracy(prediction, y)}, dev-set accuracy= {accuracy(dev_predictions, y_test)}\")\n",
        "\n",
        "        update_params(grads, weights, biases, learning_rate)"
      ],
      "metadata": {
        "id": "bE-obYbZv2Lb"
      },
      "execution_count": 327,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run_mini_batches(epochs, learning_rate, mini_batch_size=64):\n",
        "    num_samples = X.shape[0]\n",
        "    div = int(num_samples / mini_batch_size)\n",
        "\n",
        "    divisible_by_mini_batch_size = mini_batch_size * div\n",
        "    not_divisible = num_samples - divisible_by_mini_batch_size\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        shuffled_indices = np.arange(num_samples)\n",
        "        np.random.shuffle(shuffled_indices)\n",
        "        X_shuffled = X[shuffled_indices]\n",
        "        y_shuffled = y[shuffled_indices]\n",
        "\n",
        "        start = 0\n",
        "        end = 0\n",
        "        for batch in range(start, divisible_by_mini_batch_size, mini_batch_size):\n",
        "            start = end\n",
        "            end = start + mini_batch_size\n",
        "            X_batch = X_shuffled[start:end, :]\n",
        "            y_batch = y_shuffled[start:end]\n",
        "            #forward\n",
        "            cache = forward(X_batch, weights, biases, activation_function='relu')\n",
        "            prediction = cache['A'][list(cache['A'].keys())[-1]]\n",
        "            #backward\n",
        "            grads = backpropagation(X_batch, y_batch, weights, biases, cache)\n",
        "            #update\n",
        "            update_params(grads, weights, biases, learning_rate)\n",
        "\n",
        "        X_batch = X_shuffled[divisible_by_mini_batch_size:, :]\n",
        "        y_batch = y_shuffled[divisible_by_mini_batch_size:]\n",
        "        #forward\n",
        "        cache = forward(X_batch, weights, biases, activation_function='relu')\n",
        "        prediction = cache['A'][list(cache['A'].keys())[-1]]\n",
        "        #backward\n",
        "        grads = backpropagation(X_batch, y_batch, weights, biases, cache)\n",
        "        #update\n",
        "        update_params(grads, weights, biases, learning_rate)\n",
        "\n",
        "        cache = forward(X, weights, biases, activation_function='relu')\n",
        "        full_prediction = cache['A'][list(cache['A'].keys())[-1]]\n",
        "        dev_predictions = predict(X_test, weights, biases)\n",
        "        print(f\"epoch: {epoch}, loss= {calculate_loss(full_prediction, y, loss='cross_entropy' if classification_type=='multi' else 'binary_cross_entropy')}, training-set accuracy= {accuracy(full_prediction, y)}, dev-set accuracy= {accuracy(dev_predictions, y_test)}\")\n"
      ],
      "metadata": {
        "id": "AgzrO6SZBrIw"
      },
      "execution_count": 328,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# run(epochs=10000, learning_rate=0.005)"
      ],
      "metadata": {
        "id": "4oMThHvuwDdK"
      },
      "execution_count": 329,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "run_mini_batches(epochs=100, learning_rate=0.05, mini_batch_size=64)"
      ],
      "metadata": {
        "id": "zq_460UVTJVT",
        "outputId": "02d3fcc5-9789-45d7-a311-fe640aac02d3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 330,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 0, loss= 2.165097561043975, training-set accuracy= 0.17786666666666667, dev-set accuracy= 0.1859\n",
            "epoch: 1, loss= 2.0338339840686226, training-set accuracy= 0.21186666666666668, dev-set accuracy= 0.2132\n",
            "epoch: 2, loss= 1.936364317358308, training-set accuracy= 0.22906666666666667, dev-set accuracy= 0.2303\n",
            "epoch: 3, loss= 1.7326206556438508, training-set accuracy= 0.3168166666666667, dev-set accuracy= 0.3231\n",
            "epoch: 4, loss= 1.7304146152119533, training-set accuracy= 0.3130833333333333, dev-set accuracy= 0.3207\n",
            "epoch: 5, loss= 1.6583524264516463, training-set accuracy= 0.34225, dev-set accuracy= 0.3435\n",
            "epoch: 6, loss= 1.569883863683089, training-set accuracy= 0.3548, dev-set accuracy= 0.3566\n",
            "epoch: 7, loss= 1.5891225340681487, training-set accuracy= 0.3733, dev-set accuracy= 0.3721\n",
            "epoch: 8, loss= 1.5194922712157672, training-set accuracy= 0.3544, dev-set accuracy= 0.3586\n",
            "epoch: 9, loss= 1.48692437905627, training-set accuracy= 0.3906, dev-set accuracy= 0.392\n",
            "epoch: 10, loss= 1.7918524676226466, training-set accuracy= 0.2855666666666667, dev-set accuracy= 0.2855\n",
            "epoch: 11, loss= 1.5453263883856492, training-set accuracy= 0.38593333333333335, dev-set accuracy= 0.3776\n",
            "epoch: 12, loss= 1.696511113924133, training-set accuracy= 0.40491666666666665, dev-set accuracy= 0.407\n",
            "epoch: 13, loss= 1.4513390113421076, training-set accuracy= 0.44103333333333333, dev-set accuracy= 0.4433\n",
            "epoch: 14, loss= 1.2686056985340997, training-set accuracy= 0.5072166666666666, dev-set accuracy= 0.5129\n",
            "epoch: 15, loss= 1.3469979760213633, training-set accuracy= 0.49573333333333336, dev-set accuracy= 0.4963\n",
            "epoch: 16, loss= 1.214825119658852, training-set accuracy= 0.5745166666666667, dev-set accuracy= 0.5821\n",
            "epoch: 17, loss= 1.1204896340964736, training-set accuracy= 0.6065166666666667, dev-set accuracy= 0.6143\n",
            "epoch: 18, loss= 1.2692315835468222, training-set accuracy= 0.5842833333333334, dev-set accuracy= 0.588\n",
            "epoch: 19, loss= 0.9861196854592493, training-set accuracy= 0.6696166666666666, dev-set accuracy= 0.6788\n",
            "epoch: 20, loss= 1.0426967600775536, training-set accuracy= 0.6425, dev-set accuracy= 0.6462\n",
            "epoch: 21, loss= 0.7974778509530897, training-set accuracy= 0.7513, dev-set accuracy= 0.7524\n",
            "epoch: 22, loss= 0.7470468120253004, training-set accuracy= 0.7641333333333333, dev-set accuracy= 0.7662\n",
            "epoch: 23, loss= 0.7303478472464039, training-set accuracy= 0.7755333333333333, dev-set accuracy= 0.7644\n",
            "epoch: 24, loss= 0.6700152001440581, training-set accuracy= 0.799, dev-set accuracy= 0.8002\n",
            "epoch: 25, loss= 0.7034930692471145, training-set accuracy= 0.7824833333333333, dev-set accuracy= 0.7753\n",
            "epoch: 26, loss= 0.7862122275273457, training-set accuracy= 0.73955, dev-set accuracy= 0.7473\n",
            "epoch: 27, loss= 0.6063846003482043, training-set accuracy= 0.8226833333333333, dev-set accuracy= 0.8267\n",
            "epoch: 28, loss= 0.5582529627080046, training-set accuracy= 0.8416166666666667, dev-set accuracy= 0.8441\n",
            "epoch: 29, loss= 0.5585096543937256, training-set accuracy= 0.8414666666666667, dev-set accuracy= 0.8463\n",
            "epoch: 30, loss= 0.5316143451278427, training-set accuracy= 0.8458, dev-set accuracy= 0.8472\n",
            "epoch: 31, loss= 0.5094693760050127, training-set accuracy= 0.85975, dev-set accuracy= 0.8611\n",
            "epoch: 32, loss= 0.5955521478481685, training-set accuracy= 0.8198333333333333, dev-set accuracy= 0.8124\n",
            "epoch: 33, loss= 0.48772419620410684, training-set accuracy= 0.8650333333333333, dev-set accuracy= 0.8617\n",
            "epoch: 34, loss= 0.49517998295444776, training-set accuracy= 0.8567666666666667, dev-set accuracy= 0.8502\n",
            "epoch: 35, loss= 0.49984549125559424, training-set accuracy= 0.8534, dev-set accuracy= 0.8578\n",
            "epoch: 36, loss= 0.4646914752058148, training-set accuracy= 0.866, dev-set accuracy= 0.8651\n",
            "epoch: 37, loss= 0.4657489124111955, training-set accuracy= 0.86415, dev-set accuracy= 0.8651\n",
            "epoch: 38, loss= 0.4420970712835612, training-set accuracy= 0.87455, dev-set accuracy= 0.8713\n",
            "epoch: 39, loss= 0.4210726847589452, training-set accuracy= 0.8790666666666667, dev-set accuracy= 0.8768\n",
            "epoch: 40, loss= 0.409325747376177, training-set accuracy= 0.88205, dev-set accuracy= 0.8784\n",
            "epoch: 41, loss= 0.41020314405114744, training-set accuracy= 0.8822, dev-set accuracy= 0.8819\n",
            "epoch: 42, loss= 0.3793835344849397, training-set accuracy= 0.89275, dev-set accuracy= 0.8933\n",
            "epoch: 43, loss= 0.3719865675459023, training-set accuracy= 0.8954333333333333, dev-set accuracy= 0.8938\n",
            "epoch: 44, loss= 0.3943372326586935, training-set accuracy= 0.88485, dev-set accuracy= 0.8823\n",
            "epoch: 45, loss= 0.36454859068314766, training-set accuracy= 0.8959833333333334, dev-set accuracy= 0.895\n",
            "epoch: 46, loss= 0.37345984003733207, training-set accuracy= 0.8957833333333334, dev-set accuracy= 0.8935\n",
            "epoch: 47, loss= 0.45396108050902345, training-set accuracy= 0.8618833333333333, dev-set accuracy= 0.8615\n",
            "epoch: 48, loss= 0.3660498069368421, training-set accuracy= 0.8944, dev-set accuracy= 0.8894\n",
            "epoch: 49, loss= 0.34647519849935793, training-set accuracy= 0.9005166666666666, dev-set accuracy= 0.897\n",
            "epoch: 50, loss= 0.3466774618803655, training-set accuracy= 0.9014333333333333, dev-set accuracy= 0.8998\n",
            "epoch: 51, loss= 0.37234230648982214, training-set accuracy= 0.89455, dev-set accuracy= 0.8926\n",
            "epoch: 52, loss= 0.3538463074892615, training-set accuracy= 0.90045, dev-set accuracy= 0.8997\n",
            "epoch: 53, loss= 0.3705165253361068, training-set accuracy= 0.8908666666666667, dev-set accuracy= 0.8862\n",
            "epoch: 54, loss= 0.3392984858663895, training-set accuracy= 0.90135, dev-set accuracy= 0.8984\n",
            "epoch: 55, loss= 0.3317197800603786, training-set accuracy= 0.90585, dev-set accuracy= 0.8991\n",
            "epoch: 56, loss= 0.3327913847393238, training-set accuracy= 0.90215, dev-set accuracy= 0.8993\n",
            "epoch: 57, loss= 0.3240236710851762, training-set accuracy= 0.9086166666666666, dev-set accuracy= 0.9052\n",
            "epoch: 58, loss= 0.3312945471097668, training-set accuracy= 0.9044833333333333, dev-set accuracy= 0.9012\n",
            "epoch: 59, loss= 0.32455357840346327, training-set accuracy= 0.9086666666666666, dev-set accuracy= 0.9049\n",
            "epoch: 60, loss= 0.36873852148131625, training-set accuracy= 0.888, dev-set accuracy= 0.8886\n",
            "epoch: 61, loss= 0.3136403053575133, training-set accuracy= 0.9117833333333333, dev-set accuracy= 0.9089\n",
            "epoch: 62, loss= 0.3171159063788498, training-set accuracy= 0.9107666666666666, dev-set accuracy= 0.9082\n",
            "epoch: 63, loss= 0.31249818241964883, training-set accuracy= 0.9112166666666667, dev-set accuracy= 0.9104\n",
            "epoch: 64, loss= 0.2994919789785732, training-set accuracy= 0.9148666666666667, dev-set accuracy= 0.9109\n",
            "epoch: 65, loss= 0.3056276446732808, training-set accuracy= 0.9122833333333333, dev-set accuracy= 0.9094\n",
            "epoch: 66, loss= 0.2930735816299154, training-set accuracy= 0.9172333333333333, dev-set accuracy= 0.9118\n",
            "epoch: 67, loss= 0.28819807388656005, training-set accuracy= 0.9177666666666666, dev-set accuracy= 0.9149\n",
            "epoch: 68, loss= 0.3045332786913414, training-set accuracy= 0.9116833333333333, dev-set accuracy= 0.9046\n",
            "epoch: 69, loss= 0.2908560196993214, training-set accuracy= 0.9172833333333333, dev-set accuracy= 0.9145\n",
            "epoch: 70, loss= 0.35682599608855614, training-set accuracy= 0.8909, dev-set accuracy= 0.8837\n",
            "epoch: 71, loss= 0.28275883544269265, training-set accuracy= 0.9193333333333333, dev-set accuracy= 0.9166\n",
            "epoch: 72, loss= 0.282216743414947, training-set accuracy= 0.9198666666666667, dev-set accuracy= 0.9144\n",
            "epoch: 73, loss= 0.27797916232514824, training-set accuracy= 0.9209833333333334, dev-set accuracy= 0.9171\n",
            "epoch: 74, loss= 0.27703106195664795, training-set accuracy= 0.9222, dev-set accuracy= 0.9176\n",
            "epoch: 75, loss= 0.2873347576289775, training-set accuracy= 0.9189, dev-set accuracy= 0.9119\n",
            "epoch: 76, loss= 0.2902748223407538, training-set accuracy= 0.914, dev-set accuracy= 0.9072\n",
            "epoch: 77, loss= 0.2684445263525797, training-set accuracy= 0.924, dev-set accuracy= 0.9205\n",
            "epoch: 78, loss= 0.2724743231968057, training-set accuracy= 0.92175, dev-set accuracy= 0.9158\n",
            "epoch: 79, loss= 0.2827180644594083, training-set accuracy= 0.91615, dev-set accuracy= 0.9094\n",
            "epoch: 80, loss= 0.27622343492511864, training-set accuracy= 0.92095, dev-set accuracy= 0.9162\n",
            "epoch: 81, loss= 0.2718943891586886, training-set accuracy= 0.9224, dev-set accuracy= 0.9153\n",
            "epoch: 82, loss= 0.2777997768397676, training-set accuracy= 0.91795, dev-set accuracy= 0.9112\n",
            "epoch: 83, loss= 0.27415692664228136, training-set accuracy= 0.9219833333333334, dev-set accuracy= 0.9153\n",
            "epoch: 84, loss= 0.2678339969991086, training-set accuracy= 0.92335, dev-set accuracy= 0.9155\n",
            "epoch: 85, loss= 0.25263190101766053, training-set accuracy= 0.9275333333333333, dev-set accuracy= 0.9208\n",
            "epoch: 86, loss= 0.2520077661952359, training-set accuracy= 0.92785, dev-set accuracy= 0.9209\n",
            "epoch: 87, loss= 0.2726193228704174, training-set accuracy= 0.9203666666666667, dev-set accuracy= 0.9133\n",
            "epoch: 88, loss= 0.2533115663607739, training-set accuracy= 0.92665, dev-set accuracy= 0.9188\n",
            "epoch: 89, loss= 0.2500844069997651, training-set accuracy= 0.9295, dev-set accuracy= 0.9223\n",
            "epoch: 90, loss= 0.2456618297265605, training-set accuracy= 0.9282833333333333, dev-set accuracy= 0.9204\n",
            "epoch: 91, loss= 0.24994518856949124, training-set accuracy= 0.9282666666666667, dev-set accuracy= 0.9217\n",
            "epoch: 92, loss= 0.27166800034161537, training-set accuracy= 0.9207166666666666, dev-set accuracy= 0.9124\n",
            "epoch: 93, loss= 0.25783429117896794, training-set accuracy= 0.9259666666666667, dev-set accuracy= 0.9204\n",
            "epoch: 94, loss= 0.2442036821421272, training-set accuracy= 0.9303833333333333, dev-set accuracy= 0.9238\n",
            "epoch: 95, loss= 0.23980849605787127, training-set accuracy= 0.9319, dev-set accuracy= 0.9234\n",
            "epoch: 96, loss= 0.2514621174425771, training-set accuracy= 0.9282833333333333, dev-set accuracy= 0.9186\n",
            "epoch: 97, loss= 0.24952563943915565, training-set accuracy= 0.92975, dev-set accuracy= 0.9232\n",
            "epoch: 98, loss= 0.2444735964805794, training-set accuracy= 0.9299833333333334, dev-set accuracy= 0.9205\n",
            "epoch: 99, loss= 0.23777456517437587, training-set accuracy= 0.93225, dev-set accuracy= 0.9239\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# np.savez('trained_model_params.npz', **weights, **biases)\n",
        "# data = np.load('trained_model_params.npz')"
      ],
      "metadata": {
        "id": "PDZUH2uAUaeD"
      },
      "execution_count": 331,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#visualize mnist\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_predictions(X, y, num_images=10):\n",
        "    num_samples = X.shape[0]\n",
        "    shuffled_indices = np.arange(num_samples)\n",
        "    np.random.shuffle(shuffled_indices)\n",
        "    X_shuffled = X[shuffled_indices]\n",
        "    y_shuffled = y[shuffled_indices]\n",
        "\n",
        "    random_picks = np.random.choice(np.arange(num_samples), size=num_images)\n",
        "\n",
        "    images = X_shuffled[random_picks]\n",
        "    labels = y_shuffled[random_picks]\n",
        "    predicted_labels = predict(images, weights, biases)\n",
        "    predicted_labels = np.argmax(predicted_labels, axis=1)\n",
        "    # print(images.shape)\n",
        "\n",
        "    fig, axes = plt.subplots(1, 10, figsize=(15,8))\n",
        "    for i in range(len(images)):\n",
        "        axes[i].imshow(images[i].reshape(28,28), cmap='gray')\n",
        "        axes[i].set_title(\"true: \" + str(labels[i]) + \"\\npredicted: \" + str(predicted_labels[i]))\n",
        "        axes[i].axis('off')\n",
        "\n",
        "plot_predictions(X_train_copy, y_train_copy)"
      ],
      "metadata": {
        "id": "U2S_jh2B9N5O",
        "outputId": "8336b5c1-ab9b-4c50-b863-92e150fc6fba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        }
      },
      "execution_count": 338,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1500x800 with 10 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import numpy as np\n",
        "# import matplotlib.pyplot as plt\n",
        "\n",
        "# h = 0.05\n",
        "# x_min, x_max = X[:,0].min() - 1, X[:,0].max() + 1\n",
        "# y_min, y_max = X[:,1].min() - 1, X[:,1].max() + 1\n",
        "\n",
        "# xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n",
        "#                      np.arange(y_min, y_max, h))\n",
        "\n",
        "# grid_points = np.c_[xx.ravel(), yy.ravel()]\n",
        "\n",
        "# preds = predict(grid_points, weights, biases)\n",
        "\n",
        "# Z = (preds > 0.5).astype(int)\n",
        "# Z = Z.reshape(xx.shape)\n",
        "\n",
        "\n",
        "# plt.figure(figsize=(8,6))\n",
        "# plt.contourf(xx, yy, Z, alpha=0.3, cmap=plt.cm.RdBu)\n",
        "\n",
        "# plt.scatter(class0_points[:, 0], class0_points[:, 1], c='blue', label='Class 0 (Inner)', alpha=0.7)\n",
        "# plt.scatter(class1_points[:, 0], class1_points[:, 1], c='red', label='Class 1 (Outer)', alpha=0.7)\n",
        "\n",
        "# plt.title(\"Decision Boundary\")\n",
        "# plt.xlabel(\"Feature 1\")\n",
        "# plt.ylabel(\"Feature 2\")\n",
        "# plt.legend()\n",
        "# plt.grid(True)\n",
        "# plt.gca().set_aspect('equal', adjustable='box')\n",
        "# plt.show()\n"
      ],
      "metadata": {
        "id": "yoUkunx185nD"
      },
      "execution_count": 333,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2BUbd2vyiFKN"
      },
      "execution_count": 333,
      "outputs": []
    }
  ]
}