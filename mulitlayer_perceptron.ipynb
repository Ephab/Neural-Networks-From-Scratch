{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "id": "pGGkE4BAep1f"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "np.set_printoptions(suppress=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# #Binary classification\n",
        "# import matplotlib.pyplot as plt\n",
        "\n",
        "# # random dataset\n",
        "\n",
        "# NUM_SAMPLES_PER_CLASS = 200\n",
        "# INNER_RADIUS = 2\n",
        "# OUTER_RADIUS = 5\n",
        "# NOISE_STD_DEV = 0.5\n",
        "\n",
        "# theta_inner = 2 * np.pi * np.random.rand(NUM_SAMPLES_PER_CLASS)\n",
        "\n",
        "# radius_inner = INNER_RADIUS * np.random.rand(NUM_SAMPLES_PER_CLASS) + np.random.normal(0, NOISE_STD_DEV, NUM_SAMPLES_PER_CLASS)\n",
        "# x0 = radius_inner * np.cos(theta_inner)\n",
        "# y0 = radius_inner * np.sin(theta_inner)\n",
        "# class0_points = np.vstack([x0, y0]).T\n",
        "# class0_labels = np.zeros(NUM_SAMPLES_PER_CLASS)\n",
        "\n",
        "# theta_outer = 2 * np.pi * np.random.rand(NUM_SAMPLES_PER_CLASS)\n",
        "\n",
        "# radius_outer = np.random.uniform(INNER_RADIUS + 1, OUTER_RADIUS, NUM_SAMPLES_PER_CLASS) + np.random.normal(0, NOISE_STD_DEV, NUM_SAMPLES_PER_CLASS)\n",
        "# x1 = radius_outer * np.cos(theta_outer)\n",
        "# y1 = radius_outer * np.sin(theta_outer)\n",
        "# class1_points = np.vstack([x1, y1]).T\n",
        "# class1_labels = np.ones(NUM_SAMPLES_PER_CLASS)\n",
        "\n",
        "\n",
        "# X = np.vstack([class0_points, class1_points])\n",
        "# y = np.hstack([class0_labels, class1_labels])\n",
        "# y = y.reshape(-1, 1) # stupid broadcasting bug that i spent an hour on -.-\n",
        "\n",
        "\n",
        "# plt.figure(figsize=(8, 6))\n",
        "\n",
        "# plt.scatter(class0_points[:, 0], class0_points[:, 1], c='blue', label='Class 0 (Inner)', alpha=0.7)\n",
        "\n",
        "# plt.scatter(class1_points[:, 0], class1_points[:, 1], c='red', label='Class 1 (Outer)', alpha=0.7)\n",
        "# plt.title('Concentric Rings Dataset')\n",
        "# plt.xlabel('Feature 1')\n",
        "# plt.ylabel('Feature 2')\n",
        "# plt.legend()\n",
        "# plt.grid(True)\n",
        "# plt.gca().set_aspect('equal', adjustable='box')\n",
        "# plt.show()"
      ],
      "metadata": {
        "id": "0Wsu6mPtfNcy"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Mnist dataset\n",
        "import copy\n",
        "from tensorflow.keras.datasets import mnist\n",
        "\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "\n",
        "X_train = (X_train.astype('float64') / 255.0).reshape(-1,28*28)\n",
        "X_test = (X_test.astype('float64') / 255.0).reshape(-1,28*28)\n",
        "\n",
        "X_test_copy = copy.deepcopy(X_test)\n",
        "y_test_copy = copy.deepcopy(y_test)\n",
        "\n",
        "X = X_train#[:2000,:]\n",
        "y = y_train.reshape(60000, -1)#[:2000,:]\n",
        "X_test = X_test#[:1000,:]\n",
        "y_test = y_test.reshape(-1,1)#[:1000, :]"
      ],
      "metadata": {
        "id": "_rV-2-fY5Ske"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X.shape, y.shape, X_test.shape, y_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Z1MPju7fNj6",
        "outputId": "2ddad12e-c08d-43bc-c5ad-8985e81281ac"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((60000, 784), (60000, 1), (10000, 784), (10000, 1))"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def one_hot_encoding(vector):\n",
        "    vector = np.array(vector).astype(int).flatten()\n",
        "    # if vector.ndim == 1:\n",
        "    #     return vector\n",
        "    size=len(vector)\n",
        "    num_classes = max(np.max(vector) + 1, 10)\n",
        "\n",
        "    encoded_matrix = np.zeros((size, num_classes))\n",
        "    encoded_matrix[np.arange(size), vector] = 1\n",
        "    return encoded_matrix"
      ],
      "metadata": {
        "id": "wsCbSo0pwQ_l"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_test_split(X, y, test_size=0.2):\n",
        "    num_samples = X.shape[0]\n",
        "    train_size = int(np.ceil(num_samples * (1-test_size)))\n",
        "    test_size = int(np.floor(num_samples * test_size))\n",
        "\n",
        "    shuffled_indices = np.arange(num_samples)\n",
        "    np.random.shuffle(shuffled_indices)\n",
        "    X = X[shuffled_indices]\n",
        "    y= y[shuffled_indices]\n",
        "\n",
        "    X_train = X[:train_size, :]\n",
        "    y_train = y[:train_size,]\n",
        "    X_test = X[train_size:]\n",
        "    y_test = y[train_size:]\n",
        "\n",
        "    return X_train, y_train, X_test, y_test"
      ],
      "metadata": {
        "id": "fQo6YdzuK3sk"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# X_train, y_train, X_test, y_test = train_test_split(X, y)"
      ],
      "metadata": {
        "id": "DTUH6FEGOrcz"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def initialize_weights_and_biases(m_inputs, layer_sizes:list, initialization='scaled'):\n",
        "    weights = {}\n",
        "    biases = {}\n",
        "\n",
        "    layers = [m_inputs] + layer_sizes\n",
        "\n",
        "    if initialization == 'scaled':\n",
        "        for i in range(len(layers)-1):\n",
        "            weights[\"W\" + str(i+1)] = np.random.randn(layers[i], layers[i+1]) * 0.01\n",
        "            biases[\"b\" + str(i+1)] = np.zeros((1, layers[i+1]))\n",
        "\n",
        "    elif initialization == 'xavier':\n",
        "        for i in range(len(layers)-1):\n",
        "            variance = 2 / (layers[i] + layers[i+1])\n",
        "            weights[\"W\" + str(i+1)] = np.random.randn(layers[i], layers[i+1]) * np.sqrt(variance)\n",
        "            biases[\"b\" + str(i+1)] = np.zeros((1, layers[i+1]))\n",
        "\n",
        "    elif initialization == 'he':\n",
        "        for i in range(len(layers)-1):\n",
        "            variance = 2 / (layers[i])\n",
        "            weights[\"W\" + str(i+1)] = np.random.randn(layers[i], layers[i+1]) * np.sqrt(variance)\n",
        "            biases[\"b\" + str(i+1)] = np.zeros((1, layers[i+1]))\n",
        "\n",
        "    else:\n",
        "        for i in range(len(layers)-1):\n",
        "            weights[\"W\" + str(i+1)] = np.random.randn(layers[i], layers[i+1])\n",
        "            biases[\"b\" + str(i+1)] = np.zeros((1, layers[i+1]))\n",
        "\n",
        "    # print(f\"Successfully initialized weights and biases for {len(layer_sizes)} layers\")\n",
        "    return weights, biases\n"
      ],
      "metadata": {
        "id": "pOIC9U5BfNo3"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sigmoid(z):\n",
        "    return 1 / (1 + np.exp(-z))\n",
        "\n",
        "def relu(z):\n",
        "    return np.maximum(0,z)\n",
        "\n",
        "def softmax(z):\n",
        "    exponent_values = np.exp(z - np.max(z, axis=1, keepdims=True))\n",
        "    return exponent_values / np.sum(exponent_values, axis=1, keepdims=True)"
      ],
      "metadata": {
        "id": "9NQVMamKbrlu"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def forward(A, weights, biases, activation_function, dropout=False, keep_prob=1):\n",
        "    Z_dict = {}\n",
        "    A_dict = {}\n",
        "    A_dict[\"A0\"] = A\n",
        "    l_dict = {}\n",
        "    dropouts = {}\n",
        "\n",
        "    if activation_function == 'relu':\n",
        "        activation_function = relu\n",
        "    else:\n",
        "        activation_function = sigmoid\n",
        "\n",
        "    for i in range(len(weights)-1): #loop through hidden layers\n",
        "        a_prev = A\n",
        "        Z = np.dot(a_prev, weights[\"W\" + str(i+1)]) + biases[\"b\" + str(i+1)]\n",
        "        Z_dict[\"Z\" + str(i+1)] = Z\n",
        "        A = activation_function(Z)\n",
        "\n",
        "        if dropout == True:\n",
        "            dropout_mask = (np.random.rand(A.shape[0], A.shape[1]) < keep_prob).astype(int)\n",
        "            A *= dropout_mask\n",
        "            A /= keep_prob\n",
        "            dropouts['A' + str(i+1)] = dropout_mask\n",
        "\n",
        "        A_dict[\"A\" + str(i+1)] = A\n",
        "        l_dict['layer' + str(i+1)] = activation_function.__name__\n",
        "\n",
        "    last_index = len(weights)\n",
        "\n",
        "    if weights[list(weights.keys())[-1]].shape[1] == 1:\n",
        "        output_activation = sigmoid\n",
        "    else:\n",
        "        output_activation = softmax\n",
        "\n",
        "    a_prev = A\n",
        "    Z = np.dot(a_prev, weights[\"W\" + str(last_index)]) + biases[\"b\" + str(last_index)]\n",
        "    Z_dict[\"Z\" + str(last_index)] = Z\n",
        "    A = output_activation(Z)\n",
        "    A_dict[\"A\" + str(last_index)] = A\n",
        "    l_dict['layer' + str(last_index)] = output_activation.__name__\n",
        "\n",
        "\n",
        "    dropouts['keep_prob'] = keep_prob\n",
        "\n",
        "    cache = {\"Z\":Z_dict,\n",
        "             \"A\":A_dict,\n",
        "             'layer_activations':l_dict,\n",
        "             'dropouts' : dropouts}\n",
        "\n",
        "    # print(\"Successfully computed a forward pass\")\n",
        "    return cache"
      ],
      "metadata": {
        "id": "A_sdeVp1fNq3"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_loss(y_pred, y_true, weights, loss='binary_cross_entropy', regularization='l2', reg_lambda=0):\n",
        "    epsilon = 1e-8\n",
        "    num_samples = y_pred.shape[0]\n",
        "    weight_loss = 0\n",
        "\n",
        "    if regularization == 'l2':\n",
        "        weight_loss = (reg_lambda / (2*num_samples))* np.sum([np.sum(weight ** 2) for _, weight in weights.items()])\n",
        "\n",
        "    if loss == 'cross_entropy':\n",
        "        return - np.mean(np.sum(y_true * np.log(y_pred + epsilon), axis=1)) + weight_loss\n",
        "    else:\n",
        "        return - np.mean(y_true * np.log(y_pred + epsilon) + (1-y_true)*np.log(1-y_pred + epsilon)) + weight_loss # added 1e-8 to avoid log(0)"
      ],
      "metadata": {
        "id": "11iGNgXdoPaN"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sigmoid_derivative(z):\n",
        "    s = sigmoid(z)\n",
        "    return s * (1 - s)\n",
        "\n",
        "def relu_derivative(z):\n",
        "    return (z > 0).astype(float)"
      ],
      "metadata": {
        "id": "Cpa39xURvtTr"
      },
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def backpropagation(X, y, weights, biases, cache, regularization=None, reg_lambda=0, dropout=False):\n",
        "\n",
        "    activation_derivative = sigmoid_derivative\n",
        "\n",
        "    A_cache = cache['A']\n",
        "    Z_cache = cache['Z']\n",
        "    L_cache = cache['layer_activations']\n",
        "    dropouts = cache['dropouts']\n",
        "    keep_prob = dropouts['keep_prob']\n",
        "\n",
        "    Z_gradients = {}\n",
        "    A_gradients = {}\n",
        "    W_gradients = {}\n",
        "    b_gradients = {}\n",
        "\n",
        "    m = X.shape[0]\n",
        "\n",
        "    for i in reversed(range(len(weights))):\n",
        "        if L_cache['layer' + str(i+1)] == 'relu':\n",
        "            activation_derivative = relu_derivative\n",
        "        if L_cache['layer' + str(i+1)] == 'sigmoid':\n",
        "            activation_derivative = sigmoid_derivative\n",
        "\n",
        "\n",
        "        if i+1 == len(weights): #special case for first dZ\n",
        "            dZ = A_cache[\"A\" + str(i+1)] - y\n",
        "            Z_gradients[\"dZ\" + str(i+1)] = dZ\n",
        "            W_gradients[\"dW\" + str(i+1)] = np.dot(A_cache[\"A\" + str(i)].T,dZ) / m\n",
        "            b_gradients[\"db\" + str(i+1)] = np.sum(dZ, axis=0, keepdims=True) / m\n",
        "\n",
        "            #adding regularization gradient\n",
        "            if regularization == 'l2':\n",
        "                W_gradients[\"dW\" + str(i+1)] += (reg_lambda / m) * weights['W' + str(i+1)]\n",
        "\n",
        "        else: #hidden layers\n",
        "\n",
        "            dZ = np.dot(Z_gradients[\"dZ\" + str(i+2)], weights[\"W\" + str(i+2)].T) * activation_derivative(Z_cache[\"Z\" + str(i+1)])\n",
        "\n",
        "            if dropout == True:\n",
        "                if 'A' + str(i+1) in dropouts:\n",
        "                    dZ *= dropouts['A' + str(i+1)]\n",
        "                    dZ /= keep_prob\n",
        "\n",
        "            Z_gradients[\"dZ\" + str(i+1)] = dZ\n",
        "            W_gradients[\"dW\" + str(i+1)] = np.dot(A_cache[\"A\" + str(i)].T, dZ) / m\n",
        "            b_gradients[\"db\" + str(i+1)] = np.sum(dZ, axis=0, keepdims=True) / m\n",
        "\n",
        "\n",
        "            #adding regularization gradient\n",
        "            if regularization == 'l2':\n",
        "                W_gradients[\"dW\" + str(i+1)] += (reg_lambda / m) * weights['W' + str(i+1)]\n",
        "\n",
        "        # print(f\"Layer {i+1} dW magnitude: {np.linalg.norm(W_gradients['dW' + str(i+1)])}\")\n",
        "        # print(f\"Layer {i+1} db magnitude: {np.linalg.norm(b_gradients['db' + str(i+1)])}\")\n",
        "\n",
        "    grads = {\"dW\" : W_gradients,\n",
        "             \"db\" : b_gradients}\n",
        "\n",
        "    return grads"
      ],
      "metadata": {
        "id": "oBO-AJcSpSct"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "weights, biases = initialize_weights_and_biases(m_inputs=784, layer_sizes=[256, 10], initialization='he')"
      ],
      "metadata": {
        "id": "h6yc6ghG8j84"
      },
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Vdw = {}\n",
        "Vdb = {}\n",
        "Sdw = {}\n",
        "Sdb = {}\n",
        "Vdw_corrected = {}\n",
        "Vdb_corrected = {}\n",
        "Sdw_corrected = {}\n",
        "Sdb_corrected = {}\n",
        "\n",
        "t = 1\n",
        "\n",
        "for i in range(len(weights)):\n",
        "    Vdw['w' + str(i+1)] = np.zeros_like(weights['W' + str(i+1)])\n",
        "    Vdb['b' + str(i+1)] = np.zeros_like(biases['b' + str(i+1)])\n",
        "\n",
        "    Sdw['w' + str(i+1)] = np.zeros_like(weights['W' + str(i+1)])\n",
        "    Sdb['b' + str(i+1)] = np.zeros_like(biases['b' + str(i+1)])\n",
        "\n",
        "\n",
        "def update_params(grads, weights, biases, learning_rate, optimizer='gd', beta1=0.9, beta2=0.999, epsilon=1e-8):\n",
        "\n",
        "    dw = grads['dW']\n",
        "    db = grads['db']\n",
        "\n",
        "    global t\n",
        "\n",
        "    if optimizer == 'momentum':\n",
        "      for i in range(len(weights)):\n",
        "        Vdw['w' + str(i+1)] = beta1 * Vdw['w' + str(i+1)] + ((1-beta1) * dw['dW' + str(i+1)])\n",
        "        weights[\"W\" + str(i+1)] = weights[\"W\" + str(i+1)] - learning_rate * Vdw['w' + str(i+1)]\n",
        "\n",
        "        Vdb['b' + str(i+1)] = beta1 * Vdb['b' + str(i+1)] + ((1-beta1) * db[\"db\" + str(i+1)])\n",
        "        biases[\"b\" + str(i+1)] = biases[\"b\" + str(i+1)] - learning_rate * Vdb['b' + str(i+1)]\n",
        "\n",
        "    elif optimizer == 'rmsprop':\n",
        "        for i in range(len(weights)):\n",
        "            Sdw['w' + str(i+1)] = beta2 * Sdw['w' + str(i+1)] + ((1-beta2) * (dw['dW' + str(i+1)])**2)\n",
        "            weights[\"W\" + str(i+1)] = weights[\"W\" + str(i+1)] - learning_rate * ((dw['dW' + str(i+1)])/(np.sqrt(Sdw['w' + str(i+1)] + epsilon)))\n",
        "\n",
        "            # print(np.sqrt(Sdw['w1'] + epsilon))\n",
        "\n",
        "            Sdb['b' + str(i+1)] = beta2 * Sdb['b' + str(i+1)] + ((1-beta2) * (db['db' + str(i+1)])**2)\n",
        "            biases[\"b\" + str(i+1)] = biases[\"b\" + str(i+1)] - learning_rate * ((db['db' + str(i+1)])/(np.sqrt(Sdb['b' + str(i+1)] + epsilon)))\n",
        "\n",
        "    elif optimizer == 'adam':\n",
        "        for i in range(len(weights)):\n",
        "            Vdw['w' + str(i+1)] = beta1 * Vdw['w' + str(i+1)] + ((1-beta1) * dw['dW' + str(i+1)])\n",
        "            Sdw['w' + str(i+1)] = beta2 * Sdw['w' + str(i+1)] + ((1-beta2) * (dw['dW' + str(i+1)])**2)\n",
        "\n",
        "            Vdb['b' + str(i+1)] = beta1 * Vdb['b' + str(i+1)] + ((1-beta1) * db[\"db\" + str(i+1)])\n",
        "            Sdb['b' + str(i+1)] = beta2 * Sdb['b' + str(i+1)] + ((1-beta2) * (db['db' + str(i+1)])**2)\n",
        "\n",
        "\n",
        "            #bias correction\n",
        "            Vdw_corrected['w' + str(i+1)] = Vdw['w' + str(i+1)] / (1-beta1**t)\n",
        "            Vdb_corrected['b' + str(i+1)] = Vdb['b' + str(i+1)] / (1-beta1**t)\n",
        "\n",
        "            Sdw_corrected['w' + str(i+1)] = Sdw['w' + str(i+1)] / (1-beta2**t)\n",
        "            Sdb_corrected['b' + str(i+1)] = Sdb['b' + str(i+1)] / (1-beta2**t)\n",
        "\n",
        "\n",
        "            weights[\"W\" + str(i+1)] = weights[\"W\" + str(i+1)] - learning_rate * (Vdw_corrected['w' + str(i+1)] / np.sqrt(Sdw_corrected['w' + str(i+1)] + epsilon))\n",
        "            biases['b' + str(i+1)] = biases['b' + str(i+1)] - learning_rate * (Vdb_corrected['b' + str(i+1)] / np.sqrt(Sdb_corrected['b' + str(i+1)] + epsilon))\n",
        "\n",
        "        t += 1\n",
        "\n",
        "    else: #normal gd\n",
        "        for i in range(len(weights)):\n",
        "            weights[\"W\" + str(i+1)] = weights[\"W\" + str(i+1)] - learning_rate * dw[\"dW\" + str(i+1)]\n",
        "            biases[\"b\" + str(i+1)] = biases[\"b\" + str(i+1)] - learning_rate * db[\"db\" + str(i+1)]\n",
        "\n",
        "    # print(\"Successfully updated params\")\n",
        "    return weights, biases"
      ],
      "metadata": {
        "id": "djF7hwUtxlyr"
      },
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(X, weights, biases):\n",
        "    cache = forward(X, weights, biases, activation_function='relu', dropout=False)\n",
        "    prediction = cache['A'][list(cache['A'].keys())[-1]]\n",
        "    return prediction"
      ],
      "metadata": {
        "id": "uLU5V7b0y80T"
      },
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if len(np.unique(y)) > 2:\n",
        "    y = one_hot_encoding(y)\n",
        "    y_test = one_hot_encoding(y_test)\n",
        "    classification_type = 'multi'\n",
        "else:\n",
        "    classification_type = 'single'\n",
        "\n",
        "\n",
        "def accuracy(prediction, labels):\n",
        "    total = len(labels)\n",
        "\n",
        "    if classification_type == 'single':\n",
        "        acc = np.sum((prediction > 0.5).astype(int) == labels) / total\n",
        "    else:\n",
        "        predicted_class = np.argmax(prediction, axis=1)\n",
        "        true_class = np.argmax(labels, axis=1)\n",
        "        acc = np.mean(predicted_class == true_class)\n",
        "    return acc\n"
      ],
      "metadata": {
        "id": "YAN6QKh0HlhD"
      },
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run(epochs, learning_rate, optimizer='gd', beta1=0.9, beta2=0.999, regularization='l2', reg_lambda=0, dropout=False, keep_prob=1):\n",
        "\n",
        "    for i in range(epochs):\n",
        "        cache = forward(X, weights, biases, activation_function='relu', dropout=dropout, keep_prob=keep_prob)\n",
        "        prediction = cache['A'][list(cache['A'].keys())[-1]]\n",
        "        grads = backpropagation(X, y, weights, biases, cache, regularization=regularization, reg_lambda=reg_lambda, dropout=dropout)\n",
        "\n",
        "        if i % 100 == 0:\n",
        "            dev_predictions = predict(X_test, weights, biases)\n",
        "            print(f\"epoch: {i}, loss= {calculate_loss(prediction, y, loss='cross_entropy' if classification_type=='multi' else 'binary_cross_entropy', weights=weights, regularization=regularization, reg_lambda=reg_lambda)}, training-set accuracy= {accuracy(prediction, y)}, dev-set accuracy= {accuracy(dev_predictions, y_test)}\")\n",
        "\n",
        "        update_params(grads, weights, biases, learning_rate, optimizer=optimizer, beta1=beta1, beta2=beta2)"
      ],
      "metadata": {
        "id": "bE-obYbZv2Lb"
      },
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run_mini_batches(epochs, learning_rate, mini_batch_size=64, optimizer='gd', beta1=0.9, beta2=0.999, regularization='l2', reg_lambda=0, dropout=False, keep_prob=1):\n",
        "\n",
        "    num_samples = X.shape[0]\n",
        "    div = int(num_samples / mini_batch_size)\n",
        "\n",
        "    divisible_by_mini_batch_size = mini_batch_size * div\n",
        "    not_divisible = num_samples - divisible_by_mini_batch_size\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        shuffled_indices = np.arange(num_samples)\n",
        "        np.random.shuffle(shuffled_indices)\n",
        "        X_shuffled = X[shuffled_indices]\n",
        "        y_shuffled = y[shuffled_indices]\n",
        "\n",
        "        start = 0\n",
        "        end = 0\n",
        "        for batch in range(start, divisible_by_mini_batch_size, mini_batch_size):\n",
        "            start = end\n",
        "            end = start + mini_batch_size\n",
        "            X_batch = X_shuffled[start:end, :]\n",
        "            y_batch = y_shuffled[start:end]\n",
        "\n",
        "            #forward\n",
        "            cache = forward(X_batch, weights, biases, activation_function='relu', dropout=dropout, keep_prob=keep_prob)\n",
        "            prediction = cache['A'][list(cache['A'].keys())[-1]]\n",
        "            #backward\n",
        "            grads = backpropagation(X_batch, y_batch, weights, biases, cache, regularization=regularization, reg_lambda=reg_lambda, dropout=dropout)\n",
        "            #update\n",
        "            update_params(grads, weights, biases, learning_rate, optimizer=optimizer, beta1=beta1, beta2=beta2)\n",
        "\n",
        "        if not_divisible != 0:\n",
        "            X_batch = X_shuffled[divisible_by_mini_batch_size:, :]\n",
        "            y_batch = y_shuffled[divisible_by_mini_batch_size:]\n",
        "            #forward\n",
        "            cache = forward(X_batch, weights, biases, activation_function='relu', dropout=dropout, keep_prob=keep_prob)\n",
        "            prediction = cache['A'][list(cache['A'].keys())[-1]]\n",
        "            #backward\n",
        "            grads = backpropagation(X_batch, y_batch, weights, biases, cache, regularization=regularization, reg_lambda=reg_lambda, dropout=dropout)\n",
        "            #update\n",
        "            update_params(grads, weights, biases, learning_rate, optimizer=optimizer, beta1=beta1, beta2=beta2)\n",
        "\n",
        "        cache = forward(X, weights, biases, activation_function='relu', dropout=False)\n",
        "        full_prediction = cache['A'][list(cache['A'].keys())[-1]]\n",
        "        dev_predictions = predict(X_test, weights, biases)\n",
        "        print(f\"epoch: {epoch+1}, loss= {calculate_loss(full_prediction, y, loss='cross_entropy' if classification_type=='multi' else 'binary_cross_entropy', weights=weights, regularization=regularization, reg_lambda=reg_lambda)}, training-set accuracy= {accuracy(full_prediction, y)}, dev-set accuracy= {accuracy(dev_predictions, y_test)}\")\n"
      ],
      "metadata": {
        "id": "AgzrO6SZBrIw"
      },
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# run(epochs=10000, learning_rate=0.005)"
      ],
      "metadata": {
        "id": "4oMThHvuwDdK"
      },
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "run_mini_batches(epochs=10, learning_rate=0.00001, mini_batch_size=50, optimizer='adam', beta1=0.9, beta2=0.999, regularization='l2', reg_lambda=0.01, keep_prob=0.7, dropout=True)"
      ],
      "metadata": {
        "id": "zq_460UVTJVT",
        "outputId": "e58c39bb-ee29-4656-e649-26a94109bea0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 1, loss= 0.019661775371994587, training-set accuracy= 0.9966166666666667, dev-set accuracy= 0.9828\n",
            "epoch: 2, loss= 0.019577805651213153, training-set accuracy= 0.9966833333333334, dev-set accuracy= 0.9829\n",
            "epoch: 3, loss= 0.019489109802477988, training-set accuracy= 0.99675, dev-set accuracy= 0.9829\n",
            "epoch: 4, loss= 0.019458703983269585, training-set accuracy= 0.9967, dev-set accuracy= 0.9829\n",
            "epoch: 5, loss= 0.01941740585943245, training-set accuracy= 0.9966666666666667, dev-set accuracy= 0.9829\n",
            "epoch: 6, loss= 0.01935014863680289, training-set accuracy= 0.9968166666666667, dev-set accuracy= 0.9829\n",
            "epoch: 7, loss= 0.019308560376419655, training-set accuracy= 0.9968333333333333, dev-set accuracy= 0.9825\n",
            "epoch: 8, loss= 0.019354363691217638, training-set accuracy= 0.9968166666666667, dev-set accuracy= 0.9827\n",
            "epoch: 9, loss= 0.01931568254416756, training-set accuracy= 0.9968666666666667, dev-set accuracy= 0.9826\n",
            "epoch: 10, loss= 0.019312067393065197, training-set accuracy= 0.9967833333333334, dev-set accuracy= 0.983\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "A1 = forward(X_test, weights, biases, activation_function='relu')['A']['A1']\n",
        "print(f\"A2 variance = {np.var(A1)}\")"
      ],
      "metadata": {
        "id": "4dm8WTHgItOn",
        "outputId": "d6f2d75f-33c5-4258-f524-44a4d62da0c6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A2 variance = 0.27516191825917924\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# np.savez('best_trained_model_params[32,16,10].npz', **weights, **biases)\n",
        "# data = np.load('trained_model_params.npz')"
      ],
      "metadata": {
        "id": "PDZUH2uAUaeD"
      },
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#visualize mnist\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_predictions(X, y, num_images=10):\n",
        "    num_samples = X.shape[0]\n",
        "    shuffled_indices = np.arange(num_samples)\n",
        "    np.random.shuffle(shuffled_indices)\n",
        "    X_shuffled = X[shuffled_indices]\n",
        "    y_shuffled = y[shuffled_indices]\n",
        "\n",
        "    random_picks = np.random.choice(np.arange(num_samples), size=num_images)\n",
        "\n",
        "    images = X_shuffled[random_picks]\n",
        "    labels = y_shuffled[random_picks]\n",
        "    predictions_probability_distribution = predict(images, weights, biases)\n",
        "    predicted_labels = np.argmax(predictions_probability_distribution, axis=1)\n",
        "\n",
        "\n",
        "    fig, axes = plt.subplots(2, num_images, figsize=(20,6))\n",
        "    for i in range(len(images)):\n",
        "        axes[0,i].imshow(images[i].reshape(28,28), cmap='gray')\n",
        "        axes[0,i].set_title(\"true: \" + str(labels[i]) + \"\\npredicted: \" + str(predicted_labels[i]))\n",
        "        axes[0,i].axis('off')\n",
        "        axes[1,i].bar(x=np.arange(10), height=predictions_probability_distribution[i])\n",
        "        axes[1,i].set_ylim(0,1)\n",
        "        axes[1,i].set_xticks(np.arange(10))\n",
        "\n",
        "plot_predictions(X_test_copy, y_test_copy, num_images=5)"
      ],
      "metadata": {
        "id": "U2S_jh2B9N5O",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "c773ee9d-4c83-44c1-b968-725735cdc992"
      },
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 2000x600 with 10 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import numpy as np\n",
        "# import matplotlib.pyplot as plt\n",
        "\n",
        "# h = 0.05\n",
        "# x_min, x_max = X[:,0].min() - 1, X[:,0].max() + 1\n",
        "# y_min, y_max = X[:,1].min() - 1, X[:,1].max() + 1\n",
        "\n",
        "# xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n",
        "#                      np.arange(y_min, y_max, h))\n",
        "\n",
        "# grid_points = np.c_[xx.ravel(), yy.ravel()]\n",
        "\n",
        "# preds = predict(grid_points, weights, biases)\n",
        "\n",
        "# Z = (preds > 0.5).astype(int)\n",
        "# Z = Z.reshape(xx.shape)\n",
        "\n",
        "\n",
        "# plt.figure(figsize=(8,6))\n",
        "# plt.contourf(xx, yy, Z, alpha=0.3, cmap=plt.cm.RdBu)\n",
        "\n",
        "# plt.scatter(class0_points[:, 0], class0_points[:, 1], c='blue', label='Class 0 (Inner)', alpha=0.7)\n",
        "# plt.scatter(class1_points[:, 0], class1_points[:, 1], c='red', label='Class 1 (Outer)', alpha=0.7)\n",
        "\n",
        "# plt.title(\"Decision Boundary\")\n",
        "# plt.xlabel(\"Feature 1\")\n",
        "# plt.ylabel(\"Feature 2\")\n",
        "# plt.legend()\n",
        "# plt.grid(True)\n",
        "# plt.gca().set_aspect('equal', adjustable='box')\n",
        "# plt.show()\n"
      ],
      "metadata": {
        "id": "yoUkunx185nD"
      },
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2BUbd2vyiFKN"
      },
      "execution_count": 97,
      "outputs": []
    }
  ]
}