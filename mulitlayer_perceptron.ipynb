{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 389,
      "metadata": {
        "id": "pGGkE4BAep1f"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "np.set_printoptions(suppress=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# #Binary classification\n",
        "# import matplotlib.pyplot as plt\n",
        "\n",
        "# # random dataset\n",
        "\n",
        "# NUM_SAMPLES_PER_CLASS = 200\n",
        "# INNER_RADIUS = 2\n",
        "# OUTER_RADIUS = 5\n",
        "# NOISE_STD_DEV = 0.5\n",
        "\n",
        "# theta_inner = 2 * np.pi * np.random.rand(NUM_SAMPLES_PER_CLASS)\n",
        "\n",
        "# radius_inner = INNER_RADIUS * np.random.rand(NUM_SAMPLES_PER_CLASS) + np.random.normal(0, NOISE_STD_DEV, NUM_SAMPLES_PER_CLASS)\n",
        "# x0 = radius_inner * np.cos(theta_inner)\n",
        "# y0 = radius_inner * np.sin(theta_inner)\n",
        "# class0_points = np.vstack([x0, y0]).T\n",
        "# class0_labels = np.zeros(NUM_SAMPLES_PER_CLASS)\n",
        "\n",
        "# theta_outer = 2 * np.pi * np.random.rand(NUM_SAMPLES_PER_CLASS)\n",
        "\n",
        "# radius_outer = np.random.uniform(INNER_RADIUS + 1, OUTER_RADIUS, NUM_SAMPLES_PER_CLASS) + np.random.normal(0, NOISE_STD_DEV, NUM_SAMPLES_PER_CLASS)\n",
        "# x1 = radius_outer * np.cos(theta_outer)\n",
        "# y1 = radius_outer * np.sin(theta_outer)\n",
        "# class1_points = np.vstack([x1, y1]).T\n",
        "# class1_labels = np.ones(NUM_SAMPLES_PER_CLASS)\n",
        "\n",
        "\n",
        "# X = np.vstack([class0_points, class1_points])\n",
        "# y = np.hstack([class0_labels, class1_labels])\n",
        "# y = y.reshape(-1, 1) # stupid broadcasting bug that i spent an hour on -.-\n",
        "\n",
        "\n",
        "# plt.figure(figsize=(8, 6))\n",
        "\n",
        "# plt.scatter(class0_points[:, 0], class0_points[:, 1], c='blue', label='Class 0 (Inner)', alpha=0.7)\n",
        "\n",
        "# plt.scatter(class1_points[:, 0], class1_points[:, 1], c='red', label='Class 1 (Outer)', alpha=0.7)\n",
        "# plt.title('Concentric Rings Dataset')\n",
        "# plt.xlabel('Feature 1')\n",
        "# plt.ylabel('Feature 2')\n",
        "# plt.legend()\n",
        "# plt.grid(True)\n",
        "# plt.gca().set_aspect('equal', adjustable='box')\n",
        "# plt.show()"
      ],
      "metadata": {
        "id": "0Wsu6mPtfNcy"
      },
      "execution_count": 390,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Mnist dataset\n",
        "import copy\n",
        "from tensorflow.keras.datasets import mnist\n",
        "\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "\n",
        "X_train = (X_train.astype('float64') / 255.0).reshape(-1,28*28)\n",
        "X_test = (X_test.astype('float64') / 255.0).reshape(-1,28*28)\n",
        "\n",
        "X_test_copy = copy.deepcopy(X_test)\n",
        "y_test_copy = copy.deepcopy(y_test)\n",
        "\n",
        "X = X_train#[:2000,:]\n",
        "y = y_train.reshape(60000, -1)#[:2000,:]\n",
        "X_test = X_test#[:1000,:]\n",
        "y_test = y_test.reshape(-1,1)#[:1000, :]"
      ],
      "metadata": {
        "id": "_rV-2-fY5Ske"
      },
      "execution_count": 391,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X.shape, y.shape, X_test.shape, y_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Z1MPju7fNj6",
        "outputId": "ac2950a8-f054-4d8b-fead-c14749ac6844"
      },
      "execution_count": 392,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((60000, 784), (60000, 1), (10000, 784), (10000, 1))"
            ]
          },
          "metadata": {},
          "execution_count": 392
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def one_hot_encoding(vector):\n",
        "    vector = np.array(vector).astype(int).flatten()\n",
        "    # if vector.ndim == 1:\n",
        "    #     return vector\n",
        "    size=len(vector)\n",
        "    num_classes = max(np.max(vector) + 1, 10)\n",
        "\n",
        "    encoded_matrix = np.zeros((size, num_classes))\n",
        "    encoded_matrix[np.arange(size), vector] = 1\n",
        "    return encoded_matrix"
      ],
      "metadata": {
        "id": "wsCbSo0pwQ_l"
      },
      "execution_count": 393,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_test_split(X, y, test_size=0.2):\n",
        "    num_samples = X.shape[0]\n",
        "    train_size = int(np.ceil(num_samples * (1-test_size)))\n",
        "    test_size = int(np.floor(num_samples * test_size))\n",
        "\n",
        "    shuffled_indices = np.arange(num_samples)\n",
        "    np.random.shuffle(shuffled_indices)\n",
        "    X = X[shuffled_indices]\n",
        "    y= y[shuffled_indices]\n",
        "\n",
        "    X_train = X[:train_size, :]\n",
        "    y_train = y[:train_size,]\n",
        "    X_test = X[train_size:]\n",
        "    y_test = y[train_size:]\n",
        "\n",
        "    return X_train, y_train, X_test, y_test"
      ],
      "metadata": {
        "id": "fQo6YdzuK3sk"
      },
      "execution_count": 394,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# X_train, y_train, X_test, y_test = train_test_split(X, y)"
      ],
      "metadata": {
        "id": "DTUH6FEGOrcz"
      },
      "execution_count": 395,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def initialize_weights_and_biases(m_inputs, layer_sizes:list, initialization='scaled'):\n",
        "    weights = {}\n",
        "    biases = {}\n",
        "\n",
        "    layers = [m_inputs] + layer_sizes\n",
        "\n",
        "    if initialization == 'scaled':\n",
        "        for i in range(len(layers)-1):\n",
        "            weights[\"W\" + str(i+1)] = np.random.randn(layers[i], layers[i+1]) * 0.01\n",
        "            biases[\"b\" + str(i+1)] = np.zeros((1, layers[i+1]))\n",
        "\n",
        "    elif initialization == 'xavier':\n",
        "        for i in range(len(layers)-1):\n",
        "            variance = 2 / (layers[i] + layers[i+1])\n",
        "            weights[\"W\" + str(i+1)] = np.random.randn(layers[i], layers[i+1]) * np.sqrt(variance)\n",
        "            biases[\"b\" + str(i+1)] = np.zeros((1, layers[i+1]))\n",
        "\n",
        "    elif initialization == 'he':\n",
        "        for i in range(len(layers)-1):\n",
        "            variance = 2 / (layers[i])\n",
        "            weights[\"W\" + str(i+1)] = np.random.randn(layers[i], layers[i+1]) * np.sqrt(variance)\n",
        "            biases[\"b\" + str(i+1)] = np.zeros((1, layers[i+1]))\n",
        "\n",
        "    else:\n",
        "        for i in range(len(layers)-1):\n",
        "            weights[\"W\" + str(i+1)] = np.random.randn(layers[i], layers[i+1])\n",
        "            biases[\"b\" + str(i+1)] = np.zeros((1, layers[i+1]))\n",
        "\n",
        "    # print(f\"Successfully initialized weights and biases for {len(layer_sizes)} layers\")\n",
        "    return weights, biases\n"
      ],
      "metadata": {
        "id": "pOIC9U5BfNo3"
      },
      "execution_count": 396,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sigmoid(z):\n",
        "    return 1 / (1 + np.exp(-z))\n",
        "\n",
        "def relu(z):\n",
        "    return np.maximum(0,z)\n",
        "\n",
        "def softmax(z):\n",
        "    exponent_values = np.exp(z - np.max(z, axis=1, keepdims=True))\n",
        "    return exponent_values / np.sum(exponent_values, axis=1, keepdims=True)"
      ],
      "metadata": {
        "id": "9NQVMamKbrlu"
      },
      "execution_count": 397,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def forward(A, weights, biases, activation_function):\n",
        "    Z_dict = {}\n",
        "    A_dict = {}\n",
        "    A_dict[\"A0\"] = A\n",
        "    l_dict = {}\n",
        "\n",
        "    if activation_function == 'relu':\n",
        "        activation_function = relu\n",
        "    else:\n",
        "        activation_function = sigmoid\n",
        "\n",
        "\n",
        "    for i in range(len(weights)-1): #loop through hidden layers\n",
        "        a_prev = A\n",
        "        Z = np.dot(a_prev, weights[\"W\" + str(i+1)]) + biases[\"b\" + str(i+1)]\n",
        "        Z_dict[\"Z\" + str(i+1)] = Z\n",
        "        A = activation_function(Z)\n",
        "        A_dict[\"A\" + str(i+1)] = A\n",
        "        l_dict['layer' + str(i+1)] = activation_function.__name__\n",
        "\n",
        "    last_index = len(weights)\n",
        "\n",
        "    if weights[list(weights.keys())[-1]].shape[1] == 1:\n",
        "        output_activation = sigmoid\n",
        "    else:\n",
        "        output_activation = softmax\n",
        "\n",
        "    a_prev = A\n",
        "    Z = np.dot(a_prev, weights[\"W\" + str(last_index)]) + biases[\"b\" + str(last_index)]\n",
        "    Z_dict[\"Z\" + str(last_index)] = Z\n",
        "    A = output_activation(Z)\n",
        "    A_dict[\"A\" + str(last_index)] = A\n",
        "    l_dict['layer' + str(last_index)] = output_activation.__name__\n",
        "\n",
        "\n",
        "    cache = {\"Z\":Z_dict,\n",
        "             \"A\":A_dict,\n",
        "             'layer_activations':l_dict}\n",
        "\n",
        "    # print(\"Successfully computed a forward pass\")\n",
        "    return cache"
      ],
      "metadata": {
        "id": "A_sdeVp1fNq3"
      },
      "execution_count": 398,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_loss(y_pred, y_true, loss='binary_cross_entropy'):\n",
        "    epsilon = 1e-8\n",
        "\n",
        "    if loss == 'cross_entropy':\n",
        "        return - np.mean(np.sum(y_true * np.log(y_pred + epsilon), axis=1))\n",
        "    else:\n",
        "        return - np.mean(y_true * np.log(y_pred + epsilon) + (1-y_true)*np.log(1-y_pred + epsilon)) # added 1e-8 to avoid log(0)"
      ],
      "metadata": {
        "id": "11iGNgXdoPaN"
      },
      "execution_count": 399,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sigmoid_derivative(z):\n",
        "    s = sigmoid(z)\n",
        "    return s * (1 - s)\n",
        "\n",
        "def relu_derivative(z):\n",
        "    return (z > 0).astype(float)"
      ],
      "metadata": {
        "id": "Cpa39xURvtTr"
      },
      "execution_count": 400,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def backpropagation(X, y, weights, biases, cache):\n",
        "\n",
        "    activation_derivative = sigmoid_derivative\n",
        "\n",
        "    A_cache = cache['A']\n",
        "    Z_cache = cache['Z']\n",
        "    L_cache = cache['layer_activations']\n",
        "\n",
        "    Z_gradients = {}\n",
        "    A_gradients = {}\n",
        "    W_gradients = {}\n",
        "    b_gradients = {}\n",
        "\n",
        "    m = X.shape[0]\n",
        "\n",
        "    for i in reversed(range(len(weights))):\n",
        "        if L_cache['layer' + str(i+1)] == 'relu':\n",
        "            activation_derivative = relu_derivative\n",
        "        if L_cache['layer' + str(i+1)] == 'sigmoid':\n",
        "            activation_derivative = sigmoid_derivative\n",
        "\n",
        "\n",
        "        if i+1 == len(weights): #special case for first dZ\n",
        "            dZ = A_cache[\"A\" + str(i+1)] - y\n",
        "            Z_gradients[\"dZ\" + str(i+1)] = dZ\n",
        "            W_gradients[\"dW\" + str(i+1)] = np.dot(A_cache[\"A\" + str(i)].T,dZ) / m\n",
        "            b_gradients[\"db\" + str(i+1)] = np.sum(dZ, axis=0, keepdims=True) / m\n",
        "        else:\n",
        "            dZ = np.dot(Z_gradients[\"dZ\" + str(i+2)], weights[\"W\" + str(i+2)].T ) * activation_derivative(Z_cache[\"Z\" + str(i+1)])\n",
        "            Z_gradients[\"dZ\" + str(i+1)] = dZ\n",
        "            W_gradients[\"dW\" + str(i+1)] = np.dot(A_cache[\"A\" + str(i)].T,dZ) / m\n",
        "            b_gradients[\"db\" + str(i+1)] = np.sum(dZ, axis=0, keepdims=True) / m\n",
        "\n",
        "        # print(f\"Layer {i+1} dW magnitude: {np.linalg.norm(W_gradients['dW' + str(i+1)])}\")\n",
        "        # print(f\"Layer {i+1} db magnitude: {np.linalg.norm(b_gradients['db' + str(i+1)])}\")\n",
        "\n",
        "    grads = {\"dW\" : W_gradients,\n",
        "             \"db\" : b_gradients}\n",
        "\n",
        "    return grads"
      ],
      "metadata": {
        "id": "oBO-AJcSpSct"
      },
      "execution_count": 401,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "weights, biases = initialize_weights_and_biases(m_inputs=784, layer_sizes=[256, 10], initialization='he')"
      ],
      "metadata": {
        "id": "h6yc6ghG8j84"
      },
      "execution_count": 402,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Vdw = {}\n",
        "Vdb = {}\n",
        "Sdw = {}\n",
        "Sdb = {}\n",
        "Vdw_corrected = {}\n",
        "Vdb_corrected = {}\n",
        "Sdw_corrected = {}\n",
        "Sdb_corrected = {}\n",
        "\n",
        "t = 1\n",
        "\n",
        "for i in range(len(weights)):\n",
        "    Vdw['w' + str(i+1)] = np.zeros_like(weights['W' + str(i+1)])\n",
        "    Vdb['b' + str(i+1)] = np.zeros_like(biases['b' + str(i+1)])\n",
        "\n",
        "    Sdw['w' + str(i+1)] = np.zeros_like(weights['W' + str(i+1)])\n",
        "    Sdb['b' + str(i+1)] = np.zeros_like(biases['b' + str(i+1)])\n",
        "\n",
        "\n",
        "def update_params(grads, weights, biases, learning_rate, optimizer='gd', beta1=0.9, beta2=0.999, epsilon=1e-8):\n",
        "\n",
        "    dw = grads['dW']\n",
        "    db = grads['db']\n",
        "\n",
        "    global t\n",
        "\n",
        "    if optimizer == 'momentum':\n",
        "      for i in range(len(weights)):\n",
        "        Vdw['w' + str(i+1)] = beta1 * Vdw['w' + str(i+1)] + ((1-beta1) * dw['dW' + str(i+1)])\n",
        "        weights[\"W\" + str(i+1)] = weights[\"W\" + str(i+1)] - learning_rate * Vdw['w' + str(i+1)]\n",
        "\n",
        "        Vdb['b' + str(i+1)] = beta1 * Vdb['b' + str(i+1)] + ((1-beta1) * db[\"db\" + str(i+1)])\n",
        "        biases[\"b\" + str(i+1)] = biases[\"b\" + str(i+1)] - learning_rate * Vdb['b' + str(i+1)]\n",
        "\n",
        "    elif optimizer == 'rmsprop':\n",
        "        for i in range(len(weights)):\n",
        "            Sdw['w' + str(i+1)] = beta2 * Sdw['w' + str(i+1)] + ((1-beta2) * (dw['dW' + str(i+1)])**2)\n",
        "            weights[\"W\" + str(i+1)] = weights[\"W\" + str(i+1)] - learning_rate * ((dw['dW' + str(i+1)])/(np.sqrt(Sdw['w' + str(i+1)] + epsilon)))\n",
        "\n",
        "            # print(np.sqrt(Sdw['w1'] + epsilon))\n",
        "\n",
        "            Sdb['b' + str(i+1)] = beta2 * Sdb['b' + str(i+1)] + ((1-beta2) * (db['db' + str(i+1)])**2)\n",
        "            biases[\"b\" + str(i+1)] = biases[\"b\" + str(i+1)] - learning_rate * ((db['db' + str(i+1)])/(np.sqrt(Sdb['b' + str(i+1)] + epsilon)))\n",
        "\n",
        "    elif optimizer == 'adam':\n",
        "        for i in range(len(weights)):\n",
        "            Vdw['w' + str(i+1)] = beta1 * Vdw['w' + str(i+1)] + ((1-beta1) * dw['dW' + str(i+1)])\n",
        "            Sdw['w' + str(i+1)] = beta2 * Sdw['w' + str(i+1)] + ((1-beta2) * (dw['dW' + str(i+1)])**2)\n",
        "\n",
        "            Vdb['b' + str(i+1)] = beta1 * Vdb['b' + str(i+1)] + ((1-beta1) * db[\"db\" + str(i+1)])\n",
        "            Sdb['b' + str(i+1)] = beta2 * Sdb['b' + str(i+1)] + ((1-beta2) * (db['db' + str(i+1)])**2)\n",
        "\n",
        "\n",
        "            #bias correction\n",
        "            Vdw_corrected['w' + str(i+1)] = Vdw['w' + str(i+1)] / (1-beta1**t)\n",
        "            Vdb_corrected['b' + str(i+1)] = Vdb['b' + str(i+1)] / (1-beta1**t)\n",
        "\n",
        "            Sdw_corrected['w' + str(i+1)] = Sdw['w' + str(i+1)] / (1-beta2**t)\n",
        "            Sdb_corrected['b' + str(i+1)] = Sdb['b' + str(i+1)] / (1-beta2**t)\n",
        "\n",
        "\n",
        "            weights[\"W\" + str(i+1)] = weights[\"W\" + str(i+1)] - learning_rate * (Vdw_corrected['w' + str(i+1)] / np.sqrt(Sdw_corrected['w' + str(i+1)] + epsilon))\n",
        "            biases['b' + str(i+1)] = biases['b' + str(i+1)] - learning_rate * (Vdb_corrected['b' + str(i+1)] / np.sqrt(Sdb_corrected['b' + str(i+1)] + epsilon))\n",
        "\n",
        "        t += 1\n",
        "\n",
        "    else: #normal gd\n",
        "        for i in range(len(weights)):\n",
        "            weights[\"W\" + str(i+1)] = weights[\"W\" + str(i+1)] - learning_rate * dw[\"dW\" + str(i+1)]\n",
        "            biases[\"b\" + str(i+1)] = biases[\"b\" + str(i+1)] - learning_rate * db[\"db\" + str(i+1)]\n",
        "\n",
        "    # print(\"Successfully updated params\")\n",
        "    return weights, biases"
      ],
      "metadata": {
        "id": "djF7hwUtxlyr"
      },
      "execution_count": 403,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(X, weights, biases):\n",
        "    cache = forward(X, weights, biases, activation_function='relu')\n",
        "    prediction = cache['A'][list(cache['A'].keys())[-1]]\n",
        "    return prediction"
      ],
      "metadata": {
        "id": "uLU5V7b0y80T"
      },
      "execution_count": 404,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if len(np.unique(y)) > 2:\n",
        "    y = one_hot_encoding(y)\n",
        "    y_test = one_hot_encoding(y_test)\n",
        "    classification_type = 'multi'\n",
        "else:\n",
        "    classification_type = 'single'\n",
        "\n",
        "\n",
        "def accuracy(prediction, labels):\n",
        "    total = len(labels)\n",
        "\n",
        "    if classification_type == 'single':\n",
        "        acc = np.sum((prediction > 0.5).astype(int) == labels) / total\n",
        "    else:\n",
        "        predicted_class = np.argmax(prediction, axis=1)\n",
        "        true_class = np.argmax(labels, axis=1)\n",
        "        acc = np.mean(predicted_class == true_class)\n",
        "    return acc\n"
      ],
      "metadata": {
        "id": "YAN6QKh0HlhD"
      },
      "execution_count": 405,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run(epochs, learning_rate, optimizer='gd', beta1=0.9, beta2=0.999):\n",
        "    for i in range(epochs):\n",
        "        cache = forward(X, weights, biases, activation_function='relu')\n",
        "        prediction = cache['A'][list(cache['A'].keys())[-1]]\n",
        "        grads = backpropagation(X, y, weights, biases, cache)\n",
        "\n",
        "\n",
        "        if i % 100 == 0:\n",
        "            dev_predictions = predict(X_test, weights, biases)\n",
        "            print(f\"epoch: {i}, loss= {calculate_loss(prediction, y, loss='cross_entropy' if classification_type=='multi' else 'binary_cross_entropy')}, training-set accuracy= {accuracy(prediction, y)}, dev-set accuracy= {accuracy(dev_predictions, y_test)}\")\n",
        "\n",
        "        update_params(grads, weights, biases, learning_rate, optimizer=optimizer, beta1=beta1, beta2=beta2)"
      ],
      "metadata": {
        "id": "bE-obYbZv2Lb"
      },
      "execution_count": 406,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run_mini_batches(epochs, learning_rate, mini_batch_size=64, optimizer='gd', beta1=0.9, beta2=0.999):\n",
        "    num_samples = X.shape[0]\n",
        "    div = int(num_samples / mini_batch_size)\n",
        "\n",
        "    divisible_by_mini_batch_size = mini_batch_size * div\n",
        "    not_divisible = num_samples - divisible_by_mini_batch_size\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        shuffled_indices = np.arange(num_samples)\n",
        "        np.random.shuffle(shuffled_indices)\n",
        "        X_shuffled = X[shuffled_indices]\n",
        "        y_shuffled = y[shuffled_indices]\n",
        "\n",
        "        start = 0\n",
        "        end = 0\n",
        "        for batch in range(start, divisible_by_mini_batch_size, mini_batch_size):\n",
        "            start = end\n",
        "            end = start + mini_batch_size\n",
        "            X_batch = X_shuffled[start:end, :]\n",
        "            y_batch = y_shuffled[start:end]\n",
        "            #forward\n",
        "            cache = forward(X_batch, weights, biases, activation_function='relu')\n",
        "            prediction = cache['A'][list(cache['A'].keys())[-1]]\n",
        "            #backward\n",
        "            grads = backpropagation(X_batch, y_batch, weights, biases, cache)\n",
        "            #update\n",
        "            update_params(grads, weights, biases, learning_rate, optimizer=optimizer, beta1=beta1, beta2=beta2)\n",
        "\n",
        "        if not_divisible != 0:\n",
        "            X_batch = X_shuffled[divisible_by_mini_batch_size:, :]\n",
        "            y_batch = y_shuffled[divisible_by_mini_batch_size:]\n",
        "            #forward\n",
        "            cache = forward(X_batch, weights, biases, activation_function='relu')\n",
        "            prediction = cache['A'][list(cache['A'].keys())[-1]]\n",
        "            #backward\n",
        "            grads = backpropagation(X_batch, y_batch, weights, biases, cache)\n",
        "            #update\n",
        "            update_params(grads, weights, biases, learning_rate, optimizer=optimizer)\n",
        "\n",
        "        cache = forward(X, weights, biases, activation_function='relu')\n",
        "        full_prediction = cache['A'][list(cache['A'].keys())[-1]]\n",
        "        dev_predictions = predict(X_test, weights, biases)\n",
        "        print(f\"epoch: {epoch+1}, loss= {calculate_loss(full_prediction, y, loss='cross_entropy' if classification_type=='multi' else 'binary_cross_entropy')}, training-set accuracy= {accuracy(full_prediction, y)}, dev-set accuracy= {accuracy(dev_predictions, y_test)}\")\n"
      ],
      "metadata": {
        "id": "AgzrO6SZBrIw"
      },
      "execution_count": 407,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# run(epochs=10000, learning_rate=0.005)"
      ],
      "metadata": {
        "id": "4oMThHvuwDdK"
      },
      "execution_count": 408,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "run_mini_batches(epochs=20, learning_rate=0.001, mini_batch_size=32, optimizer='adam', beta1=0.9, beta2=0.999)"
      ],
      "metadata": {
        "id": "zq_460UVTJVT",
        "outputId": "783d03da-a320-49c2-db2e-2015161f668b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 409,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 1, loss= 0.10097313061068064, training-set accuracy= 0.9706, dev-set accuracy= 0.9679\n",
            "epoch: 2, loss= 0.061431025842956566, training-set accuracy= 0.9823333333333333, dev-set accuracy= 0.9731\n",
            "epoch: 3, loss= 0.04200908791980276, training-set accuracy= 0.9877833333333333, dev-set accuracy= 0.9773\n",
            "epoch: 4, loss= 0.027257136604939777, training-set accuracy= 0.9926666666666667, dev-set accuracy= 0.98\n",
            "epoch: 5, loss= 0.0199869376254527, training-set accuracy= 0.9943666666666666, dev-set accuracy= 0.9791\n",
            "epoch: 6, loss= 0.0178359401654093, training-set accuracy= 0.994, dev-set accuracy= 0.9803\n",
            "epoch: 7, loss= 0.01549859642218421, training-set accuracy= 0.9950666666666667, dev-set accuracy= 0.9803\n",
            "epoch: 8, loss= 0.011071434831255198, training-set accuracy= 0.9967166666666667, dev-set accuracy= 0.9797\n",
            "epoch: 9, loss= 0.012018330448494959, training-set accuracy= 0.9962333333333333, dev-set accuracy= 0.9793\n",
            "epoch: 10, loss= 0.014946713006484896, training-set accuracy= 0.9948833333333333, dev-set accuracy= 0.9786\n",
            "epoch: 11, loss= 0.006134866944511461, training-set accuracy= 0.9981, dev-set accuracy= 0.9802\n",
            "epoch: 12, loss= 0.007510958825365459, training-set accuracy= 0.99745, dev-set accuracy= 0.9796\n",
            "epoch: 13, loss= 0.004511075679181801, training-set accuracy= 0.9985166666666667, dev-set accuracy= 0.9811\n",
            "epoch: 14, loss= 0.008531744876308364, training-set accuracy= 0.9969833333333333, dev-set accuracy= 0.9805\n",
            "epoch: 15, loss= 0.006148617595454692, training-set accuracy= 0.99795, dev-set accuracy= 0.9793\n",
            "epoch: 16, loss= 0.004542249152893811, training-set accuracy= 0.9985833333333334, dev-set accuracy= 0.9792\n",
            "epoch: 17, loss= 0.0021621291741421578, training-set accuracy= 0.9994666666666666, dev-set accuracy= 0.9821\n",
            "epoch: 18, loss= 0.01277950210805155, training-set accuracy= 0.99555, dev-set accuracy= 0.975\n",
            "epoch: 19, loss= 0.002346450566611585, training-set accuracy= 0.9993333333333333, dev-set accuracy= 0.9823\n",
            "epoch: 20, loss= 0.004027616335175528, training-set accuracy= 0.99875, dev-set accuracy= 0.9806\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Z1 = forward(X_test, weights, biases, activation_function='relu')['Z']['Z1']\n",
        "print(f\"Z1 variance = {np.var(Z1)}\")"
      ],
      "metadata": {
        "id": "4dm8WTHgItOn",
        "outputId": "9cd1a262-dff7-4e5c-9d34-49ffee63579e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 410,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Z1 variance = 16.300485052697983\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# np.savez('best_trained_model_params[32,16,10].npz', **weights, **biases)\n",
        "# data = np.load('trained_model_params.npz')"
      ],
      "metadata": {
        "id": "PDZUH2uAUaeD"
      },
      "execution_count": 411,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#visualize mnist\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_predictions(X, y, num_images=10):\n",
        "    num_samples = X.shape[0]\n",
        "    shuffled_indices = np.arange(num_samples)\n",
        "    np.random.shuffle(shuffled_indices)\n",
        "    X_shuffled = X[shuffled_indices]\n",
        "    y_shuffled = y[shuffled_indices]\n",
        "\n",
        "    random_picks = np.random.choice(np.arange(num_samples), size=num_images)\n",
        "\n",
        "    images = X_shuffled[random_picks]\n",
        "    labels = y_shuffled[random_picks]\n",
        "    predictions_probability_distribution = predict(images, weights, biases)\n",
        "    predicted_labels = np.argmax(predictions_probability_distribution, axis=1)\n",
        "\n",
        "\n",
        "    fig, axes = plt.subplots(2, num_images, figsize=(20,6))\n",
        "    for i in range(len(images)):\n",
        "        axes[0,i].imshow(images[i].reshape(28,28), cmap='gray')\n",
        "        axes[0,i].set_title(\"true: \" + str(labels[i]) + \"\\npredicted: \" + str(predicted_labels[i]))\n",
        "        axes[0,i].axis('off')\n",
        "        axes[1,i].bar(x=np.arange(10), height=predictions_probability_distribution[i])\n",
        "        axes[1,i].set_ylim(0,1)\n",
        "        axes[1,i].set_xticks(np.arange(10))\n",
        "\n",
        "plot_predictions(X_test_copy, y_test_copy, num_images=5)"
      ],
      "metadata": {
        "id": "U2S_jh2B9N5O",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "cb077fbe-6f75-43fe-eb99-38935fd9c1a9"
      },
      "execution_count": 412,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 2000x600 with 10 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAABkEAAAIkCAYAAACp5IzGAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAVVFJREFUeJzt3Xm8nPP5P/5rkshJgqTITja0FE0QREKpr1SoRrVFbJWPot+2sYaSVAlfJaq1tHY+lmqDxNqFBg1aKrZYYt8jkU+zlaw0Ief+/fH5OXUkMzlnMuecmfc8n4/HPB7Ofc37fV+T5XXuO5eZk8uyLAsAAAAAAIDEtGrpBgAAAAAAAJqCIQgAAAAAAJAkQxAAAAAAACBJhiAAAAAAAECSDEEAAAAAAIAkGYIAAAAAAABJMgQBAAAAAACSZAgCAAAAAAAkyRAEAAAAAABIkiEIAAAAAACQJEMQSuqxxx6Ls846KxYuXNjSrTTYq6++Gqeeempsu+22sf7660ePHj1i3333jaeffrqlWwMqTCVmYETEm2++GQcccEBssMEG0aFDh9h1113joYceaum2gApTqRn4WRMmTIhcLhfrrbdeS7cCVJhKzMCzzjorcrlc3sc//vGPlm4RqACVmH8R7oOrTS7LsqylmyAdv/rVr+InP/lJvPPOO9G3b9+WbqdBTjnllLjuuuviu9/9buy0006xaNGiuPrqq2PGjBkxefLkGDp0aEu3CFSISszAWbNmxfbbbx+tW7eO448/PtZdd9244YYb4qWXXoopU6bEbrvt1tItAhWiEjPws5YuXRpbbLFFLFq0qO5rgIaqxAycPn16TJ8+fZXjP/3pT2Pp0qUxZ86caNu2bQt0BlSSSsw/98HVp01LN0D1qq2tjRUrVkS7du1atI9DDjkkzjrrrHr/x9/3v//9+PKXvxxnnXWWIQjQJMolA88///xYuHBhvPjii7HFFltERMQxxxwTW265ZZx00kkxbdq0Fu0PSFO5ZOBn/fznP4/1118/9thjj7j77rtbuh0gYeWSgf3794/+/fvXOzZr1qx477334uijjzYAAUquXPLPfXD18XFYlMxZZ50VP/nJTyIiol+/fnVvoZ0xY0ZERORyuTj22GNjwoQJsfXWW0dNTU1Mnjw5Hn744cjlcvHwww/X22/GjBmRy+XixhtvrHf81VdfjQMOOCA23HDDaNeuXeywww7xxz/+cZV+3nrrrXjrrbfW2PfAgQNX+ciDjTbaKL761a/GK6+80vBfAKCqVWoGPvLII7HddtvVXfhFRHTo0CH222+/eOaZZ+KNN95o3C8EUJUqNQM/9cYbb8TFF18cF110UbRp4/8TAxqn0jPws2655ZbIsiwOO+ywotYD1aVS8899cPVxhU/JfOc734nXX389brnllrj44oujc+fOERHRpUuXuuc8+OCDMWnSpDj22GOjc+fO0bdv30Z9ZuBLL70Uu+yyS2y88cYxZsyYWHfddWPSpEmx//77xx133BHf/va365675557RkTUBW9jzZkzp+41AKxJpWbg8uXLY4MNNljleIcOHSIiYtq0afHFL36xwT0C1alSM/BTJ554Yuyxxx7xjW98IyZNmtTgngAiKj8DP2vChAnRq1cvHwUDNEil5p/74OpjCELJ9O/fP7bffvu45ZZbYv/991/t5wC+9tpr8cILL8RWW21Vd+zzU99CTjjhhOjdu3c89dRTUVNTExERP/7xj2PXXXeN0047rV7wrY1HHnkkpk6dGj/72c9Ksh+QvkrNwC222CIeeeSRWLJkSay//vp1xx999NGIiJg9e3aj9wSqT6VmYETEPffcE/fff388//zzRa0HqOQM/KyXXnoppk+fHqeeemrkcrm13g9IX6Xmn/vg6uPjsGhWu+++e73Qa4z3338/HnzwwTjooINiyZIlsWDBgliwYEH861//imHDhsUbb7xRL6RmzJhR1P/5Mm/evDj00EOjX79+ceqppxbVK8DqlGMG/uhHP4qFCxfGiBEj4tlnn43XX389TjzxxHj66acjIuKjjz4qql+AzyvHDFyxYkWcdNJJ8cMf/rDo3gAaohwz8PMmTJgQEeGjsICSKsf8cx9cfbwThGbVr1+/ote++eabkWVZnHHGGXHGGWes9jnz5s2LjTfeuOhzLFu2LL75zW/GkiVL4tFHH13lZ4UArI1yzMB99tknLr300hgzZkxsv/32ERGx+eabx7nnnhunnnqqHARKphwz8OKLL44FCxbE2WefXXRvAA1Rjhn4WVmWxc033xzbbLPNKj8sHWBtlGP+uQ+uPoYgNKv27duvcizf22xXrlxZ7+va2tqIiDjllFNi2LBhq12z+eabF93bihUr4jvf+U5Mnz497rvvvthmm22K3gtgdco1A4899tg48sgjY/r06dG2bdvYdttt47rrrouIiC996UtF7QnweeWWgYsWLYqf//zn8eMf/zgWL14cixcvjoiIpUuXRpZlMWPGjOjQoUN07dq1UfsCrE65ZeDn/eMf/4h33303xo8fv1b7AHxeueaf++DqYghCSRXzuaGf/iCiz/9QpHfffbfe15tuumlERKyzzjoxdOjQ4hrMo7a2No444oiYMmVKTJo0KXbfffeS7g9Uh0rNwIiIddddNwYPHlz39V//+tdo37597LLLLiU/F5CmSsvADz74IJYuXRoXXHBBXHDBBavU+/XrF9/61rfi7rvvLsn5gLRVWgZ+3oQJEyKXy8Whhx7aJPsD6ark/HMfXD38TBBKat11142IVUOskD59+kTr1q3j73//e73jV1xxRb2vu3btGl/72tfi6quvjn/+85+r7DN//vx6X7/11lvx1ltvNaiH4447LiZOnBhXXHFFfOc732lw7wCfVakZ+HmPPfZY3HnnnXHUUUdFp06ditoDqD6VloFdu3aNu+66a5XHHnvsEe3atYu77rorxo4d2+DXAlS3SsvAz/r444/jtttui1133TV69+7d4HUAEZWdf5/lPjht3glCSQ0cODAiIk4//fQ4+OCDY5111onhw4fXBeLqdOrUKQ488MC49NJLI5fLxWabbRZ//vOfY968eas89/LLL49dd901vvKVr8QxxxwTm266acydOzemTp0a7733Xjz//PN1z91zzz0jItb4A5EuueSSuOKKK2Lw4MHRoUOH+P3vf1+v/u1vf7tg/wCfqsQMfPfdd+Oggw6K/fbbL7p37x4vvfRSXHXVVdG/f/8477zzivhVAKpVpWVghw4dYv/991/l+N133x1PPvnkamsA+VRaBn7WfffdF//617/8QHSgKJWYf+6Dq48hCCW14447xjnnnBNXXXVVTJ48OWpra+Odd95Z4xDh0ksvjY8//jiuuuqqqKmpiYMOOih++ctfrvJzObbaaqt4+umn4+yzz44bb7wx/vWvf0XXrl1ju+22izPPPLOonp977rmIiJg6dWpMnTp1lXpD+geIqMwM7NixY/To0SMuu+yyeP/992PjjTeO448/Pk4//fRYf/31i9oTqE6VmIEApVLJGThhwoRYZ5114sADD1yrfYDqVIn55z64+uSyLMtaugkAAAAAAIBS8zNBAAAAAACAJBmCAAAAAAAASTIEAQAAAAAAkmQIAgAAAAAAJMkQBAAAAAAASJIhCAAAAAAAkCRDEFrMww8/HLlcLh5++OG6Y//1X/8Vffv2bbGePm91PQKUggwEqpkMBKqV/AOqmQykpRiCkITzzjsv7r777pZuYxV33nlnjBgxIjbddNPo0KFDbLHFFnHyySfHwoULW7o1ICHlmoEREbfeemtsv/320a5du+jSpUscddRRsWDBgpZuC0hIOWfgZ33961+PXC4Xxx57bEu3AiSiXPOvb9++kcvlVvv44he/2NLtAYko1wyMcB9cjtq0dAPwWddee23U1tY2et15550XBxxwQOy///6lb2ot/OAHP4iePXvG4YcfHr17944XXnghLrvssrj33nvjmWeeifbt27d0i0AZSS0Dr7zyyvjxj38ce+65Z1x00UXx3nvvxa9//et4+umn44knnoh27dq1dItAGUktAz/rzjvvjKlTp7Z0G0CZSi3/Lrnkkli6dGm9Y++++2787Gc/i7322quFugLKVWoZ6D64PBmC0Gi1tbWxYsWKJvlLu84665R8z5Z0++23x9e+9rV6xwYOHBgjR46MCRMmxNFHH90yjQFFk4ENs2LFivjpT38au+22WzzwwAORy+UiImLIkCExfPjwuPbaa+O4445r4S6BxpKBjffvf/87Tj755DjttNPizDPPbOl2gCLJv4Zb3T9I/vznP4+IiMMOO6yZuwFKQQY2jPvg8uXjsKrUWWedFblcLl599dU46KCDomPHjrHRRhvFCSecEP/+97/rPffTt+1PmDAhtt5666ipqYnJkydHRMTs2bPj+9//fnTr1i1qampi6623juuvv36V87333nux//77x7rrrhtdu3aNk046KZYvX77K81b3OYC1tbXx61//Or7yla/UvY1s7733jqeffrquv2XLlsVvf/vburfY/td//Vfd+lL3+OGHH8arr77aoLexfX4AEhHx7W9/OyIiXnnllTWuB5qGDGz6DHzxxRdj4cKFMWLEiLoLv4iIb37zm7HeeuvFrbfeWnA90HRkYPNcB37qggsuiNra2jjllFMavAZoGvKvefPvs26++ebo169fDBkypKj1wNqTge6Dq5l3glS5gw46KPr27Rvjx4+Pxx9/PH7zm9/EBx98EDfddFO95z344IMxadKkOPbYY6Nz587Rt2/fmDt3buy88851wdilS5f4y1/+EkcddVQsXrw4TjzxxIiI+Oijj2LPPfeMmTNnxvHHHx89e/aM3/3ud/Hggw82qMejjjoqbrzxxthnn33i6KOPjk8++SQeeeSRePzxx2OHHXaI3/3ud3H00UfHTjvtFD/4wQ8iImKzzTaLiGiSHp988snYY489Yty4cXHWWWc1+td8zpw5ERHRuXPnRq8FSksGNr7HhmbgpxeOq/vYv/bt28ezzz4btbW10aqV/x8DWooMbHyPjb0OnDlzZpx//vlx/fXX+xhUKCPyr/E9rs198LPPPhuvvPJKnH766Y1aBzQNGdj4Ht0HJyCjKo0bNy6LiGy//fard/zHP/5xFhHZ888/X3csIrJWrVplL730Ur3nHnXUUVmPHj2yBQsW1Dt+8MEHZ506dco+/PDDLMuy7JJLLskiIps0aVLdc5YtW5ZtvvnmWURkDz30UN3xkSNHZn369Kn7+sEHH8wiIjv++ONXeQ21tbV1/73uuutmI0eOXOU5TdHjQw89lEVENm7cuFXO1xBHHXVU1rp16+z1118vaj2w9mRg02fg/Pnzs1wulx111FH1jr/66qtZRGQRsUpfQPOQgc13HXjAAQdkQ4YMqfs6IrJRo0Y1aC1QevKvZe6DTz755CwispdffrnRa4HSkYHug6uZsVOVGzVqVL2vP/1cunvvvbfe8d133z222mqruq+zLIs77rgjhg8fHlmWxYIFC+oew4YNi0WLFsUzzzxTt1ePHj3igAMOqFvfoUOHukltIXfccUfkcrkYN27cKrXPvq1sdZqqx6997WuRZVlR7wK5+eab47rrrouTTz45vvjFLzZ6PVBaMrDpMrBz585x0EEHxW9/+9u48MIL4+23345HHnkkRowYUfeZrx999NGafgmAJiQDm/Y68KGHHoo77rgjLrnkkjU+F2he8q/57oNra2vj1ltvje222y6+/OUvN2ot0DRkoPvgauTjsKrc5/8hfrPNNotWrVrFjBkz6h3v169fva/nz58fCxcujGuuuSauueaa1e49b968iIh49913Y/PNN18lqLbYYos19vfWW29Fz549Y8MNN1zjcz+vuXpsqEceeSSOOuqoGDZsWJx77rkl2xcongxs2gy8+uqr46OPPopTTjml7rPwDz/88Nhss83izjvvjPXWW2+t9gfWjgxsugz85JNP4vjjj4/vfe97seOOOxa9D9A05F/z3Qf/7W9/i9mzZ8dJJ51Usj2BtSMD3QdXI0MQ6sk3Uf38Z9nV1tZGxP/+JR45cuRq1/Tv37+0zTVSOfX4/PPPx3777RfbbLNN3H777dGmjb96UI5kYGl16tQp/vCHP8TMmTNjxowZ0adPn+jTp08MGTIkunTpEl/4whea9PxA48jA0rnpppvitddei6uvvnqVf1BYsmRJzJgxI7p27RodOnRosh6AhpN/TWfChAnRqlWrOOSQQ5rtnEDjyMDSch9cnvxLbJV744036k1233zzzaitrY2+ffsWXNelS5dYf/31Y+XKlTF06NCCz+3Tp0+8+OKLkWVZvWB97bXX1tjfZpttFvfdd1+8//77BSfAqwvs5upxTd56663Ye++9o2vXrnHvvfea+EIZkYFr32ND9O7dO3r37h0REQsXLoxp06bFd7/73ZLsDRRPBq59j/nMnDkzPv7449hll11Wqd10001x0003xV133RX7779/0ecAiif/1r7Hhli+fHnccccd8bWvfS169uxZkj2BtScD177HhnAfXF78TJAqd/nll9f7+tJLL42IiH322afgutatW8d3v/vduOOOO+LFF19cpT5//vy6//7GN74R//M//xO333573bEPP/ww79vSPuu73/1uZFkWZ5999iq1LMvq/nvdddeNhQsXNkuPH374Ybz66quxYMGCNfY/Z86c2GuvvaJVq1Zx3333RZcuXda4Bmg+MrDxPTYmA1dn7Nix8cknn/hIBCgDMrDxPTY0Aw8++OC46667Vnl8er677rorBg0aVHAPoOnIv8b3WMw14L333hsLFy6Mww47rMFrgKYnAxvfo/vgyuedIFXunXfeif322y/23nvvmDp1avz+97+PQw89NAYMGLDGteeff3489NBDMWjQoDjmmGNiq622ivfffz+eeeaZ+Otf/xrvv/9+REQcc8wxcdlll8URRxwR06ZNix49esTvfve7Br39f4899ojvfe978Zvf/CbeeOON2HvvvaO2tjYeeeSR2GOPPeLYY4+NiIiBAwfGX//617jooouiZ8+e0a9fvxg0aFCT9Pjkk0/GHnvsEePGjVvjD0Tae++94+23345TTz01Hn300Xj00Ufrat26dYuvf/3ra/w1AJqODGzaDDz//PPjxRdfjEGDBkWbNm3i7rvvjvvvvz9+/vOf+4x8KAMysOkycMstt4wtt9xytbV+/fp5Bwi0MPnXtNeAn5owYULU1NT4P5+hzMhA98FVKaMqjRs3LouI7OWXX84OOOCAbP3118822GCD7Nhjj80++uijes+NiGzUqFGr3Wfu3LnZqFGjsl69emXrrLNO1r1792zPPffMrrnmmnrPe/fdd7P99tsv69ChQ9a5c+fshBNOyCZPnpxFRPbQQw/VPW/kyJFZnz596q395JNPsl/+8pfZlltumbVt2zbr0qVLts8++2TTpk2re86rr76a7bbbbln79u2ziMhGjhzZZD0+9NBDWURk48aNW+Ovc0Tkfey+++5rXA80DRnYPBn45z//Odtpp52y9ddfP+vQoUO28847Z5MmTVrjOqBpycDmycDVKfTrCTQ9+dd8+bdo0aKsXbt22Xe+850GPR9oejLQfXA1y2XZZ95HRNU466yz4uyzz4758+dH586dW7odgGYlA4FqJgOBaiX/gGomA6lmfiYIAAAAAACQJEMQAAAAAAAgSYYgAAAAAABAkvxMEAAAAAAAIEneCQIAAAAAACTJEAQAAAAAAEhSm5ZuoFzlcrmWbgEqnk/bq1wyENaeDKxcMhBKQw5WHvkHa0/2VS4ZCGuvXDPQO0EAAAAAAIAkGYIAAAAAAABJMgQBAAAAAACSZAgCAAAAAAAkyRAEAAAAAABIkiEIAAAAAACQJEMQAAAAAAAgSYYgAAAAAABAkgxBAAAAAACAJBmCAAAAAAAASTIEAQAAAAAAkmQIAgAAAAAAJMkQBAAAAAAASJIhCAAAAAAAkCRDEAAAAAAAIEmGIAAAAAAAQJIMQQAAAAAAgCQZggAAAAAAAEkyBAEAAAAAAJJkCAIAAAAAACTJEAQAAAAAAEiSIQgAAAAAAJAkQxAAAAAAACBJhiAAAAAAAECSDEEAAAAAAIAkGYIAAAAAAABJMgQBAAAAAACSZAgCAAAAAAAkyRAEAAAAAABIUpuWbgAAAODzZs6cWfTa3r17l7ATAACgknknCAAAAAAAkCRDEAAAAAAAIEmGIAAAAAAAQJIMQQAAAAAAgCQZggAAAAAAAEkyBAEAAAAAAJLUpqUboPy1b9++YH2//fbLW9tggw2KPu+HH35YsH777bcXvRYAgPLWq1evvLVZs2Y1YycAAEAl804QAAAAAAAgSYYgAAAAAABAkgxBAAAAAACAJBmCAAAAAAAASTIEAQAAAAAAkmQIAgAAAAAAJMkQBAAAAAAASFKblm6A8tCtW7e8tddee63g2vXXX7/U7TTIDTfckLd2xBFHFFw7YcKEUrcDAEAjHHTQQQXrU6dOzVsbPXp0qdspiccee6xg/bbbbstbu/jii0vdDgBAs2vbtm3B+m677Za39s1vfrPg2t133z1vbcCAAYUbK+DQQw8tWL/11luL3pvy4J0gAAAAAABAkgxBAAAAAACAJBmCAAAAAAAASTIEAQAAAAAAkmQIAgAAAAAAJMkQBAAAAAAASFIuy7KspZsoR7lcrqVbaFbf/OY389b+8Ic/NGMnpfHJJ58UrP/pT3/KWxs5cmTBtcuWLSuqp2okXipXtWVgU/m///f/FqxfeeWVRe9d6Pfo73//e8G1vXv3zlt78MEHC679xS9+kbf2+uuvF1xbbWRg5ZKBpdOrV6+8tZkzZxZcO3Xq1Ly1IUOGFN3T2lqb11Rtf7bkYOWptj+j0BRkX+WSgQ3Xt2/fvLWTTz654Nof//jHRZ+30O/R2vzdmzdvXsF6jx49it672pRrBnonCAAAAAAAkCRDEAAAAAAAIEmGIAAAAAAAQJIMQQAAAAAAgCQZggAAAAAAAEkyBAEAAAAAAJJkCAIAAAAAACQpl2VZ1tJNlKNcLtfSLTSrjh075q3dddddBdfutttueWsffPBB0T299dZbBevbbbdd3lrbtm0Lri30x/7oo48uuPaGG24oWOc/xEvlqrYMLKRDhw4F6xMnTsxb23vvvQuubdWq+P8XodDv0QsvvFBwbW1tbd5aoe8HERHrrbde3to3vvGNgmunTZtWsJ4aGVi5ZGDpPPbYY3lrgwcPLrh2xIgReWuTJk0quqe1VejcBx54YMG11fZnSw5Wnmr7M7rZZpvlrW2++eZF77uma54FCxbkrQ0bNqzotdV2rVWuZF/lqrYMXBsTJkzIWzv44IOL3rfQ/XVExHnnnVf03ocddlje2jHHHFNw7aBBg/LW1vTvl9WmXDPQO0EAAAAAAIAkGYIAAAAAAABJMgQBAAAAAACSZAgCAAAAAAAkyRAEAAAAAABIkiEIAAAAAACQpFyWZVlLN1GOcrlcS7dQNjp27FiwPmjQoLy1Bx54oNTt1Bk7dmze2rnnnltwbaE/9ldddVXBtaNGjSrcGHXES+WSgf/x2GOPFawXysA1mTNnTt7a9ddfX3DtHXfckbf2yiuvFFxb6O9mmzZtCq594YUX8tbefffdgmu/9a1v5a0tWbKk4NpKJAMrlwxsuAsvvLBgffTo0Xlrt912W8G1Bx10UFE9NbVCf7enTp1acO2QIUNK3U5Zk4OVp6Xyb8MNN8xb+8Mf/lBw7VZbbVX0edu1a5e31r59+6L3XdN1zSeffJK3VujXIiJixYoVeWtLly4t3NhaKLT3okWLCq595JFH8tbefPPNgmsvvvjiwo2VIdlXuVwD/sea/u4df/zxeWtz584tuPakk07KW1vT9WFtbW3BerH22muvgvUXX3wxb23ZsmUF164pI1NTrhnonSAAAAAAAECSDEEAAAAAAIAkGYIAAAAAAABJMgQBAAAAAACSZAgCAAAAAAAkyRAEAAAAAABIkiEIAAAAAACQpDYt3QDlb/HixQXrDzzwQDN1Ul+vXr2aZN8nnniiSfYFyteQIUPy1rbffvui950+fXrB+iGHHJK39uqrrxZ93rWxYsWKgvXa2tq8td13373g2sGDB+et3X///YUbA1rMzjvvnLc2evTogmtnzZqVt3byyScX3VNTOumkk4pee9ttt5WwE6ge55xzTt7aLrvsUnDtc889l7f2/PPPF1z77rvv5q0tWrSo4NrUdOrUqWB9n332KXrvww8/PG+tTZvC/yx18cUXF31eoHiFrv/WZP78+QXrEydOLHrvpjJ+/PiC9W233TZv7dZbby249rDDDiumJUrMO0EAAAAAAIAkGYIAAAAAAABJMgQBAAAAAACSZAgCAAAAAAAkyRAEAAAAAABIkiEIAAAAAACQpDYt3QAU60tf+lKT7Pv66683yb5Ay9lkk00K1m+++ea8tXXWWafg2kKZMWTIkIJrP/roo4L1lrD11lsXrG+wwQZF7/31r389b+3+++8vel+gaU2aNKnotaecckre2qxZs4retykdeOCBRa+9+OKLS9gJVI/u3bsXvfbggw/OW3NvVzpnnXVW3lrHjh0Lrp0+fXreWpcuXYptCVhLnTt3zlvbaKONit53ba4dm9Jmm22Wt7bVVls1Yye0BO8EAQAAAAAAkmQIAgAAAAAAJMkQBAAAAAAASJIhCAAAAAAAkCRDEAAAAAAAIEmGIAAAAAAAQJIMQQAAAAAAgCS1aekGIJ8uXboUrG+77bZF7/3ee+/lrb3yyitF7wuUp+OOO65gvVevXkXvfeyxx+atffTRR0Xv25Tat2+ft3bHHXcUXLvBBhvkrX388ccF1/7hD38o3BjQInbeeeeC9UIZOWvWrIJrJ02aVFRPLWnw4MEF61OnTm2mTiAdW2yxRcH68OHDi9576dKlRa+lNHr06FGw3rt377y1cr1ehmqw+eab561tttlmBdd++OGHeWsXXXRR0T2tjUKvJyLi/vvvz1tr27Zt0ee99tpri15L8/FOEAAAAAAAIEmGIAAAAAAAQJIMQQAAAAAAgCQZggAAAAAAAEkyBAEAAAAAAJJkCAIAAAAAACSpTUs3APksWbKkYP3dd9/NW9too40Kru3Vq1fe2pe//OWCax9//PGC9UI222yzvLW33nqr6H2Bwg499NCi144ZM6ZgfW0yoaX89Kc/zVv74he/WPS+999/f8H6o48+WvTeQNO56KKLil570EEHlbCT5nPSSScVvfaSSy4pXSNQJY4//viC9TZt8v/TxHvvvVdw7bJly4rqidI58MADi167putHoOms6d/OCsmyLG/to48+KnrfNTnkkEPy1saPH19wbaF/C1yTd955J2/t5ZdfLnpfmo93ggAAAAAAAEkyBAEAAAAAAJJkCAIAAAAAACTJEAQAAAAAAEiSIQgAAAAAAJAkQxAAAAAAACBJhiAAAAAAAECS2rR0A5DPAQccULC+7bbb5q1lWVZw7fz58/PWZs2aVXDt2njrrbeabG+gadx7770F68uWLWumTurbfPPN89batm1bcG337t2LPu8TTzyRt3bGGWcUvS/QcgYPHlz02scff7yEnTSfk046qei1kyZNKmEn/7Gmni6++OImOS80hw033LDotW+//XbB+qJFi4rem9LYb7/9il47Z86cEnYCNMbOO+9c9No2bfL/k3KfPn0Krl2+fHne2k477VRw7S9+8Yu8tY033rjg2rUxb968omqUD+8EAQAAAAAAkmQIAgAAAAAAJMkQBAAAAAAASJIhCAAAAAAAkCRDEAAAAAAAIEmGIAAAAAAAQJLatHQDlM6QIUPy1vr371/0vgcddFDBek1NTdF7F7Lttts2yb4REa+//nre2vDhwwuufe+99/LWHnzwwYJrsyzLW/voo48KrgWKt6a/m4cffniTnDeXyxWsr7vuunlrG264YcG1hTKjb9++BdfutttuBeuF/OQnP8lbe/7554veF6CUdt5554L1Xr165a1NnTq1yc570UUX5a1tsskmBddefPHFRfUE5aB169ZFr33nnXdK2Enla9u2bd7amn6dP/7447y12tragms32mijomprsnTp0oL1I488Mm/thhtuKPq8QMR1112Xt3bUUUcVXNutW7e8taeeeqrg2pUrV+atde3ateDaQvfYl19+ecG1s2fPzls799xzC66l8nknCAAAAAAAkCRDEAAAAAAAIEmGIAAAAAAAQJIMQQAAAAAAgCQZggAAAAAAAEkyBAEAAAAAAJJkCAIAAAAAACSpTUs3QMONHz++YP3YY4/NW+vQoUOp26loQ4YMKaq2tpYvX5639qc//anofZ966qmC9V/96ldF7w0pOPHEEwvWhw4dmrf261//uuDaefPm5a0V+jsfEbHrrrvmrZ166qkF1z755JN5a3/9618Lrt1oo40K1guZM2dO0WuB8jRr1qyC9V69euWtZVlWcO1tt92WtzZ16tSCa2fPnl2wXsgBBxxQ9NrBgwcXrK/pNRdrxIgRTbIvlIPu3bsXvbbQNU+l6tOnT97amn6tJk6cmLfWu3fvgmtffPHFvLX58+cXXLvHHnsUrBdrTdfphb6P3HDDDSXuBqrLjBkz8tYef/zxgmt33333vLXOnTsX21IsXry4YP2kk07KW1tTJhxzzDF5a61aFX6fQC6XK1in/HknCAAAAAAAkCRDEAAAAAAAIEmGIAAAAAAAQJIMQQAAAAAAgCQZggAAAAAAAEkyBAEAAAAAAJKUy7Isa+kmylEul2vpFlZRW1tbsO638j/W9PuX2q/Vmv5sjB8/Pm/tzDPPLHU7dVL7da4m5ZiBTal///55a6NHjy64tm3btnlrzz33XMG1N910U97anDlzCq5dG//617/y1jbYYIOCa6+55pq8tR/+8IdF95QiGVi5qi0D1+TCCy/MW1tTRlaiqVOnFqy/9957eWu33357wbWTJk0qqqdKJQcrT1Pl35AhQwrWe/funbf29NNPF1z75ptvFtVTSzrttNPy1gYOHFhw7QEHHJC3Nn369IJr33nnncKNFbDFFlvkrW255ZYF177wwgt5awMGDCi6p3Il+yqXa8CG23zzzfPWvvzlLxe975py6sUXXyx676OPPjpv7eqrry649oknnshbW9P3uGpTrhnonSAAAAAAAECSDEEAAAAAAIAkGYIAAAAAAABJMgQBAAAAAACSZAgCAAAAAAAkyRAEAAAAAABIkiEIAAAAAACQpFyWZVlLN1GOcrlcS7ewiscff7xgfeDAgXlrrVqlN+9avHhx3tonn3xScO3a/LFfb7318tZqamqK3reltG7dusn2Fi+VqxwzkIbr0aNHwfprr72Wt7buuusWXPuzn/0sb238+PGFG6syMrByycDSOeigg4pee8ABB+St7bzzzgXX9urVq2D9tttuy1tbm56pTw5WHvnXPNbmHmydddbJW1vTffCa6oX84Q9/yFsbPnx4wbXjxo3LWzvnnHOK7qlcyb7KJQPTdvTRR+etXX311QXXPvHEE3lrQ4YMKbqnFJVrBqb3L+MAAAAAAABhCAIAAAAAACTKEAQAAAAAAEiSIQgAAAAAAJAkQxAAAAAAACBJhiAAAAAAAECS2rR0AzTczjvvXLB+yimn5K2deuqpBddutNFGRfXUlO69996C9bFjx+atvfjii6Vup87222+ftzZ8+PCCawcMGJC39q1vfavontbk+uuvb7K9gfLzz3/+s2B9xYoVeWsLFiwouPbaa68tqiegOk2aNKlJ1mZZVvS+EREnn3zyWq0HWBsrV65skbVrY9NNNy167UMPPVTCTgCKM3jw4KLX3njjjaVrhBbhnSAAAAAAAECSDEEAAAAAAIAkGYIAAAAAAABJMgQBAAAAAACSZAgCAAAAAAAkyRAEAAAAAABIkiEIAAAAAACQpFyWZVlLN1GOcrlcS7dQUv379y9YHzx4cN7aBx98UHDtn/70p6J6WpPly5cXrNfW1jbJeZtSoT9X7dq1K7i2S5cueWtr+rVasGBB3trKlSsLrl0b4qVypZaB1ebCCy8sWD/++OPz1qZNm1Zw7dChQ/PWli5dWrixKiMDK5cMLH9r+/fL73HzkIOVx9+N6tWjR4+C9eeffz5v7ZNPPim4tl+/fnlra7qXrUSyr3LJwLRNnz49b23rrbcuuPaJJ57IWxsyZEjRPaWoXDPQO0EAAAAAAIAkGYIAAAAAAABJMgQBAAAAAACSZAgCAAAAAAAkyRAEAAAAAABIkiEIAAAAAACQpDYt3QDNY/r06WtVpzSyLMtb++ijjwqunTlzZqnbARK12267Fay3apX//4GYOHFiwbVLly4tqieA5nTbbbe1dAsAFWWjjTYqWO/cuXPe2ksvvVRw7fLly4vqCaAxdthhh4L1fv36Fb33a6+9VvRayoN3ggAAAAAAAEkyBAEAAAAAAJJkCAIAAAAAACTJEAQAAAAAAEiSIQgAAAAAAJAkQxAAAAAAACBJhiAAAAAAAECS2rR0AwBA43Xv3j1vbeutty649qWXXspbe/nll4vuCaBcbLLJJgXrvXr1ylubNWtWqdsBKHtrun4sZPLkySXsBKA4nTp1Kljv0KFD0Xvfd999Ra+lPHgnCAAAAAAAkCRDEAAAAAAAIEmGIAAAAAAAQJIMQQAAAAAAgCQZggAAAAAAAEkyBAEAAAAAAJLUpqUbAAAa78orr8xbu+CCCwquHTx4cN7ac889V2xLAM1m6tSpBeubbLJJM3UCkIbRo0cXvfb1118vYScAUHreCQIAAAAAACTJEAQAAAAAAEiSIQgAAAAAAJAkQxAAAAAAACBJhiAAAAAAAECSDEEAAAAAAIAkGYIAAAAAAABJatPSDQAAjbfVVlvlrf3mN78puPaJJ57IW5s7d27RPQE0lyFDhrR0CwBJmTNnTsH6O++8k7d26623lrodgEZbsGBBwfqSJUvy1tZff/1St0OZ8U4QAAAAAAAgSYYgAAAAAABAkgxBAAAAAACAJBmCAAAAAAAASTIEAQAAAAAAkmQIAgAAAAAAJKlNSzcAADTe+uuvn7e2ww47FFz761//utTtAABQwQ4//PCC9W7duuWtLVmypNTtADTa888/X7A+YsSIvLUxY8YUXPv6668X1RPlwztBAAAAAACAJBmCAAAAAAAASTIEAQAAAAAAkmQIAgAAAAAAJMkQBAAAAAAASJIhCAAAAAAAkCRDEAAAAAAAIEm5LMuylm6iHOVyuZZuASqeeKlcMrDljR07tmD93HPPzVvr0KFDwbX//ve/i+qJxpGBlUsGQmnIwcoj/2Dtyb7KJQNh7ZVrBnonCAAAAAAAkCRDEAAAAAAAIEmGIAAAAAAAQJIMQQAAAAAAgCQZggAAAAAAAEkyBAEAAAAAAJKUy7Isa+kmylEul2vpFqDiiZfKJQNh7cnAyiUDoTTkYOWRf7D2ZF/lkoGw9so1A70TBAAAAAAASJIhCAAAAAAAkCRDEAAAAAAAIEmGIAAAAAAAQJIMQQAAAAAAgCQZggAAAAAAAEkyBAEAAAAAAJKUy7Isa+kmAAAAAAAASs07QQAAAAAAgCQZggAAAAAAAEkyBAEAAAAAAJJkCAIAAAAAACTJEAQAAAAAAEiSIQgAAAAAAJAkQxAAAAAAACBJhiAAAAAAAECSDEEAAAAAAIAkGYIAAAAAAABJMgQBAAAAAACSZAgCAAAAAAAkyRAEAAAAAABIkiEIAAAAAACQJEMQAAAAAAAgSYYgAAAAAABAkgxBAAAAAACAJBmCAAAAAAAASTIEAQAAAAAAkmQIAgAAAAAAJMkQBAAAAAAASJIhCAAAAAAAkCRDEAAAAAAAIEmGIAAAAAAAQJIMQQAAAAAAgCQZggAAAAAAAEkyBAEAAAAAAJJkCAIAAAAAACTJEAQAAAAAAEiSIQgAAAAAAJAkQxAAAAAAACBJhiAAAAAAAECSDEEAAAAAAIAkGYIAAAAAAABJMgQBAAAAAACSZAgCAAAAAAAkyRAEAAAAAABIkiEIAAAAAACQpEYPQf7+97/H8OHDo2fPnpHL5eLuu+9e45qHH344tt9++6ipqYnNN988brzxxiJaBWhZ8g+oZjIQqGYyEKhW8g9IQaOHIMuWLYsBAwbE5Zdf3qDnv/POO7HvvvvGHnvsEc8991yceOKJcfTRR8d9993X6GYBWpL8A6qZDASqmQwEqpX8A1KQy7IsK3pxLhd33XVX7L///nmfc9ppp8U999wTL774Yt2xgw8+OBYuXBiTJ09e7Zrly5fH8uXL676ura2N999/PzbaaKPI5XLFtgskLsuyWLJkSfTs2TNatWraT/uTf0C5kYFAtWrO/IuQgUB5cQ0IVLOGZmCbpm5k6tSpMXTo0HrHhg0bFieeeGLeNePHj4+zzz67iTsDUjVr1qzYZJNNWroN+Qe0CBkIVKtyyb8IGQg0v3LJQPkHtIQ1ZWCTD0HmzJkT3bp1q3esW7dusXjx4vjoo4+iffv2q6wZO3ZsjB49uu7rRYsWRe/evWPWrFnRsWPHpm65bGwzrrRvFXzx7GEl3Q/KzeLFi6NXr16x/vrrt3QrESH/oBq15PduGUi5cS1Lcym3/IuQgdBQvlesvXLLQPkH1acS7oObfAhSjJqamqipqVnleMeOHasq/FrVdCjpftX0a0d1q+S3y8o/qGzl8L1bBlIuyuHvA9WlkvMvQgZSnXyvKJ1KzkD5B5WtHLJ8TRnY5B+Y2r1795g7d269Y3Pnzo2OHTuudvoLkAr5B1QzGQhUMxkIVCv5B5SjJh+CDB48OKZMmVLv2AMPPBCDBw9u6lMDtCj5B1QzGQhUMxkIVCv5B5SjRg9Bli5dGs8991w899xzERHxzjvvxHPPPRczZ86MiP/9HL8jjjii7vk//OEP4+23345TTz01Xn311bjiiiti0qRJcdJJJ5XmFQA0E/kHVDMZCFQzGQhUK/kHpKDRQ5Cnn346tttuu9huu+0iImL06NGx3XbbxZlnnhkREf/85z/rgjAiol+/fnHPPffEAw88EAMGDIgLL7ww/vu//zuGDau+H1YFVDb5B1QzGQhUMxkIVCv5B6Qgl2VZ1tJNrMnixYujU6dOsWjRoqr6gUh9x9xT0v1mnL9vSfeDcpNiVqT4miBlLfm9O8W8SPE1VRPXsjSXVLMi1dcFn+V7xdpLMStSfE2Qskq4D27ynwkCAAAAAADQEgxBAAAAAACAJBmCAAAAAAAASTIEAQAAAAAAkmQIAgAAAAAAJMkQBAAAAAAASJIhCAAAAAAAkCRDEAAAAAAAIEmGIAAAAAAAQJIMQQAAAAAAgCQZggAAAAAAAEkyBAEAAAAAAJJkCAIAAAAAACTJEAQAAAAAAEiSIQgAAAAAAJAkQxAAAAAAACBJhiAAAAAAAECSDEEAAAAAAIAkGYIAAAAAAABJMgQBAAAAAACSZAgCAAAAAAAkyRAEAAAAAABIkiEIAAAAAACQJEMQAAAAAAAgSYYgAAAAAABAkgxBAAAAAACAJBmCAAAAAAAASTIEAQAAAAAAkmQIAgAAAAAAJMkQBAAAAAAASJIhCAAAAAAAkKSihiCXX3559O3bN9q1axeDBg2KJ598suDzL7nkkthiiy2iffv20atXrzjppJPi3//+d1ENA7Q0GQhUK/kHVDMZCFQzGQhUskYPQSZOnBijR4+OcePGxTPPPBMDBgyIYcOGxbx581b7/JtvvjnGjBkT48aNi1deeSWuu+66mDhxYvz0pz9d6+YBmpsMBKqV/AOqmQwEqpkMBCpdo4cgF110URxzzDFx5JFHxlZbbRVXXXVVdOjQIa6//vrVPv+xxx6LXXbZJQ499NDo27dv7LXXXnHIIYcUnBgvX748Fi9eXO8BUA6aOgPlH1CuXAMC1UwGAtXMfTBQ6Ro1BFmxYkVMmzYthg4d+p8NWrWKoUOHxtSpU1e7ZsiQITFt2rS6oHv77bfj3nvvjW984xt5zzN+/Pjo1KlT3aNXr16NaROgSTRHBso/oBy5BgSqmQwEqpn7YCAFbRrz5AULFsTKlSujW7du9Y5369YtXn311dWuOfTQQ2PBggWx6667RpZl8cknn8QPf/jDgm+BGzt2bIwePbru68WLFwtAoMU1RwbKP6AcuQYEqpkMBKqZ+2AgBUX9YPTGePjhh+O8886LK664Ip555pm4884745577olzzjkn75qampro2LFjvQdAJWpsBso/IBWuAYFqJgOBauY+GCg3jXonSOfOnaN169Yxd+7cesfnzp0b3bt3X+2aM844I773ve/F0UcfHRERX/nKV2LZsmXxgx/8IE4//fRo1arJ5zAAJSEDgWol/4BqJgOBaiYDgRQ0KnXatm0bAwcOjClTptQdq62tjSlTpsTgwYNXu+bDDz9cJdxat24dERFZljW2X4AWIwOBaiX/gGomA4FqJgOBFDTqnSAREaNHj46RI0fGDjvsEDvttFNccsklsWzZsjjyyCMjIuKII46IjTfeOMaPHx8REcOHD4+LLrootttuuxg0aFC8+eabccYZZ8Tw4cPrAhCgUshAoFrJP6CayUCgmslAoNI1eggyYsSImD9/fpx55pkxZ86c2HbbbWPy5Ml1PyBp5syZ9aa9P/vZzyKXy8XPfvazmD17dnTp0iWGDx8e5557buleBUAzkYFAtZJ/QDWTgUA1k4FApctlFfA+tMWLF0enTp1i0aJFVfXDkfqOuaek+804f9+S7gflJsWsSPE1Qcpa8nt3inmR4muqJq5laS6pZkWqrws+y/eKtZdiVqT4miBllXAf7CcRAQAAAAAASTIEAQAAAAAAkmQIAgAAAAAAJMkQBAAAAAAASJIhCAAAAAAAkCRDEAAAAAAAIEmGIAAAAAAAQJIMQQAAAAAAgCQZggAAAAAAAEkyBAEAAAAAAJJkCAIAAAAAACTJEAQAAAAAAEiSIQgAAAAAAJAkQxAAAAAAACBJhiAAAAAAAECSDEEAAAAAAIAkGYIAAAAAAABJMgQBAAAAAACSZAgCAAAAAAAkyRAEAAAAAABIkiEIAAAAAACQJEMQAAAAAAAgSYYgAAAAAABAkgxBAAAAAACAJBmCAAAAAAAASTIEAQAAAAAAkmQIAgAAAAAAJMkQBAAAAAAASJIhCAAAAAAAkCRDEAAAAAAAIEmGIAAAAAAAQJKKGoJcfvnl0bdv32jXrl0MGjQonnzyyYLPX7hwYYwaNSp69OgRNTU18aUvfSnuvffeohoGaGkyEKhW8g+oZjIQqGYyEKhkbRq7YOLEiTF69Oi46qqrYtCgQXHJJZfEsGHD4rXXXouuXbuu8vwVK1bE17/+9ejatWvcfvvtsfHGG8e7774bX/jCF0rRP0CzkoFAtZJ/QDWTgUA1k4FApWv0EOSiiy6KY445Jo488siIiLjqqqvinnvuieuvvz7GjBmzyvOvv/76eP/99+Oxxx6LddZZJyIi+vbtW/Acy5cvj+XLl9d9vXjx4sa2CdAkmjoD5R9QrlwDAtVMBgLVzH0wUOka9XFYK1asiGnTpsXQoUP/s0GrVjF06NCYOnXqatf88Y9/jMGDB8eoUaOiW7dusc0228R5550XK1euzHue8ePHR6dOneoevXr1akybAE2iOTJQ/gHlyDUgUM1kIFDN3AcDKWjUEGTBggWxcuXK6NatW73j3bp1izlz5qx2zdtvvx233357rFy5Mu69994444wz4sILL4yf//znec8zduzYWLRoUd1j1qxZjWkToEk0RwbKP6AcuQYEqpkMBKqZ+2AgBY3+OKzGqq2tja5du8Y111wTrVu3joEDB8bs2bPjl7/8ZYwbN261a2pqaqKmpqapWwNoco3NQPkHpMI1IFDNZCBQzdwHA+WmUUOQzp07R+vWrWPu3Ln1js+dOze6d+++2jU9evSIddZZJ1q3bl137Mtf/nLMmTMnVqxYEW3bti2ibYDmJwOBaiX/gGomA4FqJgOBFDTq47Datm0bAwcOjClTptQdq62tjSlTpsTgwYNXu2aXXXaJN998M2pra+uOvf7669GjRw+hB1QUGQhUK/kHVDMZCFQzGQikoFFDkIiI0aNHx7XXXhu//e1v45VXXokf/ehHsWzZsjjyyCMjIuKII46IsWPH1j3/Rz/6Ubz//vtxwgknxOuvvx733HNPnHfeeTFq1KjSvQqAZiIDgWol/4BqJgOBaiYDgUrX6J8JMmLEiJg/f36ceeaZMWfOnNh2221j8uTJdT8gaebMmdGq1X9mK7169Yr77rsvTjrppOjfv39svPHGccIJJ8Rpp51WulcB0ExkIFCt5B9QzWQgUM1kIFDpclmWZS3dxJosXrw4OnXqFIsWLYqOHTu2dDvNpu+Ye0q634zz9y3pflBuUsyKFF8TpKwlv3enmBcpvqZq4lqW5pJqVqT6uuCzfK9YeylmRYqvCVJWCffBjf44LAAAAAAAgEpgCAIAAAAAACTJEAQAAAAAAEiSIQgAAAAAAJAkQxAAAAAAACBJhiAAAAAAAECSDEEAAAAAAIAkGYIAAAAAAABJMgQBAAAAAACSZAgCAAAAAAAkyRAEAAAAAABIkiEIAAAAAACQJEMQAAAAAAAgSYYgAAAAAABAkgxBAAAAAACAJBmCAAAAAAAASTIEAQAAAAAAkmQIAgAAAAAAJMkQBAAAAAAASJIhCAAAAAAAkCRDEAAAAAAAIEmGIAAAAAAAQJIMQQAAAAAAgCQZggAAAAAAAEkyBAEAAAAAAJJkCAIAAAAAACTJEAQAAAAAAEiSIQgAAAAAAJAkQxAAAAAAACBJhiAAAAAAAECSDEEAAAAAAIAkFTUEufzyy6Nv377Rrl27GDRoUDz55JMNWnfrrbdGLpeL/fffv5jTApQFGQhUK/kHVDMZCFQzGQhUskYPQSZOnBijR4+OcePGxTPPPBMDBgyIYcOGxbx58wqumzFjRpxyyinx1a9+tehmAVqaDASqlfwDqpkMBKqZDAQqXaOHIBdddFEcc8wxceSRR8ZWW20VV111VXTo0CGuv/76vGtWrlwZhx12WJx99tmx6aabrvEcy5cvj8WLF9d7AJSDps5A+QeUK9eAQDWTgUA1cx8MVLpGDUFWrFgR06ZNi6FDh/5ng1atYujQoTF16tS86/7f//t/0bVr1zjqqKMadJ7x48dHp06d6h69evVqTJsATaI5MlD+AeXINSBQzWQgUM3cBwMpaNQQZMGCBbFy5cro1q1bvePdunWLOXPmrHbNo48+Gtddd11ce+21DT7P2LFjY9GiRXWPWbNmNaZNgCbRHBko/4By5BoQqGYyEKhm7oOBFLRpys2XLFkS3/ve9+Laa6+Nzp07N3hdTU1N1NTUNGFnAE2vmAyUf0AKXAMC1UwGAtXMfTBQjho1BOncuXO0bt065s6dW+/43Llzo3v37qs8/6233ooZM2bE8OHD647V1tb+74nbtInXXnstNttss2L6Bmh2MhCoVvIPqGYyEKhmMhBIQaM+Dqtt27YxcODAmDJlSt2x2tramDJlSgwePHiV52+55ZbxwgsvxHPPPVf32G+//WKPPfaI5557zmf8ARVFBgLVSv4B1UwGAtVMBgIpaPTHYY0ePTpGjhwZO+ywQ+y0005xySWXxLJly+LII4+MiIgjjjgiNt544xg/fny0a9cuttlmm3rrv/CFL0RErHIcoBLIQKBayT+gmslAoJrJQKDSNXoIMmLEiJg/f36ceeaZMWfOnNh2221j8uTJdT8gaebMmdGqVaPeYAJQMWQgUK3kH1DNZCBQzWQgUOlyWZZlLd3EmixevDg6deoUixYtio4dO7Z0O82m75h7SrrfjPP3Lel+UG5SzIoUXxOkrCW/d6eYFym+pmriWpbmkmpWpPq64LN8r1h7KWZFiq8JUlYJ98HGtAAAAAAAQJIMQQAAAAAAgCQZggAAAAAAAEkyBAEAAAAAAJJkCAIAAAAAACTJEAQAAAAAAEiSIQgAAAAAAJAkQxAAAAAAACBJhiAAAAAAAECSDEEAAAAAAIAkGYIAAAAAAABJMgQBAAAAAACSZAgCAAAAAAAkyRAEAAAAAABIkiEIAAAAAACQJEMQAAAAAAAgSYYgAAAAAABAkgxBAAAAAACAJBmCAAAAAAAASTIEAQAAAAAAkmQIAgAAAAAAJMkQBAAAAAAASJIhCAAAAAAAkCRDEAAAAAAAIEmGIAAAAAAAQJIMQQAAAAAAgCQZggAAAAAAAEkyBAEAAAAAAJJkCAIAAAAAACTJEAQAAAAAAEiSIQgAAAAAAJCkooYgl19+efTt2zfatWsXgwYNiieffDLvc6+99tr46le/GhtssEFssMEGMXTo0ILPByh3MhCoVvIPqGYyEKhmMhCoZI0egkycODFGjx4d48aNi2eeeSYGDBgQw4YNi3nz5q32+Q8//HAccsgh8dBDD8XUqVOjV69esddee8Xs2bPXunmA5iYDgWol/4BqJgOBaiYDgUqXy7Isa8yCQYMGxY477hiXXXZZRETU1tZGr1694rjjjosxY8ascf3KlStjgw02iMsuuyyOOOKI1T5n+fLlsXz58rqvFy9eHL169YpFixZFx44dG9NuRes75p6S7jfj/H1Luh+Um8WLF0enTp2aNCuaOgPlH1S2lvze3dQZ6BqQxnItS3NJ4RowQgZSnXyvWHspZKD8g8pWCffBjXonyIoVK2LatGkxdOjQ/2zQqlUMHTo0pk6d2qA9Pvzww/j4449jww03zPuc8ePHR6dOneoevXr1akybAE2iOTJQ/gHlyDUgUM1kIFDN3AcDKWjUEGTBggWxcuXK6NatW73j3bp1izlz5jRoj9NOOy169uxZLzw/b+zYsbFo0aK6x6xZsxrTJkCTaI4MlH9AOXINCFQzGQhUM/fBQAraNOfJzj///Lj11lvj4Ycfjnbt2uV9Xk1NTdTU1DRjZwBNryEZKP+AFLkGBKqZDASqmftgoBw0agjSuXPnaN26dcydO7fe8blz50b37t0Lrv3Vr34V559/fvz1r3+N/v37N75TgBYmA4FqJf+AaiYDgWomA4EUNOrjsNq2bRsDBw6MKVOm1B2rra2NKVOmxODBg/Ouu+CCC+Kcc86JyZMnxw477FB8twAtSAYC1Ur+AdVMBgLVTAYCKWj0x2GNHj06Ro4cGTvssEPstNNOcckll8SyZcviyCOPjIiII444IjbeeOMYP358RET84he/iDPPPDNuvvnm6Nu3b93nBa633nqx3nrrlfClADQ9GQhUK/kHVDMZCFQzGQhUukYPQUaMGBHz58+PM888M+bMmRPbbrttTJ48ue4HJM2cOTNatfrPG0yuvPLKWLFiRRxwwAH19hk3blycddZZa9c9QDOTgUC1kn9ANZOBQDWTgUCly2VZlrV0E2uyePHi6NSpUyxatCg6duzY0u00m75j7inpfjPO37ek+0G5STErUnxNkLKW/N6dYl6k+JqqiWtZmkuqWZHq64LP8r1i7aWYFSm+JkhZJdwHN+pnggAAAAAAAFQKQxAAAAAAACBJhiAAAAAAAECSDEEAAAAAAIAkGYIAAAAAAABJMgQBAAAAAACSZAgCAAAAAAAkyRAEAAAAAABIkiEIAAAAAACQJEMQAAAAAAAgSYYgAAAAAABAkgxBAAAAAACAJBmCAAAAAAAASTIEAQAAAAAAkmQIAgAAAAAAJMkQBAAAAAAASJIhCAAAAAAAkCRDEAAAAAAAIEmGIAAAAAAAQJIMQQAAAAAAgCQZggAAAAAAAEkyBAEAAAAAAJJkCAIAAAAAACTJEAQAAAAAAEiSIQgAAAAAAJAkQxAAAAAAACBJhiAAAAAAAECSDEEAAAAAAIAkGYIAAAAAAABJMgQBAAAAAACSZAgCAAAAAAAkqaghyOWXXx59+/aNdu3axaBBg+LJJ58s+Pzbbrstttxyy2jXrl185StfiXvvvbeoZgHKgQwEqpX8A6qZDASqmQwEKlmjhyATJ06M0aNHx7hx4+KZZ56JAQMGxLBhw2LevHmrff5jjz0WhxxySBx11FHx7LPPxv777x/7779/vPjii2vdPEBzk4FAtZJ/QDWTgUA1k4FApctlWZY1ZsGgQYNixx13jMsuuywiImpra6NXr15x3HHHxZgxY1Z5/ogRI2LZsmXx5z//ue7YzjvvHNtuu21cddVVqz3H8uXLY/ny5XVfL1q0KHr37h2zZs2Kjh07NqbdirbNuPtKut+LZw8r6X5QbhYvXhy9evWKhQsXRqdOnZrkHE2dgfIPKltLfu9u6gx0DUhjuZaluaRwDRghA6lOvlesvRQyUP5BZauI++CsEZYvX561bt06u+uuu+odP+KII7L99ttvtWt69eqVXXzxxfWOnXnmmVn//v3znmfcuHFZRHh4eHgU9Zg1a1Zjoq3BmiMD5Z+Hh8faPpoiA10Denh4VMKjkq8Bs0wGenh4rN2jkjNQ/nl4eKztY00Z2CYaYcGCBbFy5cro1q1bvePdunWLV199dbVr5syZs9rnz5kzJ+95xo4dG6NHj677ura2Nt5///3YaKONIpfLNablgj6dFDXlZLmpz5HCa3CO8tm/0s+RZVksWbIkevbsWbI9P6s5MlD+OYfscI5iNWUGugZ0DvmU/jkq+TWkcA0YIQPLaX/nKK9zpPAamvIcKWRgc+VfhD+v1XSOFF6Dc6xZQzOwUUOQ5lJTUxM1NTX1jn3hC19osvN17Nixyd9e19TnSOE1OEf57F/J52iqt/82F/nnHLLDOdaGDGycSv19TvEcKbyGVM5Rqa+h0vMvQgaW4/7OUV7nSOE1NNU5Kj0Dmzv/Ivx5raZzpPAanKOwhmRgo34weufOnaN169Yxd+7cesfnzp0b3bt3X+2a7t27N+r5AOVKBgLVSv4B1UwGAtVMBgIpaNQQpG3btjFw4MCYMmVK3bHa2tqYMmVKDB48eLVrBg8eXO/5EREPPPBA3ucDlCsZCFQr+QdUMxkIVDMZCKSg0R+HNXr06Bg5cmTssMMOsdNOO8Ull1wSy5YtiyOPPDIiIo444ojYeOONY/z48RERccIJJ8Tuu+8eF154Yey7775x6623xtNPPx3XXHNNaV9JEWpqamLcuHGrvOWuks6RwmtwjvLZP6VzNJVUMjCV32fnKI/9naP8ztEUUsm/iHR+n1M4RwqvIZVzpPAampIMLK9zpPAanKN89k/pHE1FBpbP/s5RPvs7R/mdo6CCPzY9j0svvTTr3bt31rZt22ynnXbKHn/88bra7rvvno0cObLe8ydNmpR96Utfytq2bZttvfXW2T333FPMaQHKggwEqpX8A6qZDASqmQwEKlkuy7KsZcYvAAAAAAAATadRPxMEAAAAAACgUhiCAAAAAAAASTIEAQAAAAAAkmQIAgAAAAAAJKlqhyCXX3559O3bN9q1axeDBg2KJ598sqT7//3vf4/hw4dHz549I5fLxd13313S/cePHx877rhjrL/++tG1a9fYf//947XXXivpOa688sro379/dOzYMTp27BiDBw+Ov/zlLyU9x2edf/75kcvl4sQTTyzZnmeddVbkcrl6jy233LJk+39q9uzZcfjhh8dGG20U7du3j6985Svx9NNPl2z/vn37rvI6crlcjBo1qmTnWLlyZZxxxhnRr1+/aN++fWy22WZxzjnnRJZlJTvHkiVL4sQTT4w+ffpE+/btY8iQIfHUU0+VbH8arikzsKnzL0IGNpQMbJjmyL8IGVhOKjkDU8y/iMrNwErPvwgZWG3cB6+Za8CGk4ENI//KRyVfA0bIwIaSgQ1TbdeAVTkEmThxYowePTrGjRsXzzzzTAwYMCCGDRsW8+bNK9k5li1bFgMGDIjLL7+8ZHt+1t/+9rcYNWpUPP744/HAAw/Exx9/HHvttVcsW7asZOfYZJNN4vzzz49p06bF008/Hf/n//yf+Na3vhUvvfRSyc7xqaeeeiquvvrq6N+/f8n33nrrreOf//xn3ePRRx8t6f4ffPBB7LLLLrHOOuvEX/7yl3j55ZfjwgsvjA022KBk53jqqafqvYYHHnggIiIOPPDAkp3jF7/4RVx55ZVx2WWXxSuvvBK/+MUv4oILLohLL720ZOc4+uij44EHHojf/e538cILL8Ree+0VQ4cOjdmzZ5fsHKxZU2dgU+dfhAxsDBm4Zs2RfxEysFxUegamln8RlZuBKeRfhAysJu6DG8Y1YMPIwIaTf+Wh0q8BI2RgY8jANau6a8CsCu20007ZqFGj6r5euXJl1rNnz2z8+PFNcr6IyO66664m2ftT8+bNyyIi+9vf/tak59lggw2y//7v/y7pnkuWLMm++MUvZg888EC2++67ZyeccELJ9h43blw2YMCAku23Oqeddlq26667Nuk5Pu+EE07INttss6y2trZke+67777Z97///XrHvvOd72SHHXZYSfb/8MMPs9atW2d//vOf6x3ffvvts9NPP70k56BhmjMDmyP/skwG5iMDG6ap8y/LZGA5SS0DKzn/sqyyMzCF/MsyGVhN3AcXzzXgqmRgw8i/8pHaNWCWycB8ZGDDVNs1YNW9E2TFihUxbdq0GDp0aN2xVq1axdChQ2Pq1Kkt2NnaWbRoUUREbLjhhk2y/8qVK+PWW2+NZcuWxeDBg0u696hRo2Lfffet93tSSm+88Ub07NkzNt100zjssMNi5syZJd3/j3/8Y+ywww5x4IEHRteuXWO77baLa6+9tqTn+KwVK1bE73//+/j+978fuVyuZPsOGTIkpkyZEq+//npERDz//PPx6KOPxj777FOS/T/55JNYuXJltGvXrt7x9u3bl3wiT34ysDgyML8UMrCp8y9CBpaLFDOwkvMvorIzMIX8i5CB1SLF/Iuo7Ays5PyLkIENJf/KgwwsjgzML4UMrLprwGYduZSB2bNnZxGRPfbYY/WO/+QnP8l22mmnJjlnNPEEeOXKldm+++6b7bLLLiXfe/r06dm6666btW7dOuvUqVN2zz33lHT/W265Jdtmm22yjz76KMuyrOTT33vvvTebNGlS9vzzz2eTJ0/OBg8enPXu3TtbvHhxyc5RU1OT1dTUZGPHjs2eeeaZ7Oqrr87atWuX3XjjjSU7x2dNnDgxa926dTZ79uyS7rty5crstNNOy3K5XNamTZssl8tl5513XknPMXjw4Gz33XfPZs+enX3yySfZ7373u6xVq1bZl770pZKeh/yaOwObOv+yTAYWIgMbpjnyL8tkYDlILQMrOf+yrPIzMIX8yzIZWC3cBzeOa8A1k4ENJ/9aXmrXgFkmAwuRgQ1TbdeAhiD/v0q++PvhD3+Y9enTJ5s1a1bJ916+fHn2xhtvZE8//XQ2ZsyYrHPnztlLL71Ukr1nzpyZde3aNXv++efrjpU6+D7vgw8+yDp27FjSt/Gts8462eDBg+sdO+6447Kdd965ZOf4rL322iv75je/WfJ9b7nllmyTTTbJbrnllmz69OnZTTfdlG244YYlDfA333wz22233bKIyFq3bp3tuOOO2WGHHZZtueWWJTsHhaV48ScDG04Grl5z5F+WycBykFoGVmr+ZVkaGZhC/mWZDKwW7oMbxzXgmsnAhpN/LS+1a8Ask4GNIQNXr9quAatuCLJ8+fKsdevWq4TREUccke23335Ncs6mDL9Ro0Zlm2yySfb22283yf6ft+eee2Y/+MEPSrLXXXfdVfcX4NNHRGS5XC5r3bp19sknn5TkPJ+3ww47ZGPGjCnZfr17986OOuqoeseuuOKKrGfPniU7x6dmzJiRtWrVKrv77rtLvvcmm2ySXXbZZfWOnXPOOdkWW2xR8nMtXbo0+5//+Z8sy7LsoIMOyr7xjW+U/BysXnNnYFNf/MnAxpOBq2rO/MsyGdiSUsrASs6/LEsjA1PIvyyTgdXCffDacQ24KhnYePKv5aR0DZhlMrAYMnBV1XYNWHU/E6Rt27YxcODAmDJlSt2x2tramDJlSpN8znFTybIsjj322LjrrrviwQcfjH79+jXLeWtra2P58uUl2WvPPfeMF154IZ577rm6xw477BCHHXZYPPfcc9G6deuSnOezli5dGm+99Vb06NGjZHvusssu8dprr9U79vrrr0efPn1Kdo5P3XDDDdG1a9fYd999S773hx9+GK1a1Y+E1q1bR21tbcnPte6660aPHj3igw8+iPvuuy++9a1vlfwcrJ4MXDsycFUpZGBz5l+EDGxJKWRgCvkXkUYGppB/ETKwWqSQfxFpZGAK+RchA4sh/1qODFw7MnBVKWRg1V0DNuvIpUzceuutWU1NTXbjjTdmL7/8cvaDH/wg+8IXvpDNmTOnZOdYsmRJ9uyzz2bPPvtsFhHZRRddlD377LPZu+++W5L9f/SjH2WdOnXKHn744eyf//xn3ePDDz8syf5ZlmVjxozJ/va3v2XvvPNONn369GzMmDFZLpfL7r///pKd4/NK/Ra4k08+OXv44Yezd955J/vHP/6RDR06NOvcuXM2b968kp3jySefzNq0aZOde+652RtvvJFNmDAh69ChQ/b73/++ZOfIsv/9rL7evXtnp512Wkn3/dTIkSOzjTfeOPvzn/+cvfPOO9mdd96Zde7cOTv11FNLdo7Jkydnf/nLX7K33347u//++7MBAwZkgwYNylasWFGyc7BmTZ2BTZ1/WSYDG0oGNkxz5F+WycByUekZmGr+ZVnlZWAK+ZdlMrCauA9uGNeADSMDG07+lYdKvwbMMhnYUDKwYartGrAqhyBZlmWXXnpp1rt376xt27bZTjvtlD3++OMl3f+hhx7KImKVx8iRI0uy/+r2jojshhtuKMn+WZZl3//+97M+ffpkbdu2zbp06ZLtueeeFXfzO2LEiKxHjx5Z27Zts4033jgbMWJE9uabb5Zs/0/96U9/yrbZZpuspqYm23LLLbNrrrmm5Oe47777sojIXnvttZLvnWVZtnjx4uyEE07IevfunbVr1y7bdNNNs9NPPz1bvnx5yc4xceLEbNNNN83atm2bde/ePRs1alS2cOHCku1PwzVlBjZ1/mWZDGwoGdgwzZF/WSYDy0klZ2Cq+ZdllZmBlZ5/WSYDq4374DVzDdhwMrBh5F/5qORrwCyTgQ0lAxum2q4Bc1mWZWv9dhIAAAAAAIAyU3U/EwQAAAAAAKgOhiAAAAAAAECSDEEAAAAAAIAkGYIAAAAAAABJMgQBAAAAAACSZAgCAAAAAAAkyRAEAAAAAABIkiEIAAAAAACQJEMQAAAAAAAgSYYgAAAAAABAkgxBAAAAAACAJP1/JiXX8bNMrVAAAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import numpy as np\n",
        "# import matplotlib.pyplot as plt\n",
        "\n",
        "# h = 0.05\n",
        "# x_min, x_max = X[:,0].min() - 1, X[:,0].max() + 1\n",
        "# y_min, y_max = X[:,1].min() - 1, X[:,1].max() + 1\n",
        "\n",
        "# xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n",
        "#                      np.arange(y_min, y_max, h))\n",
        "\n",
        "# grid_points = np.c_[xx.ravel(), yy.ravel()]\n",
        "\n",
        "# preds = predict(grid_points, weights, biases)\n",
        "\n",
        "# Z = (preds > 0.5).astype(int)\n",
        "# Z = Z.reshape(xx.shape)\n",
        "\n",
        "\n",
        "# plt.figure(figsize=(8,6))\n",
        "# plt.contourf(xx, yy, Z, alpha=0.3, cmap=plt.cm.RdBu)\n",
        "\n",
        "# plt.scatter(class0_points[:, 0], class0_points[:, 1], c='blue', label='Class 0 (Inner)', alpha=0.7)\n",
        "# plt.scatter(class1_points[:, 0], class1_points[:, 1], c='red', label='Class 1 (Outer)', alpha=0.7)\n",
        "\n",
        "# plt.title(\"Decision Boundary\")\n",
        "# plt.xlabel(\"Feature 1\")\n",
        "# plt.ylabel(\"Feature 2\")\n",
        "# plt.legend()\n",
        "# plt.grid(True)\n",
        "# plt.gca().set_aspect('equal', adjustable='box')\n",
        "# plt.show()\n"
      ],
      "metadata": {
        "id": "yoUkunx185nD"
      },
      "execution_count": 413,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2BUbd2vyiFKN"
      },
      "execution_count": 413,
      "outputs": []
    }
  ]
}