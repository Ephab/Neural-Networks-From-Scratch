{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "pGGkE4BAep1f"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "np.set_printoptions(suppress=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# #Binary classification\n",
        "# import matplotlib.pyplot as plt\n",
        "\n",
        "# # random dataset\n",
        "\n",
        "# NUM_SAMPLES_PER_CLASS = 200\n",
        "# INNER_RADIUS = 2\n",
        "# OUTER_RADIUS = 5\n",
        "# NOISE_STD_DEV = 0.5\n",
        "\n",
        "# theta_inner = 2 * np.pi * np.random.rand(NUM_SAMPLES_PER_CLASS)\n",
        "\n",
        "# radius_inner = INNER_RADIUS * np.random.rand(NUM_SAMPLES_PER_CLASS) + np.random.normal(0, NOISE_STD_DEV, NUM_SAMPLES_PER_CLASS)\n",
        "# x0 = radius_inner * np.cos(theta_inner)\n",
        "# y0 = radius_inner * np.sin(theta_inner)\n",
        "# class0_points = np.vstack([x0, y0]).T\n",
        "# class0_labels = np.zeros(NUM_SAMPLES_PER_CLASS)\n",
        "\n",
        "# theta_outer = 2 * np.pi * np.random.rand(NUM_SAMPLES_PER_CLASS)\n",
        "\n",
        "# radius_outer = np.random.uniform(INNER_RADIUS + 1, OUTER_RADIUS, NUM_SAMPLES_PER_CLASS) + np.random.normal(0, NOISE_STD_DEV, NUM_SAMPLES_PER_CLASS)\n",
        "# x1 = radius_outer * np.cos(theta_outer)\n",
        "# y1 = radius_outer * np.sin(theta_outer)\n",
        "# class1_points = np.vstack([x1, y1]).T\n",
        "# class1_labels = np.ones(NUM_SAMPLES_PER_CLASS)\n",
        "\n",
        "\n",
        "# X = np.vstack([class0_points, class1_points])\n",
        "# y = np.hstack([class0_labels, class1_labels])\n",
        "# y = y.reshape(-1, 1) # stupid broadcasting bug that i spent an hour on -.-\n",
        "\n",
        "\n",
        "# plt.figure(figsize=(8, 6))\n",
        "\n",
        "# plt.scatter(class0_points[:, 0], class0_points[:, 1], c='blue', label='Class 0 (Inner)', alpha=0.7)\n",
        "\n",
        "# plt.scatter(class1_points[:, 0], class1_points[:, 1], c='red', label='Class 1 (Outer)', alpha=0.7)\n",
        "# plt.title('Concentric Rings Dataset')\n",
        "# plt.xlabel('Feature 1')\n",
        "# plt.ylabel('Feature 2')\n",
        "# plt.legend()\n",
        "# plt.grid(True)\n",
        "# plt.gca().set_aspect('equal', adjustable='box')\n",
        "# plt.show()"
      ],
      "metadata": {
        "id": "0Wsu6mPtfNcy"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Mnist dataset\n",
        "import copy\n",
        "from tensorflow.keras.datasets import mnist\n",
        "\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "\n",
        "X_train = (X_train.astype('float64') / 255.0).reshape(-1,28*28)\n",
        "X_test = (X_test.astype('float64') / 255.0).reshape(-1,28*28)\n",
        "\n",
        "X_test_copy = copy.deepcopy(X_test)\n",
        "y_test_copy = copy.deepcopy(y_test)\n",
        "\n",
        "X = X_train#[:2000,:]\n",
        "y = y_train.reshape(60000, -1)#[:2000,:]\n",
        "X_test = X_test#[:1000,:]\n",
        "y_test = y_test.reshape(-1,1)#[:1000, :]"
      ],
      "metadata": {
        "id": "_rV-2-fY5Ske"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X.shape, y.shape, X_test.shape, y_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Z1MPju7fNj6",
        "outputId": "7075029e-fe8f-4cfd-fcd9-f12686889330"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((60000, 784), (60000, 1), (10000, 784), (10000, 1))"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def one_hot_encoding(vector):\n",
        "    vector = np.array(vector).astype(int).flatten()\n",
        "    # if vector.ndim == 1:\n",
        "    #     return vector\n",
        "    size=len(vector)\n",
        "    num_classes = max(np.max(vector) + 1, 10)\n",
        "\n",
        "    encoded_matrix = np.zeros((size, num_classes))\n",
        "    encoded_matrix[np.arange(size), vector] = 1\n",
        "    return encoded_matrix"
      ],
      "metadata": {
        "id": "wsCbSo0pwQ_l"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_test_split(X, y, test_size=0.2):\n",
        "    num_samples = X.shape[0]\n",
        "    train_size = int(np.ceil(num_samples * (1-test_size)))\n",
        "    test_size = int(np.floor(num_samples * test_size))\n",
        "\n",
        "    shuffled_indices = np.arange(num_samples)\n",
        "    np.random.shuffle(shuffled_indices)\n",
        "    X = X[shuffled_indices]\n",
        "    y= y[shuffled_indices]\n",
        "\n",
        "    X_train = X[:train_size, :]\n",
        "    y_train = y[:train_size,]\n",
        "    X_test = X[train_size:]\n",
        "    y_test = y[train_size:]\n",
        "\n",
        "    return X_train, y_train, X_test, y_test"
      ],
      "metadata": {
        "id": "fQo6YdzuK3sk"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# X_train, y_train, X_test, y_test = train_test_split(X, y)"
      ],
      "metadata": {
        "id": "DTUH6FEGOrcz"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def initialize_weights_and_biases(m_inputs, layer_sizes:list, initialization='scaled'):\n",
        "    weights = {}\n",
        "    biases = {}\n",
        "\n",
        "    layers = [m_inputs] + layer_sizes\n",
        "\n",
        "    if initialization == 'scaled':\n",
        "        for i in range(len(layers)-1):\n",
        "            weights[\"W\" + str(i+1)] = np.random.randn(layers[i], layers[i+1]) * 0.01\n",
        "            biases[\"b\" + str(i+1)] = np.zeros((1, layers[i+1]))\n",
        "\n",
        "    elif initialization == 'xavier':\n",
        "        for i in range(len(layers)-1):\n",
        "            variance = 2 / (layers[i] + layers[i+1])\n",
        "            weights[\"W\" + str(i+1)] = np.random.randn(layers[i], layers[i+1]) * np.sqrt(variance)\n",
        "            biases[\"b\" + str(i+1)] = np.zeros((1, layers[i+1]))\n",
        "\n",
        "    elif initialization == 'he':\n",
        "        for i in range(len(layers)-1):\n",
        "            variance = 2 / (layers[i])\n",
        "            weights[\"W\" + str(i+1)] = np.random.randn(layers[i], layers[i+1]) * np.sqrt(variance)\n",
        "            biases[\"b\" + str(i+1)] = np.zeros((1, layers[i+1]))\n",
        "\n",
        "    else:\n",
        "        for i in range(len(layers)-1):\n",
        "            weights[\"W\" + str(i+1)] = np.random.randn(layers[i], layers[i+1])\n",
        "            biases[\"b\" + str(i+1)] = np.zeros((1, layers[i+1]))\n",
        "\n",
        "    # print(f\"Successfully initialized weights and biases for {len(layer_sizes)} layers\")\n",
        "    return weights, biases\n"
      ],
      "metadata": {
        "id": "pOIC9U5BfNo3"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sigmoid(z):\n",
        "    return 1 / (1 + np.exp(-z))\n",
        "\n",
        "def relu(z):\n",
        "    return np.maximum(0,z)\n",
        "\n",
        "def softmax(z):\n",
        "    exponent_values = np.exp(z - np.max(z, axis=1, keepdims=True))\n",
        "    return exponent_values / np.sum(exponent_values, axis=1, keepdims=True)"
      ],
      "metadata": {
        "id": "9NQVMamKbrlu"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def forward(A, weights, biases, activation_function, dropout=False, keep_prob=1):\n",
        "    Z_dict = {}\n",
        "    A_dict = {}\n",
        "    A_dict[\"A0\"] = A\n",
        "    l_dict = {}\n",
        "    dropouts = {}\n",
        "\n",
        "    if activation_function == 'relu':\n",
        "        activation_function = relu\n",
        "    else:\n",
        "        activation_function = sigmoid\n",
        "\n",
        "    for i in range(len(weights)-1): #loop through hidden layers\n",
        "        a_prev = A\n",
        "        Z = np.dot(a_prev, weights[\"W\" + str(i+1)]) + biases[\"b\" + str(i+1)]\n",
        "        Z_dict[\"Z\" + str(i+1)] = Z\n",
        "        A = activation_function(Z)\n",
        "\n",
        "        if dropout == True:\n",
        "            dropout_mask = (np.random.rand(A.shape[0], A.shape[1]) < keep_prob).astype(int)\n",
        "            A *= dropout_mask\n",
        "            A /= keep_prob\n",
        "            dropouts['A' + str(i+1)] = dropout_mask\n",
        "\n",
        "        A_dict[\"A\" + str(i+1)] = A\n",
        "        l_dict['layer' + str(i+1)] = activation_function.__name__\n",
        "\n",
        "    last_index = len(weights)\n",
        "\n",
        "    if weights[list(weights.keys())[-1]].shape[1] == 1:\n",
        "        output_activation = sigmoid\n",
        "    else:\n",
        "        output_activation = softmax\n",
        "\n",
        "    a_prev = A\n",
        "    Z = np.dot(a_prev, weights[\"W\" + str(last_index)]) + biases[\"b\" + str(last_index)]\n",
        "    Z_dict[\"Z\" + str(last_index)] = Z\n",
        "    A = output_activation(Z)\n",
        "    A_dict[\"A\" + str(last_index)] = A\n",
        "    l_dict['layer' + str(last_index)] = output_activation.__name__\n",
        "\n",
        "\n",
        "    dropouts['keep_prob'] = keep_prob\n",
        "\n",
        "    cache = {\"Z\":Z_dict,\n",
        "             \"A\":A_dict,\n",
        "             'layer_activations':l_dict,\n",
        "             'dropouts' : dropouts}\n",
        "\n",
        "    # print(\"Successfully computed a forward pass\")\n",
        "    return cache"
      ],
      "metadata": {
        "id": "A_sdeVp1fNq3"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_loss(y_pred, y_true, weights, loss='binary_cross_entropy', regularization='l2', reg_lambda=0):\n",
        "    epsilon = 1e-8\n",
        "    num_samples = y_pred.shape[0]\n",
        "    weight_loss = 0\n",
        "\n",
        "    if regularization == 'l2':\n",
        "        weight_loss = (reg_lambda / (2*num_samples))* np.sum([np.sum(weight ** 2) for _, weight in weights.items()])\n",
        "\n",
        "    if loss == 'cross_entropy':\n",
        "        return - np.mean(np.sum(y_true * np.log(y_pred + epsilon), axis=1)) + weight_loss\n",
        "    else:\n",
        "        return - np.mean(y_true * np.log(y_pred + epsilon) + (1-y_true)*np.log(1-y_pred + epsilon)) + weight_loss # added 1e-8 to avoid log(0)"
      ],
      "metadata": {
        "id": "11iGNgXdoPaN"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sigmoid_derivative(z):\n",
        "    s = sigmoid(z)\n",
        "    return s * (1 - s)\n",
        "\n",
        "def relu_derivative(z):\n",
        "    return (z > 0).astype(float)"
      ],
      "metadata": {
        "id": "Cpa39xURvtTr"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def backpropagation(X, y, weights, biases, cache, regularization=None, reg_lambda=0, dropout=False):\n",
        "\n",
        "    activation_derivative = sigmoid_derivative\n",
        "\n",
        "    A_cache = cache['A']\n",
        "    Z_cache = cache['Z']\n",
        "    L_cache = cache['layer_activations']\n",
        "    dropouts = cache['dropouts']\n",
        "    keep_prob = dropouts['keep_prob']\n",
        "\n",
        "    Z_gradients = {}\n",
        "    A_gradients = {}\n",
        "    W_gradients = {}\n",
        "    b_gradients = {}\n",
        "\n",
        "    m = X.shape[0]\n",
        "\n",
        "    for i in reversed(range(len(weights))):\n",
        "        if L_cache['layer' + str(i+1)] == 'relu':\n",
        "            activation_derivative = relu_derivative\n",
        "        if L_cache['layer' + str(i+1)] == 'sigmoid':\n",
        "            activation_derivative = sigmoid_derivative\n",
        "\n",
        "\n",
        "        if i+1 == len(weights): #special case for first dZ\n",
        "            dZ = A_cache[\"A\" + str(i+1)] - y\n",
        "            Z_gradients[\"dZ\" + str(i+1)] = dZ\n",
        "            W_gradients[\"dW\" + str(i+1)] = np.dot(A_cache[\"A\" + str(i)].T,dZ) / m\n",
        "            b_gradients[\"db\" + str(i+1)] = np.sum(dZ, axis=0, keepdims=True) / m\n",
        "\n",
        "            #adding regularization gradient\n",
        "            if regularization == 'l2':\n",
        "                W_gradients[\"dW\" + str(i+1)] += (reg_lambda / m) * weights['W' + str(i+1)]\n",
        "\n",
        "        else: #hidden layers\n",
        "\n",
        "            dZ = np.dot(Z_gradients[\"dZ\" + str(i+2)], weights[\"W\" + str(i+2)].T) * activation_derivative(Z_cache[\"Z\" + str(i+1)])\n",
        "\n",
        "            if dropout == True:\n",
        "                if 'A' + str(i+1) in dropouts:\n",
        "                    dZ *= dropouts['A' + str(i+1)]\n",
        "                    dZ /= keep_prob\n",
        "\n",
        "            Z_gradients[\"dZ\" + str(i+1)] = dZ\n",
        "            W_gradients[\"dW\" + str(i+1)] = np.dot(A_cache[\"A\" + str(i)].T, dZ) / m\n",
        "            b_gradients[\"db\" + str(i+1)] = np.sum(dZ, axis=0, keepdims=True) / m\n",
        "\n",
        "\n",
        "            #adding regularization gradient\n",
        "            if regularization == 'l2':\n",
        "                W_gradients[\"dW\" + str(i+1)] += (reg_lambda / m) * weights['W' + str(i+1)]\n",
        "\n",
        "        # print(f\"Layer {i+1} dW magnitude: {np.linalg.norm(W_gradients['dW' + str(i+1)])}\")\n",
        "        # print(f\"Layer {i+1} db magnitude: {np.linalg.norm(b_gradients['db' + str(i+1)])}\")\n",
        "\n",
        "    grads = {\"dW\" : W_gradients,\n",
        "             \"db\" : b_gradients}\n",
        "\n",
        "    return grads"
      ],
      "metadata": {
        "id": "oBO-AJcSpSct"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "weights, biases = initialize_weights_and_biases(m_inputs=784, layer_sizes=[256, 10], initialization='he')"
      ],
      "metadata": {
        "id": "h6yc6ghG8j84"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Vdw = {}\n",
        "Vdb = {}\n",
        "Sdw = {}\n",
        "Sdb = {}\n",
        "Vdw_corrected = {}\n",
        "Vdb_corrected = {}\n",
        "Sdw_corrected = {}\n",
        "Sdb_corrected = {}\n",
        "\n",
        "t = 1\n",
        "\n",
        "for i in range(len(weights)):\n",
        "    Vdw['w' + str(i+1)] = np.zeros_like(weights['W' + str(i+1)])\n",
        "    Vdb['b' + str(i+1)] = np.zeros_like(biases['b' + str(i+1)])\n",
        "\n",
        "    Sdw['w' + str(i+1)] = np.zeros_like(weights['W' + str(i+1)])\n",
        "    Sdb['b' + str(i+1)] = np.zeros_like(biases['b' + str(i+1)])\n",
        "\n",
        "\n",
        "def update_params(grads, weights, biases, learning_rate, optimizer='gd', beta1=0.9, beta2=0.999, epsilon=1e-8):\n",
        "\n",
        "    dw = grads['dW']\n",
        "    db = grads['db']\n",
        "\n",
        "    global t\n",
        "\n",
        "    if optimizer == 'momentum':\n",
        "      for i in range(len(weights)):\n",
        "        Vdw['w' + str(i+1)] = beta1 * Vdw['w' + str(i+1)] + ((1-beta1) * dw['dW' + str(i+1)])\n",
        "        weights[\"W\" + str(i+1)] = weights[\"W\" + str(i+1)] - learning_rate * Vdw['w' + str(i+1)]\n",
        "\n",
        "        Vdb['b' + str(i+1)] = beta1 * Vdb['b' + str(i+1)] + ((1-beta1) * db[\"db\" + str(i+1)])\n",
        "        biases[\"b\" + str(i+1)] = biases[\"b\" + str(i+1)] - learning_rate * Vdb['b' + str(i+1)]\n",
        "\n",
        "    elif optimizer == 'rmsprop':\n",
        "        for i in range(len(weights)):\n",
        "            Sdw['w' + str(i+1)] = beta2 * Sdw['w' + str(i+1)] + ((1-beta2) * (dw['dW' + str(i+1)])**2)\n",
        "            weights[\"W\" + str(i+1)] = weights[\"W\" + str(i+1)] - learning_rate * ((dw['dW' + str(i+1)])/(np.sqrt(Sdw['w' + str(i+1)] + epsilon)))\n",
        "\n",
        "            # print(np.sqrt(Sdw['w1'] + epsilon))\n",
        "\n",
        "            Sdb['b' + str(i+1)] = beta2 * Sdb['b' + str(i+1)] + ((1-beta2) * (db['db' + str(i+1)])**2)\n",
        "            biases[\"b\" + str(i+1)] = biases[\"b\" + str(i+1)] - learning_rate * ((db['db' + str(i+1)])/(np.sqrt(Sdb['b' + str(i+1)] + epsilon)))\n",
        "\n",
        "    elif optimizer == 'adam':\n",
        "        for i in range(len(weights)):\n",
        "            Vdw['w' + str(i+1)] = beta1 * Vdw['w' + str(i+1)] + ((1-beta1) * dw['dW' + str(i+1)])\n",
        "            Sdw['w' + str(i+1)] = beta2 * Sdw['w' + str(i+1)] + ((1-beta2) * (dw['dW' + str(i+1)])**2)\n",
        "\n",
        "            Vdb['b' + str(i+1)] = beta1 * Vdb['b' + str(i+1)] + ((1-beta1) * db[\"db\" + str(i+1)])\n",
        "            Sdb['b' + str(i+1)] = beta2 * Sdb['b' + str(i+1)] + ((1-beta2) * (db['db' + str(i+1)])**2)\n",
        "\n",
        "\n",
        "            #bias correction\n",
        "            Vdw_corrected['w' + str(i+1)] = Vdw['w' + str(i+1)] / (1-beta1**t)\n",
        "            Vdb_corrected['b' + str(i+1)] = Vdb['b' + str(i+1)] / (1-beta1**t)\n",
        "\n",
        "            Sdw_corrected['w' + str(i+1)] = Sdw['w' + str(i+1)] / (1-beta2**t)\n",
        "            Sdb_corrected['b' + str(i+1)] = Sdb['b' + str(i+1)] / (1-beta2**t)\n",
        "\n",
        "\n",
        "            weights[\"W\" + str(i+1)] = weights[\"W\" + str(i+1)] - learning_rate * (Vdw_corrected['w' + str(i+1)] / np.sqrt(Sdw_corrected['w' + str(i+1)] + epsilon))\n",
        "            biases['b' + str(i+1)] = biases['b' + str(i+1)] - learning_rate * (Vdb_corrected['b' + str(i+1)] / np.sqrt(Sdb_corrected['b' + str(i+1)] + epsilon))\n",
        "\n",
        "        t += 1\n",
        "\n",
        "    else: #normal gd\n",
        "        for i in range(len(weights)):\n",
        "            weights[\"W\" + str(i+1)] = weights[\"W\" + str(i+1)] - learning_rate * dw[\"dW\" + str(i+1)]\n",
        "            biases[\"b\" + str(i+1)] = biases[\"b\" + str(i+1)] - learning_rate * db[\"db\" + str(i+1)]\n",
        "\n",
        "    # print(\"Successfully updated params\")\n",
        "    return weights, biases"
      ],
      "metadata": {
        "id": "djF7hwUtxlyr"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(X, weights, biases):\n",
        "    cache = forward(X, weights, biases, activation_function='relu', dropout=False)\n",
        "    prediction = cache['A'][list(cache['A'].keys())[-1]]\n",
        "    return prediction"
      ],
      "metadata": {
        "id": "uLU5V7b0y80T"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if len(np.unique(y)) > 2:\n",
        "    y = one_hot_encoding(y)\n",
        "    y_test = one_hot_encoding(y_test)\n",
        "    classification_type = 'multi'\n",
        "else:\n",
        "    classification_type = 'single'\n",
        "\n",
        "\n",
        "def accuracy(prediction, labels):\n",
        "    total = len(labels)\n",
        "\n",
        "    if classification_type == 'single':\n",
        "        acc = np.sum((prediction > 0.5).astype(int) == labels) / total\n",
        "    else:\n",
        "        predicted_class = np.argmax(prediction, axis=1)\n",
        "        true_class = np.argmax(labels, axis=1)\n",
        "        acc = np.mean(predicted_class == true_class)\n",
        "    return acc\n"
      ],
      "metadata": {
        "id": "YAN6QKh0HlhD"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run(epochs, learning_rate, optimizer='gd', beta1=0.9, beta2=0.999, regularization='l2', reg_lambda=0, dropout=False, keep_prob=1):\n",
        "\n",
        "    for i in range(epochs):\n",
        "        cache = forward(X, weights, biases, activation_function='relu', dropout=dropout, keep_prob=keep_prob)\n",
        "        prediction = cache['A'][list(cache['A'].keys())[-1]]\n",
        "        grads = backpropagation(X, y, weights, biases, cache, regularization=regularization, reg_lambda=reg_lambda, dropout=dropout)\n",
        "\n",
        "        if i % 100 == 0:\n",
        "            dev_predictions = predict(X_test, weights, biases)\n",
        "            print(f\"epoch: {i}, loss= {calculate_loss(prediction, y, loss='cross_entropy' if classification_type=='multi' else 'binary_cross_entropy', weights=weights, regularization=regularization, reg_lambda=reg_lambda)}, training-set accuracy= {accuracy(prediction, y)}, dev-set accuracy= {accuracy(dev_predictions, y_test)}\")\n",
        "\n",
        "        update_params(grads, weights, biases, learning_rate, optimizer=optimizer, beta1=beta1, beta2=beta2)"
      ],
      "metadata": {
        "id": "bE-obYbZv2Lb"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run_mini_batches(epochs, learning_rate, mini_batch_size=64, optimizer='gd', beta1=0.9, beta2=0.999, regularization='l2', reg_lambda=0, dropout=False, keep_prob=1):\n",
        "\n",
        "    num_samples = X.shape[0]\n",
        "    div = int(num_samples / mini_batch_size)\n",
        "\n",
        "    divisible_by_mini_batch_size = mini_batch_size * div\n",
        "    not_divisible = num_samples - divisible_by_mini_batch_size\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        shuffled_indices = np.arange(num_samples)\n",
        "        np.random.shuffle(shuffled_indices)\n",
        "        X_shuffled = X[shuffled_indices]\n",
        "        y_shuffled = y[shuffled_indices]\n",
        "\n",
        "        start = 0\n",
        "        end = 0\n",
        "        for batch in range(start, divisible_by_mini_batch_size, mini_batch_size):\n",
        "            start = end\n",
        "            end = start + mini_batch_size\n",
        "            X_batch = X_shuffled[start:end, :]\n",
        "            y_batch = y_shuffled[start:end]\n",
        "\n",
        "            #forward\n",
        "            cache = forward(X_batch, weights, biases, activation_function='relu', dropout=dropout, keep_prob=keep_prob)\n",
        "            prediction = cache['A'][list(cache['A'].keys())[-1]]\n",
        "            #backward\n",
        "            grads = backpropagation(X_batch, y_batch, weights, biases, cache, regularization=regularization, reg_lambda=reg_lambda, dropout=dropout)\n",
        "            #update\n",
        "            update_params(grads, weights, biases, learning_rate, optimizer=optimizer, beta1=beta1, beta2=beta2)\n",
        "\n",
        "        if not_divisible != 0:\n",
        "            X_batch = X_shuffled[divisible_by_mini_batch_size:, :]\n",
        "            y_batch = y_shuffled[divisible_by_mini_batch_size:]\n",
        "            #forward\n",
        "            cache = forward(X_batch, weights, biases, activation_function='relu', dropout=dropout, keep_prob=keep_prob)\n",
        "            prediction = cache['A'][list(cache['A'].keys())[-1]]\n",
        "            #backward\n",
        "            grads = backpropagation(X_batch, y_batch, weights, biases, cache, regularization=regularization, reg_lambda=reg_lambda, dropout=dropout)\n",
        "            #update\n",
        "            update_params(grads, weights, biases, learning_rate, optimizer=optimizer, beta1=beta1, beta2=beta2)\n",
        "\n",
        "        cache = forward(X, weights, biases, activation_function='relu', dropout=False)\n",
        "        full_prediction = cache['A'][list(cache['A'].keys())[-1]]\n",
        "        dev_predictions = predict(X_test, weights, biases)\n",
        "        print(f\"epoch: {epoch+1}, loss= {calculate_loss(full_prediction, y, loss='cross_entropy' if classification_type=='multi' else 'binary_cross_entropy', weights=weights, regularization=regularization, reg_lambda=reg_lambda)}, training-set accuracy= {accuracy(full_prediction, y)}, dev-set accuracy= {accuracy(dev_predictions, y_test)}\")\n"
      ],
      "metadata": {
        "id": "AgzrO6SZBrIw"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# run(epochs=10000, learning_rate=0.005)"
      ],
      "metadata": {
        "id": "4oMThHvuwDdK"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "run_mini_batches(epochs=10, learning_rate=0.0005, mini_batch_size=32, optimizer='adam', beta1=0.9, beta2=0.999, regularization='l2', reg_lambda=0.09, keep_prob=0.7, dropout=True)"
      ],
      "metadata": {
        "id": "zq_460UVTJVT",
        "outputId": "5fa35898-17ec-4cff-fb4b-35e99280b27d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 1, loss= 0.16872591702797018, training-set accuracy= 0.95415, dev-set accuracy= 0.9524\n",
            "epoch: 2, loss= 0.13509876566372322, training-set accuracy= 0.96285, dev-set accuracy= 0.9616\n",
            "epoch: 3, loss= 0.11941247844702362, training-set accuracy= 0.96725, dev-set accuracy= 0.9663\n",
            "epoch: 4, loss= 0.12012740727428738, training-set accuracy= 0.9679, dev-set accuracy= 0.966\n",
            "epoch: 5, loss= 0.11601953335876405, training-set accuracy= 0.96965, dev-set accuracy= 0.9668\n",
            "epoch: 6, loss= 0.12309712937034675, training-set accuracy= 0.9684833333333334, dev-set accuracy= 0.9639\n",
            "epoch: 7, loss= 0.1289005465409624, training-set accuracy= 0.96485, dev-set accuracy= 0.9592\n",
            "epoch: 8, loss= 0.11485428972252053, training-set accuracy= 0.9694666666666667, dev-set accuracy= 0.9658\n",
            "epoch: 9, loss= 0.11212208374084698, training-set accuracy= 0.97, dev-set accuracy= 0.9673\n",
            "epoch: 10, loss= 0.11522479399756953, training-set accuracy= 0.96925, dev-set accuracy= 0.9664\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "A1 = forward(X_test, weights, biases, activation_function='relu')['A']['A1']\n",
        "print(f\"A1 variance = {np.var(A1)}\")"
      ],
      "metadata": {
        "id": "4dm8WTHgItOn",
        "outputId": "d65399b7-4152-4362-f52c-1c66e5ca16c4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A1 variance = 0.23813206498863929\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# np.savez('best_trained_model_params[32,16,10].npz', **weights, **biases)\n",
        "# data = np.load('trained_model_params.npz')"
      ],
      "metadata": {
        "id": "PDZUH2uAUaeD"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#visualize mnist\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_predictions(X, y, num_images=10):\n",
        "    num_samples = X.shape[0]\n",
        "    shuffled_indices = np.arange(num_samples)\n",
        "    np.random.shuffle(shuffled_indices)\n",
        "    X_shuffled = X[shuffled_indices]\n",
        "    y_shuffled = y[shuffled_indices]\n",
        "\n",
        "    random_picks = np.random.choice(np.arange(num_samples), size=num_images)\n",
        "\n",
        "    images = X_shuffled[random_picks]\n",
        "    labels = y_shuffled[random_picks]\n",
        "    predictions_probability_distribution = predict(images, weights, biases)\n",
        "    predicted_labels = np.argmax(predictions_probability_distribution, axis=1)\n",
        "\n",
        "\n",
        "    fig, axes = plt.subplots(2, num_images, figsize=(20,6))\n",
        "    for i in range(len(images)):\n",
        "        axes[0,i].imshow(images[i].reshape(28,28), cmap='gray')\n",
        "        axes[0,i].set_title(\"true: \" + str(labels[i]) + \"\\npredicted: \" + str(predicted_labels[i]))\n",
        "        axes[0,i].axis('off')\n",
        "        axes[1,i].bar(x=np.arange(10), height=predictions_probability_distribution[i])\n",
        "        axes[1,i].set_ylim(0,1)\n",
        "        axes[1,i].set_xticks(np.arange(10))\n",
        "\n",
        "plot_predictions(X_test_copy, y_test_copy, num_images=5)"
      ],
      "metadata": {
        "id": "U2S_jh2B9N5O",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "b6c17314-f9b7-4474-fcf7-164709f5aa01"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 2000x600 with 10 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import numpy as np\n",
        "# import matplotlib.pyplot as plt\n",
        "\n",
        "# h = 0.05\n",
        "# x_min, x_max = X[:,0].min() - 1, X[:,0].max() + 1\n",
        "# y_min, y_max = X[:,1].min() - 1, X[:,1].max() + 1\n",
        "\n",
        "# xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n",
        "#                      np.arange(y_min, y_max, h))\n",
        "\n",
        "# grid_points = np.c_[xx.ravel(), yy.ravel()]\n",
        "\n",
        "# preds = predict(grid_points, weights, biases)\n",
        "\n",
        "# Z = (preds > 0.5).astype(int)\n",
        "# Z = Z.reshape(xx.shape)\n",
        "\n",
        "\n",
        "# plt.figure(figsize=(8,6))\n",
        "# plt.contourf(xx, yy, Z, alpha=0.3, cmap=plt.cm.RdBu)\n",
        "\n",
        "# plt.scatter(class0_points[:, 0], class0_points[:, 1], c='blue', label='Class 0 (Inner)', alpha=0.7)\n",
        "# plt.scatter(class1_points[:, 0], class1_points[:, 1], c='red', label='Class 1 (Outer)', alpha=0.7)\n",
        "\n",
        "# plt.title(\"Decision Boundary\")\n",
        "# plt.xlabel(\"Feature 1\")\n",
        "# plt.ylabel(\"Feature 2\")\n",
        "# plt.legend()\n",
        "# plt.grid(True)\n",
        "# plt.gca().set_aspect('equal', adjustable='box')\n",
        "# plt.show()\n"
      ],
      "metadata": {
        "id": "yoUkunx185nD"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "from PIL import Image\n",
        "\n",
        "def predict_image(img):\n",
        "\n",
        "    if isinstance(img, dict):\n",
        "        img = img[\"composite\"]\n",
        "\n",
        "    if img is None:\n",
        "        return {str(i): 0.0 for i in range(10)}\n",
        "\n",
        "\n",
        "    pil = Image.fromarray(img)\n",
        "    pil = pil.resize((28, 28)).convert('L')\n",
        "    image = np.array(pil, dtype=np.float32) / 255.0\n",
        "    image = image.reshape(-1, 28*28)\n",
        "\n",
        "    image = 1.0 - image\n",
        "\n",
        "\n",
        "    prediction = predict(image, weights, biases)\n",
        "    # print(prediction)\n",
        "\n",
        "\n",
        "    return {str(i): float(prediction[0, i]) for i in range(10)}"
      ],
      "metadata": {
        "id": "2BUbd2vyiFKN"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "demo = gr.Interface(fn=predict_image, inputs=gr.Sketchpad(), outputs=gr.Label(num_top_classes=10), live=True)\n",
        "demo.launch(share=True, debug=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "NmFQscJULvdG",
        "outputId": "2bd4887b-0438-4bfe-c265-11ac31c2f705"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "* Running on public URL: https://779688772a86c8059b.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://779688772a86c8059b.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "content_type multipart/form-data; boundary=----WebKitFormBoundaryWes9PGBwuwUGAPEX\n",
            "content_type multipart/form-data; boundary=----WebKitFormBoundarysj9MQqelAeJNNe0H\n",
            "content_type multipart/form-data; boundary=----WebKitFormBoundaryl5BV3yRo6SfYr0tG\n",
            "[[0.00091284 0.0039442  0.00918577 0.6514196  0.0003693  0.00100078\n",
            "  0.00005895 0.15739261 0.00310201 0.17261395]]\n",
            "content_type multipart/form-data; boundary=----WebKitFormBoundaryVLhETvG0pARVt4ny\n",
            "content_type multipart/form-data; boundary=----WebKitFormBoundaryjvO0GOjt67JKbeAi\n",
            "content_type multipart/form-data; boundary=----WebKitFormBoundaryWJUcablXcNNBADvi\n",
            "[[0.00024626 0.0001249  0.00046265 0.00016781 0.00209216 0.00149907\n",
            "  0.00008347 0.02324035 0.00151904 0.97056429]]\n",
            "content_type multipart/form-data; boundary=----WebKitFormBoundary5citCMLigoGxGIb9\n",
            "content_type multipart/form-data; boundary=----WebKitFormBoundarywosL8TAnBfTNvAOl\n",
            "content_type multipart/form-data; boundary=----WebKitFormBoundaryMO6jWPnVZrNaIgSh\n",
            "[[0.0072892  0.00632762 0.00733962 0.06901235 0.00107605 0.78089632\n",
            "  0.01913874 0.01837363 0.02380037 0.06674609]]\n",
            "content_type multipart/form-data; boundary=----WebKitFormBoundary6rhQUQ9X8dVTRMxA\n",
            "content_type multipart/form-data; boundary=----WebKitFormBoundary6Di1M6Bq2LK70hLz\n",
            "content_type multipart/form-data; boundary=----WebKitFormBoundaryk7OQGIDrbT3S0HWn\n",
            "[[0.00209389 0.00016203 0.00164796 0.0017717  0.00004185 0.00088204\n",
            "  0.00000998 0.98337625 0.00023997 0.00977434]]\n",
            "content_type multipart/form-data; boundary=----WebKitFormBoundaryB9lxBnyIcFs1wjHp\n",
            "content_type multipart/form-data; boundary=----WebKitFormBoundarygOss6CKn88A8p5cM\n",
            "content_type multipart/form-data; boundary=----WebKitFormBoundaryftNUBtAhMnTM8Zuv\n",
            "[[0.00051627 0.00036442 0.0078987  0.00687953 0.00070154 0.00040257\n",
            "  0.0000531  0.94494327 0.00148647 0.03675413]]\n",
            "content_type multipart/form-data; boundary=----WebKitFormBoundaryFSWsDeZ1Kkj6Iz2f\n",
            "content_type multipart/form-data; boundary=----WebKitFormBoundarygJlQt8A5IA7Nbz0G\n",
            "content_type multipart/form-data; boundary=----WebKitFormBoundaryZR7A0uORBLgMGdA0\n",
            "[[0.00053204 0.00137608 0.00151761 0.00216485 0.70910989 0.14004195\n",
            "  0.00429569 0.00610848 0.0204744  0.11437901]]\n",
            "content_type multipart/form-data; boundary=----WebKitFormBoundaryntOlaJFAJXidZX0F\n",
            "content_type multipart/form-data; boundary=----WebKitFormBoundarybtthe8LLPtyEs59E\n",
            "content_type multipart/form-data; boundary=----WebKitFormBoundaryBdACkiCHSAgbmzJj\n",
            "[[0.00009958 0.00039258 0.00029612 0.00052901 0.93224357 0.00155387\n",
            "  0.00017742 0.00621677 0.00239165 0.05609943]]\n",
            "Keyboard interruption in main thread... closing server.\n",
            "Killing tunnel 127.0.0.1:7862 <> https://779688772a86c8059b.gradio.live\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 84
        }
      ]
    }
  ]
}