{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 378,
      "metadata": {
        "id": "pGGkE4BAep1f"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "np.set_printoptions(suppress=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# #Binary classification\n",
        "# import matplotlib.pyplot as plt\n",
        "\n",
        "# # random dataset\n",
        "\n",
        "# NUM_SAMPLES_PER_CLASS = 200\n",
        "# INNER_RADIUS = 2\n",
        "# OUTER_RADIUS = 5\n",
        "# NOISE_STD_DEV = 0.5\n",
        "\n",
        "# theta_inner = 2 * np.pi * np.random.rand(NUM_SAMPLES_PER_CLASS)\n",
        "\n",
        "# radius_inner = INNER_RADIUS * np.random.rand(NUM_SAMPLES_PER_CLASS) + np.random.normal(0, NOISE_STD_DEV, NUM_SAMPLES_PER_CLASS)\n",
        "# x0 = radius_inner * np.cos(theta_inner)\n",
        "# y0 = radius_inner * np.sin(theta_inner)\n",
        "# class0_points = np.vstack([x0, y0]).T\n",
        "# class0_labels = np.zeros(NUM_SAMPLES_PER_CLASS)\n",
        "\n",
        "# theta_outer = 2 * np.pi * np.random.rand(NUM_SAMPLES_PER_CLASS)\n",
        "\n",
        "# radius_outer = np.random.uniform(INNER_RADIUS + 1, OUTER_RADIUS, NUM_SAMPLES_PER_CLASS) + np.random.normal(0, NOISE_STD_DEV, NUM_SAMPLES_PER_CLASS)\n",
        "# x1 = radius_outer * np.cos(theta_outer)\n",
        "# y1 = radius_outer * np.sin(theta_outer)\n",
        "# class1_points = np.vstack([x1, y1]).T\n",
        "# class1_labels = np.ones(NUM_SAMPLES_PER_CLASS)\n",
        "\n",
        "\n",
        "# X = np.vstack([class0_points, class1_points])\n",
        "# y = np.hstack([class0_labels, class1_labels])\n",
        "# y = y.reshape(-1, 1) # stupid broadcasting bug that i spent an hour on -.-\n",
        "\n",
        "\n",
        "# plt.figure(figsize=(8, 6))\n",
        "\n",
        "# plt.scatter(class0_points[:, 0], class0_points[:, 1], c='blue', label='Class 0 (Inner)', alpha=0.7)\n",
        "\n",
        "# plt.scatter(class1_points[:, 0], class1_points[:, 1], c='red', label='Class 1 (Outer)', alpha=0.7)\n",
        "# plt.title('Concentric Rings Dataset')\n",
        "# plt.xlabel('Feature 1')\n",
        "# plt.ylabel('Feature 2')\n",
        "# plt.legend()\n",
        "# plt.grid(True)\n",
        "# plt.gca().set_aspect('equal', adjustable='box')\n",
        "# plt.show()"
      ],
      "metadata": {
        "id": "0Wsu6mPtfNcy"
      },
      "execution_count": 379,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Mnist dataset\n",
        "import copy\n",
        "from tensorflow.keras.datasets import mnist\n",
        "\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "\n",
        "X_train = (X_train.astype('float64') / 255.0).reshape(-1,28*28)\n",
        "X_test = (X_test.astype('float64') / 255.0).reshape(-1,28*28)\n",
        "\n",
        "X_test_copy = copy.deepcopy(X_test)\n",
        "y_test_copy = copy.deepcopy(y_test)\n",
        "\n",
        "X = X_train#[:2000,:]\n",
        "y = y_train.reshape(60000, -1)#[:2000,:]\n",
        "X_test = X_test#[:1000,:]\n",
        "y_test = y_test.reshape(-1,1)#[:1000, :]"
      ],
      "metadata": {
        "id": "_rV-2-fY5Ske"
      },
      "execution_count": 380,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X.shape, y.shape, X_test.shape, y_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Z1MPju7fNj6",
        "outputId": "e71a2482-4d4d-4ac2-f58e-389430709b55"
      },
      "execution_count": 381,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((60000, 784), (60000, 1), (10000, 784), (10000, 1))"
            ]
          },
          "metadata": {},
          "execution_count": 381
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def one_hot_encoding(vector):\n",
        "    vector = np.array(vector).astype(int).flatten()\n",
        "    # if vector.ndim == 1:\n",
        "    #     return vector\n",
        "    size=len(vector)\n",
        "    num_classes = max(np.max(vector) + 1, 10)\n",
        "\n",
        "    encoded_matrix = np.zeros((size, num_classes))\n",
        "    encoded_matrix[np.arange(size), vector] = 1\n",
        "    return encoded_matrix"
      ],
      "metadata": {
        "id": "wsCbSo0pwQ_l"
      },
      "execution_count": 382,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_test_split(X, y, test_size=0.2):\n",
        "    num_samples = X.shape[0]\n",
        "    train_size = int(np.ceil(num_samples * (1-test_size)))\n",
        "    test_size = int(np.floor(num_samples * test_size))\n",
        "\n",
        "    shuffled_indices = np.arange(num_samples)\n",
        "    np.random.shuffle(shuffled_indices)\n",
        "    X = X[shuffled_indices]\n",
        "    y= y[shuffled_indices]\n",
        "\n",
        "    X_train = X[:train_size, :]\n",
        "    y_train = y[:train_size,]\n",
        "    X_test = X[train_size:]\n",
        "    y_test = y[train_size:]\n",
        "\n",
        "    return X_train, y_train, X_test, y_test"
      ],
      "metadata": {
        "id": "fQo6YdzuK3sk"
      },
      "execution_count": 383,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# X_train, y_train, X_test, y_test = train_test_split(X, y)"
      ],
      "metadata": {
        "id": "DTUH6FEGOrcz"
      },
      "execution_count": 384,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def initialize_weights_and_biases(m_inputs, layer_sizes:list):\n",
        "    weights = {}\n",
        "    biases = {}\n",
        "\n",
        "    layers = [m_inputs] + layer_sizes\n",
        "\n",
        "    for i in range(len(layers)-1):\n",
        "        weights[\"W\" + str(i+1)] = np.random.randn(layers[i], layers[i+1])# * 0.01 left out due to vanishing gradients\n",
        "        biases[\"b\" + str(i+1)] = np.zeros((1, layers[i+1]))\n",
        "\n",
        "    # print(f\"Successfully initialized weights and biases for {len(layer_sizes)} layers\")\n",
        "    return weights, biases\n"
      ],
      "metadata": {
        "id": "pOIC9U5BfNo3"
      },
      "execution_count": 385,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sigmoid(z):\n",
        "    return 1 / (1 + np.exp(-z))\n",
        "\n",
        "def relu(z):\n",
        "    return np.maximum(0,z)\n",
        "\n",
        "def softmax(z):\n",
        "    exponent_values = np.exp(z - np.max(z, axis=1, keepdims=True))\n",
        "    return exponent_values / np.sum(exponent_values, axis=1, keepdims=True)"
      ],
      "metadata": {
        "id": "9NQVMamKbrlu"
      },
      "execution_count": 386,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def forward(A, weights, biases, activation_function):\n",
        "    Z_dict = {}\n",
        "    A_dict = {}\n",
        "    A_dict[\"A0\"] = A\n",
        "    l_dict = {}\n",
        "\n",
        "    if activation_function == 'relu':\n",
        "        activation_function = relu\n",
        "    else:\n",
        "        activation_function = sigmoid\n",
        "\n",
        "\n",
        "    for i in range(len(weights)-1): #loop through hidden layers\n",
        "        a_prev = A\n",
        "        Z = np.dot(a_prev, weights[\"W\" + str(i+1)]) + biases[\"b\" + str(i+1)]\n",
        "        Z_dict[\"Z\" + str(i+1)] = Z\n",
        "        A = activation_function(Z)\n",
        "        A_dict[\"A\" + str(i+1)] = A\n",
        "        l_dict['layer' + str(i+1)] = activation_function.__name__\n",
        "\n",
        "    last_index = len(weights)\n",
        "\n",
        "    if weights[list(weights.keys())[-1]].shape[1] == 1:\n",
        "        output_activation = sigmoid\n",
        "    else:\n",
        "        output_activation = softmax\n",
        "\n",
        "    a_prev = A\n",
        "    Z = np.dot(a_prev, weights[\"W\" + str(last_index)]) + biases[\"b\" + str(last_index)]\n",
        "    Z_dict[\"Z\" + str(last_index)] = Z\n",
        "    A = output_activation(Z)\n",
        "    A_dict[\"A\" + str(last_index)] = A\n",
        "    l_dict['layer' + str(last_index)] = output_activation.__name__\n",
        "\n",
        "\n",
        "    cache = {\"Z\":Z_dict,\n",
        "             \"A\":A_dict,\n",
        "             'layer_activations':l_dict}\n",
        "\n",
        "    # print(\"Successfully computed a forward pass\")\n",
        "    return cache"
      ],
      "metadata": {
        "id": "A_sdeVp1fNq3"
      },
      "execution_count": 387,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_loss(y_pred, y_true, loss='binary_cross_entropy'):\n",
        "    epsilon = 1e-8\n",
        "\n",
        "    if loss == 'cross_entropy':\n",
        "        return - np.mean(np.sum(y_true * np.log(y_pred + epsilon), axis=1))\n",
        "    else:\n",
        "        return - np.mean(y_true * np.log(y_pred + epsilon) + (1-y_true)*np.log(1-y_pred + epsilon)) # added 1e-8 to avoid log(0)"
      ],
      "metadata": {
        "id": "11iGNgXdoPaN"
      },
      "execution_count": 388,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sigmoid_derivative(z):\n",
        "    s = sigmoid(z)\n",
        "    return s * (1 - s)\n",
        "\n",
        "def relu_derivative(z):\n",
        "    return (z > 0).astype(float)"
      ],
      "metadata": {
        "id": "Cpa39xURvtTr"
      },
      "execution_count": 389,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def backpropagation(X, y, weights, biases, cache):\n",
        "\n",
        "    activation_derivative = sigmoid_derivative\n",
        "\n",
        "    A_cache = cache['A']\n",
        "    Z_cache = cache['Z']\n",
        "    L_cache = cache['layer_activations']\n",
        "\n",
        "    Z_gradients = {}\n",
        "    A_gradients = {}\n",
        "    W_gradients = {}\n",
        "    b_gradients = {}\n",
        "\n",
        "    m = X.shape[0]\n",
        "\n",
        "    for i in reversed(range(len(weights))):\n",
        "        if L_cache['layer' + str(i+1)] == 'relu':\n",
        "            activation_derivative = relu_derivative\n",
        "        if L_cache['layer' + str(i+1)] == 'sigmoid':\n",
        "            activation_derivative = sigmoid_derivative\n",
        "\n",
        "\n",
        "        if i+1 == len(weights): #special case for first dZ\n",
        "            dZ = A_cache[\"A\" + str(i+1)] - y\n",
        "            Z_gradients[\"dZ\" + str(i+1)] = dZ\n",
        "            W_gradients[\"dW\" + str(i+1)] = np.dot(A_cache[\"A\" + str(i)].T,dZ) / m\n",
        "            b_gradients[\"db\" + str(i+1)] = np.sum(dZ, axis=0, keepdims=True) / m\n",
        "        else:\n",
        "            dZ = np.dot(Z_gradients[\"dZ\" + str(i+2)], weights[\"W\" + str(i+2)].T ) * activation_derivative(Z_cache[\"Z\" + str(i+1)])\n",
        "            Z_gradients[\"dZ\" + str(i+1)] = dZ\n",
        "            W_gradients[\"dW\" + str(i+1)] = np.dot(A_cache[\"A\" + str(i)].T,dZ) / m\n",
        "            b_gradients[\"db\" + str(i+1)] = np.sum(dZ, axis=0, keepdims=True) / m\n",
        "\n",
        "        # print(f\"Layer {i+1} dW magnitude: {np.linalg.norm(W_gradients['dW' + str(i+1)])}\")\n",
        "        # print(f\"Layer {i+1} db magnitude: {np.linalg.norm(b_gradients['db' + str(i+1)])}\")\n",
        "\n",
        "    grads = {\"dW\" : W_gradients,\n",
        "             \"db\" : b_gradients}\n",
        "\n",
        "    return grads"
      ],
      "metadata": {
        "id": "oBO-AJcSpSct"
      },
      "execution_count": 390,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def update_params(grads, weights, biases, learning_rate:float):\n",
        "\n",
        "    dw = grads['dW']\n",
        "    db = grads['db']\n",
        "\n",
        "    for i in range(len(weights)):\n",
        "        weights[\"W\" + str(i+1)] = weights[\"W\" + str(i+1)] - learning_rate * dw[\"dW\" + str(i+1)]\n",
        "        biases[\"b\" + str(i+1)] = biases[\"b\" + str(i+1)] - learning_rate * db[\"db\" + str(i+1)]\n",
        "\n",
        "    # print(\"Successfully updated params\")\n",
        "    return weights, biases"
      ],
      "metadata": {
        "id": "djF7hwUtxlyr"
      },
      "execution_count": 391,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(X, weights, biases):\n",
        "    cache = forward(X, weights, biases, activation_function='relu')\n",
        "    prediction = cache['A'][list(cache['A'].keys())[-1]]\n",
        "    return prediction"
      ],
      "metadata": {
        "id": "uLU5V7b0y80T"
      },
      "execution_count": 392,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "weights, biases = initialize_weights_and_biases(m_inputs=784, layer_sizes=[32, 16, 10])"
      ],
      "metadata": {
        "id": "h6yc6ghG8j84"
      },
      "execution_count": 393,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if len(np.unique(y)) > 2:\n",
        "    y = one_hot_encoding(y)\n",
        "    y_test = one_hot_encoding(y_test)\n",
        "    classification_type = 'multi'\n",
        "else:\n",
        "    classification_type = 'single'\n",
        "\n",
        "\n",
        "def accuracy(prediction, labels):\n",
        "    total = len(labels)\n",
        "\n",
        "    if classification_type == 'single':\n",
        "        acc = np.sum((prediction > 0.5).astype(int) == labels) / total\n",
        "    else:\n",
        "        predicted_class = np.argmax(prediction, axis=1)\n",
        "        true_class = np.argmax(labels, axis=1)\n",
        "        acc = np.mean(predicted_class == true_class)\n",
        "    return acc\n"
      ],
      "metadata": {
        "id": "YAN6QKh0HlhD"
      },
      "execution_count": 394,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run(epochs, learning_rate):\n",
        "    for i in range(epochs):\n",
        "        cache = forward(X, weights, biases, activation_function='relu')\n",
        "        prediction = cache['A'][list(cache['A'].keys())[-1]]\n",
        "        grads = backpropagation(X, y, weights, biases, cache)\n",
        "\n",
        "\n",
        "        if i % 100 == 0:\n",
        "            dev_predictions = predict(X_test, weights, biases)\n",
        "            print(f\"epoch: {i}, loss= {calculate_loss(prediction, y, loss='cross_entropy' if classification_type=='multi' else 'binary_cross_entropy')}, training-set accuracy= {accuracy(prediction, y)}, dev-set accuracy= {accuracy(dev_predictions, y_test)}\")\n",
        "\n",
        "        update_params(grads, weights, biases, learning_rate)"
      ],
      "metadata": {
        "id": "bE-obYbZv2Lb"
      },
      "execution_count": 395,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run_mini_batches(epochs, learning_rate, mini_batch_size=64):\n",
        "    num_samples = X.shape[0]\n",
        "    div = int(num_samples / mini_batch_size)\n",
        "\n",
        "    divisible_by_mini_batch_size = mini_batch_size * div\n",
        "    not_divisible = num_samples - divisible_by_mini_batch_size\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        shuffled_indices = np.arange(num_samples)\n",
        "        np.random.shuffle(shuffled_indices)\n",
        "        X_shuffled = X[shuffled_indices]\n",
        "        y_shuffled = y[shuffled_indices]\n",
        "\n",
        "        start = 0\n",
        "        end = 0\n",
        "        for batch in range(start, divisible_by_mini_batch_size, mini_batch_size):\n",
        "            start = end\n",
        "            end = start + mini_batch_size\n",
        "            X_batch = X_shuffled[start:end, :]\n",
        "            y_batch = y_shuffled[start:end]\n",
        "            #forward\n",
        "            cache = forward(X_batch, weights, biases, activation_function='relu')\n",
        "            prediction = cache['A'][list(cache['A'].keys())[-1]]\n",
        "            #backward\n",
        "            grads = backpropagation(X_batch, y_batch, weights, biases, cache)\n",
        "            #update\n",
        "            update_params(grads, weights, biases, learning_rate)\n",
        "\n",
        "        X_batch = X_shuffled[divisible_by_mini_batch_size:, :]\n",
        "        y_batch = y_shuffled[divisible_by_mini_batch_size:]\n",
        "        #forward\n",
        "        cache = forward(X_batch, weights, biases, activation_function='relu')\n",
        "        prediction = cache['A'][list(cache['A'].keys())[-1]]\n",
        "        #backward\n",
        "        grads = backpropagation(X_batch, y_batch, weights, biases, cache)\n",
        "        #update\n",
        "        update_params(grads, weights, biases, learning_rate)\n",
        "\n",
        "        cache = forward(X, weights, biases, activation_function='relu')\n",
        "        full_prediction = cache['A'][list(cache['A'].keys())[-1]]\n",
        "        dev_predictions = predict(X_test, weights, biases)\n",
        "        print(f\"epoch: {epoch}, loss= {calculate_loss(full_prediction, y, loss='cross_entropy' if classification_type=='multi' else 'binary_cross_entropy')}, training-set accuracy= {accuracy(full_prediction, y)}, dev-set accuracy= {accuracy(dev_predictions, y_test)}\")\n"
      ],
      "metadata": {
        "id": "AgzrO6SZBrIw"
      },
      "execution_count": 396,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# run(epochs=10000, learning_rate=0.005)"
      ],
      "metadata": {
        "id": "4oMThHvuwDdK"
      },
      "execution_count": 397,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "run_mini_batches(epochs=100, learning_rate=0.03, mini_batch_size=64)"
      ],
      "metadata": {
        "id": "zq_460UVTJVT",
        "outputId": "622325df-6d26-4bcc-b6c5-8d8cfa78d793",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 413,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 0, loss= 0.18987850892281466, training-set accuracy= 0.9433, dev-set accuracy= 0.9347\n",
            "epoch: 1, loss= 0.18156129005827276, training-set accuracy= 0.94825, dev-set accuracy= 0.9404\n",
            "epoch: 2, loss= 0.18273131465635417, training-set accuracy= 0.9471833333333334, dev-set accuracy= 0.9389\n",
            "epoch: 3, loss= 0.20628942810662865, training-set accuracy= 0.9386166666666667, dev-set accuracy= 0.9281\n",
            "epoch: 4, loss= 0.18662739486645621, training-set accuracy= 0.9456, dev-set accuracy= 0.9359\n",
            "epoch: 5, loss= 0.17687831367592016, training-set accuracy= 0.9485833333333333, dev-set accuracy= 0.9394\n",
            "epoch: 6, loss= 0.17751971600426408, training-set accuracy= 0.9472333333333334, dev-set accuracy= 0.9399\n",
            "epoch: 7, loss= 0.18260060844467269, training-set accuracy= 0.9469, dev-set accuracy= 0.9376\n",
            "epoch: 8, loss= 0.1888165606137159, training-set accuracy= 0.9438833333333333, dev-set accuracy= 0.9359\n",
            "epoch: 9, loss= 0.17774738395275297, training-set accuracy= 0.94775, dev-set accuracy= 0.9389\n",
            "epoch: 10, loss= 0.1912115775993184, training-set accuracy= 0.9428, dev-set accuracy= 0.9343\n",
            "epoch: 11, loss= 0.18324366739966194, training-set accuracy= 0.9453166666666667, dev-set accuracy= 0.9375\n",
            "epoch: 12, loss= 0.18573127383209684, training-set accuracy= 0.9465, dev-set accuracy= 0.9393\n",
            "epoch: 13, loss= 0.1765491206494054, training-set accuracy= 0.9483333333333334, dev-set accuracy= 0.9395\n",
            "epoch: 14, loss= 0.18260045244162762, training-set accuracy= 0.94725, dev-set accuracy= 0.9383\n",
            "epoch: 15, loss= 0.18118739741850093, training-set accuracy= 0.9468166666666666, dev-set accuracy= 0.9366\n",
            "epoch: 16, loss= 0.18456505617084443, training-set accuracy= 0.9456666666666667, dev-set accuracy= 0.9374\n",
            "epoch: 17, loss= 0.18217774678794837, training-set accuracy= 0.9465, dev-set accuracy= 0.9372\n",
            "epoch: 18, loss= 0.19031947036608626, training-set accuracy= 0.9440833333333334, dev-set accuracy= 0.9336\n",
            "epoch: 19, loss= 0.17457061938980264, training-set accuracy= 0.9489333333333333, dev-set accuracy= 0.9392\n",
            "epoch: 20, loss= 0.17872591418608455, training-set accuracy= 0.9474, dev-set accuracy= 0.9382\n",
            "epoch: 21, loss= 0.18259876848303436, training-set accuracy= 0.9464833333333333, dev-set accuracy= 0.9395\n",
            "epoch: 22, loss= 0.17536899499590472, training-set accuracy= 0.94875, dev-set accuracy= 0.9403\n",
            "epoch: 23, loss= 0.17469590637920857, training-set accuracy= 0.9482166666666667, dev-set accuracy= 0.9406\n",
            "epoch: 24, loss= 0.1812575330725507, training-set accuracy= 0.9461833333333334, dev-set accuracy= 0.939\n",
            "epoch: 25, loss= 0.19540332831499363, training-set accuracy= 0.9411, dev-set accuracy= 0.9326\n",
            "epoch: 26, loss= 0.17116469931493764, training-set accuracy= 0.9501666666666667, dev-set accuracy= 0.9406\n",
            "epoch: 27, loss= 0.21026138043875625, training-set accuracy= 0.9357, dev-set accuracy= 0.9273\n",
            "epoch: 28, loss= 0.17303474085940063, training-set accuracy= 0.949, dev-set accuracy= 0.94\n",
            "epoch: 29, loss= 0.1763899736281265, training-set accuracy= 0.94895, dev-set accuracy= 0.9415\n",
            "epoch: 30, loss= 0.1866304792538467, training-set accuracy= 0.9442166666666667, dev-set accuracy= 0.9341\n",
            "epoch: 31, loss= 0.1745465378534126, training-set accuracy= 0.9496, dev-set accuracy= 0.9399\n",
            "epoch: 32, loss= 0.17158703778914672, training-set accuracy= 0.9502666666666667, dev-set accuracy= 0.9396\n",
            "epoch: 33, loss= 0.1764478565258456, training-set accuracy= 0.9486333333333333, dev-set accuracy= 0.9393\n",
            "epoch: 34, loss= 0.17522839349693797, training-set accuracy= 0.9481833333333334, dev-set accuracy= 0.9396\n",
            "epoch: 35, loss= 0.17011886483666103, training-set accuracy= 0.95065, dev-set accuracy= 0.9405\n",
            "epoch: 36, loss= 0.16856022747356983, training-set accuracy= 0.9503166666666667, dev-set accuracy= 0.9419\n",
            "epoch: 37, loss= 0.1676619663336879, training-set accuracy= 0.9518666666666666, dev-set accuracy= 0.9429\n",
            "epoch: 38, loss= 0.1752987378724608, training-set accuracy= 0.94765, dev-set accuracy= 0.9374\n",
            "epoch: 39, loss= 0.17201373465903405, training-set accuracy= 0.9496333333333333, dev-set accuracy= 0.9392\n",
            "epoch: 40, loss= 0.1721207778970768, training-set accuracy= 0.9487333333333333, dev-set accuracy= 0.94\n",
            "epoch: 41, loss= 0.17319815941614353, training-set accuracy= 0.9491166666666667, dev-set accuracy= 0.9383\n",
            "epoch: 42, loss= 0.17185718657743038, training-set accuracy= 0.9496833333333333, dev-set accuracy= 0.9397\n",
            "epoch: 43, loss= 0.16554825703599715, training-set accuracy= 0.9513666666666667, dev-set accuracy= 0.9412\n",
            "epoch: 44, loss= 0.16939411912334726, training-set accuracy= 0.9501833333333334, dev-set accuracy= 0.9412\n",
            "epoch: 45, loss= 0.17227592951868936, training-set accuracy= 0.9486166666666667, dev-set accuracy= 0.9389\n",
            "epoch: 46, loss= 0.16844593549741152, training-set accuracy= 0.9508333333333333, dev-set accuracy= 0.9418\n",
            "epoch: 47, loss= 0.210241953839752, training-set accuracy= 0.93865, dev-set accuracy= 0.93\n",
            "epoch: 48, loss= 0.1959867241551197, training-set accuracy= 0.94155, dev-set accuracy= 0.9322\n",
            "epoch: 49, loss= 0.1664892134521773, training-set accuracy= 0.9509666666666666, dev-set accuracy= 0.9402\n",
            "epoch: 50, loss= 0.16209634387261485, training-set accuracy= 0.9525166666666667, dev-set accuracy= 0.9443\n",
            "epoch: 51, loss= 0.1625949595824832, training-set accuracy= 0.9523666666666667, dev-set accuracy= 0.9442\n",
            "epoch: 52, loss= 0.1835443324612015, training-set accuracy= 0.9445166666666667, dev-set accuracy= 0.9361\n",
            "epoch: 53, loss= 0.16617803591876462, training-set accuracy= 0.9519333333333333, dev-set accuracy= 0.9419\n",
            "epoch: 54, loss= 0.17744448648088812, training-set accuracy= 0.9472, dev-set accuracy= 0.9377\n",
            "epoch: 55, loss= 0.16156833401513118, training-set accuracy= 0.9529166666666666, dev-set accuracy= 0.9432\n",
            "epoch: 56, loss= 0.17721786060706393, training-set accuracy= 0.9475, dev-set accuracy= 0.937\n",
            "epoch: 57, loss= 0.16547269568605052, training-set accuracy= 0.95125, dev-set accuracy= 0.9436\n",
            "epoch: 58, loss= 0.16247059954746523, training-set accuracy= 0.9533166666666667, dev-set accuracy= 0.9437\n",
            "epoch: 59, loss= 0.1667029472785527, training-set accuracy= 0.9507, dev-set accuracy= 0.9401\n",
            "epoch: 60, loss= 0.1627095659953602, training-set accuracy= 0.9533666666666667, dev-set accuracy= 0.9427\n",
            "epoch: 61, loss= 0.15823117228439665, training-set accuracy= 0.9541833333333334, dev-set accuracy= 0.9427\n",
            "epoch: 62, loss= 0.16942849531032764, training-set accuracy= 0.9494833333333333, dev-set accuracy= 0.9394\n",
            "epoch: 63, loss= 0.1753951384888218, training-set accuracy= 0.94865, dev-set accuracy= 0.9387\n",
            "epoch: 64, loss= 0.17020115113030085, training-set accuracy= 0.9500666666666666, dev-set accuracy= 0.9397\n",
            "epoch: 65, loss= 0.17119190538992018, training-set accuracy= 0.9500666666666666, dev-set accuracy= 0.9425\n",
            "epoch: 66, loss= 0.16106340403416708, training-set accuracy= 0.9524166666666667, dev-set accuracy= 0.944\n",
            "epoch: 67, loss= 0.1589129133763944, training-set accuracy= 0.9538166666666666, dev-set accuracy= 0.9444\n",
            "epoch: 68, loss= 0.16674072276610946, training-set accuracy= 0.9517166666666667, dev-set accuracy= 0.9414\n",
            "epoch: 69, loss= 0.1548035667258976, training-set accuracy= 0.9548333333333333, dev-set accuracy= 0.9454\n",
            "epoch: 70, loss= 0.15760877742654633, training-set accuracy= 0.9530833333333333, dev-set accuracy= 0.9436\n",
            "epoch: 71, loss= 0.15872332655188887, training-set accuracy= 0.9523333333333334, dev-set accuracy= 0.9424\n",
            "epoch: 72, loss= 0.15645043898387825, training-set accuracy= 0.9553, dev-set accuracy= 0.9464\n",
            "epoch: 73, loss= 0.16164329060037003, training-set accuracy= 0.95235, dev-set accuracy= 0.941\n",
            "epoch: 74, loss= 0.16785516515615714, training-set accuracy= 0.9503, dev-set accuracy= 0.9394\n",
            "epoch: 75, loss= 0.16118905842945655, training-set accuracy= 0.9516333333333333, dev-set accuracy= 0.9414\n",
            "epoch: 76, loss= 0.1679175266933246, training-set accuracy= 0.9508166666666666, dev-set accuracy= 0.9412\n",
            "epoch: 77, loss= 0.15393690850074057, training-set accuracy= 0.9545333333333333, dev-set accuracy= 0.9436\n",
            "epoch: 78, loss= 0.15981135680793732, training-set accuracy= 0.9528, dev-set accuracy= 0.9433\n",
            "epoch: 79, loss= 0.15646981411118954, training-set accuracy= 0.9537666666666667, dev-set accuracy= 0.943\n",
            "epoch: 80, loss= 0.16032488256127775, training-set accuracy= 0.9532333333333334, dev-set accuracy= 0.944\n",
            "epoch: 81, loss= 0.15512481259208732, training-set accuracy= 0.9554833333333334, dev-set accuracy= 0.9438\n",
            "epoch: 82, loss= 0.15307282591659352, training-set accuracy= 0.9553, dev-set accuracy= 0.9445\n",
            "epoch: 83, loss= 0.16790370986565023, training-set accuracy= 0.9501, dev-set accuracy= 0.939\n",
            "epoch: 84, loss= 0.1615408957980072, training-set accuracy= 0.9522166666666667, dev-set accuracy= 0.941\n",
            "epoch: 85, loss= 0.15187736793302295, training-set accuracy= 0.9563666666666667, dev-set accuracy= 0.9455\n",
            "epoch: 86, loss= 0.1672504998352584, training-set accuracy= 0.95065, dev-set accuracy= 0.9405\n",
            "epoch: 87, loss= 0.15425269073271147, training-set accuracy= 0.9548, dev-set accuracy= 0.9446\n",
            "epoch: 88, loss= 0.15268518982882065, training-set accuracy= 0.9560333333333333, dev-set accuracy= 0.9461\n",
            "epoch: 89, loss= 0.15859717353825567, training-set accuracy= 0.9525166666666667, dev-set accuracy= 0.9429\n",
            "epoch: 90, loss= 0.15185618113429156, training-set accuracy= 0.9554166666666667, dev-set accuracy= 0.9447\n",
            "epoch: 91, loss= 0.15187109476087182, training-set accuracy= 0.9551333333333333, dev-set accuracy= 0.9428\n",
            "epoch: 92, loss= 0.15015223783620454, training-set accuracy= 0.9556833333333333, dev-set accuracy= 0.9457\n",
            "epoch: 93, loss= 0.15304544270899728, training-set accuracy= 0.9557333333333333, dev-set accuracy= 0.9442\n",
            "epoch: 94, loss= 0.157134780670897, training-set accuracy= 0.9536833333333333, dev-set accuracy= 0.9445\n",
            "epoch: 95, loss= 0.15611811118064145, training-set accuracy= 0.9538333333333333, dev-set accuracy= 0.9432\n",
            "epoch: 96, loss= 0.15371162510190145, training-set accuracy= 0.9549833333333333, dev-set accuracy= 0.9446\n",
            "epoch: 97, loss= 0.15557436839554914, training-set accuracy= 0.9536833333333333, dev-set accuracy= 0.9451\n",
            "epoch: 98, loss= 0.15241424924466224, training-set accuracy= 0.9553, dev-set accuracy= 0.9462\n",
            "epoch: 99, loss= 0.15782104980174702, training-set accuracy= 0.95445, dev-set accuracy= 0.9431\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.savez('best_trained_model_params[32,16,10].npz', **weights, **biases)\n",
        "# data = np.load('trained_model_params.npz')"
      ],
      "metadata": {
        "id": "PDZUH2uAUaeD"
      },
      "execution_count": 399,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#visualize mnist\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_predictions(X, y, num_images=10):\n",
        "    num_samples = X.shape[0]\n",
        "    shuffled_indices = np.arange(num_samples)\n",
        "    np.random.shuffle(shuffled_indices)\n",
        "    X_shuffled = X[shuffled_indices]\n",
        "    y_shuffled = y[shuffled_indices]\n",
        "\n",
        "    random_picks = np.random.choice(np.arange(num_samples), size=num_images)\n",
        "\n",
        "    images = X_shuffled[random_picks]\n",
        "    labels = y_shuffled[random_picks]\n",
        "    predictions_probability_distribution = predict(images, weights, biases)\n",
        "    predicted_labels = np.argmax(predictions_probability_distribution, axis=1)\n",
        "\n",
        "\n",
        "    fig, axes = plt.subplots(2, num_images, figsize=(20,6))\n",
        "    for i in range(len(images)):\n",
        "        axes[0,i].imshow(images[i].reshape(28,28), cmap='gray')\n",
        "        axes[0,i].set_title(\"true: \" + str(labels[i]) + \"\\npredicted: \" + str(predicted_labels[i]))\n",
        "        axes[0,i].axis('off')\n",
        "        axes[1,i].bar(x=np.arange(10), height=predictions_probability_distribution[i])\n",
        "        axes[1,i].set_ylim(0,1)\n",
        "        axes[1,i].set_xticks(np.arange(10))\n",
        "\n",
        "plot_predictions(X_test_copy, y_test_copy, num_images=5)"
      ],
      "metadata": {
        "id": "U2S_jh2B9N5O",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "aa9e2881-4e4f-4591-c18b-05153f4a45ea"
      },
      "execution_count": 446,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 2000x600 with 10 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import numpy as np\n",
        "# import matplotlib.pyplot as plt\n",
        "\n",
        "# h = 0.05\n",
        "# x_min, x_max = X[:,0].min() - 1, X[:,0].max() + 1\n",
        "# y_min, y_max = X[:,1].min() - 1, X[:,1].max() + 1\n",
        "\n",
        "# xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n",
        "#                      np.arange(y_min, y_max, h))\n",
        "\n",
        "# grid_points = np.c_[xx.ravel(), yy.ravel()]\n",
        "\n",
        "# preds = predict(grid_points, weights, biases)\n",
        "\n",
        "# Z = (preds > 0.5).astype(int)\n",
        "# Z = Z.reshape(xx.shape)\n",
        "\n",
        "\n",
        "# plt.figure(figsize=(8,6))\n",
        "# plt.contourf(xx, yy, Z, alpha=0.3, cmap=plt.cm.RdBu)\n",
        "\n",
        "# plt.scatter(class0_points[:, 0], class0_points[:, 1], c='blue', label='Class 0 (Inner)', alpha=0.7)\n",
        "# plt.scatter(class1_points[:, 0], class1_points[:, 1], c='red', label='Class 1 (Outer)', alpha=0.7)\n",
        "\n",
        "# plt.title(\"Decision Boundary\")\n",
        "# plt.xlabel(\"Feature 1\")\n",
        "# plt.ylabel(\"Feature 2\")\n",
        "# plt.legend()\n",
        "# plt.grid(True)\n",
        "# plt.gca().set_aspect('equal', adjustable='box')\n",
        "# plt.show()\n"
      ],
      "metadata": {
        "id": "yoUkunx185nD"
      },
      "execution_count": 401,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2BUbd2vyiFKN"
      },
      "execution_count": 401,
      "outputs": []
    }
  ]
}