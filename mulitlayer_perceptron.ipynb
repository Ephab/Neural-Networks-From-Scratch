{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 482,
      "metadata": {
        "id": "pGGkE4BAep1f"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "np.set_printoptions(suppress=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# #Binary classification\n",
        "# import matplotlib.pyplot as plt\n",
        "\n",
        "# # random dataset\n",
        "\n",
        "# NUM_SAMPLES_PER_CLASS = 200\n",
        "# INNER_RADIUS = 2\n",
        "# OUTER_RADIUS = 5\n",
        "# NOISE_STD_DEV = 0.5\n",
        "\n",
        "# theta_inner = 2 * np.pi * np.random.rand(NUM_SAMPLES_PER_CLASS)\n",
        "\n",
        "# radius_inner = INNER_RADIUS * np.random.rand(NUM_SAMPLES_PER_CLASS) + np.random.normal(0, NOISE_STD_DEV, NUM_SAMPLES_PER_CLASS)\n",
        "# x0 = radius_inner * np.cos(theta_inner)\n",
        "# y0 = radius_inner * np.sin(theta_inner)\n",
        "# class0_points = np.vstack([x0, y0]).T\n",
        "# class0_labels = np.zeros(NUM_SAMPLES_PER_CLASS)\n",
        "\n",
        "# theta_outer = 2 * np.pi * np.random.rand(NUM_SAMPLES_PER_CLASS)\n",
        "\n",
        "# radius_outer = np.random.uniform(INNER_RADIUS + 1, OUTER_RADIUS, NUM_SAMPLES_PER_CLASS) + np.random.normal(0, NOISE_STD_DEV, NUM_SAMPLES_PER_CLASS)\n",
        "# x1 = radius_outer * np.cos(theta_outer)\n",
        "# y1 = radius_outer * np.sin(theta_outer)\n",
        "# class1_points = np.vstack([x1, y1]).T\n",
        "# class1_labels = np.ones(NUM_SAMPLES_PER_CLASS)\n",
        "\n",
        "\n",
        "# X = np.vstack([class0_points, class1_points])\n",
        "# y = np.hstack([class0_labels, class1_labels])\n",
        "# y = y.reshape(-1, 1) # stupid broadcasting bug that i spent an hour on -.-\n",
        "\n",
        "\n",
        "# plt.figure(figsize=(8, 6))\n",
        "\n",
        "# plt.scatter(class0_points[:, 0], class0_points[:, 1], c='blue', label='Class 0 (Inner)', alpha=0.7)\n",
        "\n",
        "# plt.scatter(class1_points[:, 0], class1_points[:, 1], c='red', label='Class 1 (Outer)', alpha=0.7)\n",
        "# plt.title('Concentric Rings Dataset')\n",
        "# plt.xlabel('Feature 1')\n",
        "# plt.ylabel('Feature 2')\n",
        "# plt.legend()\n",
        "# plt.grid(True)\n",
        "# plt.gca().set_aspect('equal', adjustable='box')\n",
        "# plt.show()"
      ],
      "metadata": {
        "id": "0Wsu6mPtfNcy"
      },
      "execution_count": 483,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Mnist dataset\n",
        "import copy\n",
        "from tensorflow.keras.datasets import mnist\n",
        "\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "\n",
        "X_train = (X_train.astype('float64') / 255.0).reshape(-1,28*28)\n",
        "X_test = (X_test.astype('float64') / 255.0).reshape(-1,28*28)\n",
        "\n",
        "X_test_copy = copy.deepcopy(X_test)\n",
        "y_test_copy = copy.deepcopy(y_test)\n",
        "\n",
        "X = X_train#[:2000,:]\n",
        "y = y_train.reshape(60000, -1)#[:2000,:]\n",
        "X_test = X_test#[:1000,:]\n",
        "y_test = y_test.reshape(-1,1)#[:1000, :]"
      ],
      "metadata": {
        "id": "_rV-2-fY5Ske"
      },
      "execution_count": 484,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X.shape, y.shape, X_test.shape, y_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Z1MPju7fNj6",
        "outputId": "a0e6530d-eacc-41da-ac3f-46abc20f076f"
      },
      "execution_count": 485,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((60000, 784), (60000, 1), (10000, 784), (10000, 1))"
            ]
          },
          "metadata": {},
          "execution_count": 485
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def one_hot_encoding(vector):\n",
        "    vector = np.array(vector).astype(int).flatten()\n",
        "    # if vector.ndim == 1:\n",
        "    #     return vector\n",
        "    size=len(vector)\n",
        "    num_classes = max(np.max(vector) + 1, 10)\n",
        "\n",
        "    encoded_matrix = np.zeros((size, num_classes))\n",
        "    encoded_matrix[np.arange(size), vector] = 1\n",
        "    return encoded_matrix"
      ],
      "metadata": {
        "id": "wsCbSo0pwQ_l"
      },
      "execution_count": 486,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_test_split(X, y, test_size=0.2):\n",
        "    num_samples = X.shape[0]\n",
        "    train_size = int(np.ceil(num_samples * (1-test_size)))\n",
        "    test_size = int(np.floor(num_samples * test_size))\n",
        "\n",
        "    shuffled_indices = np.arange(num_samples)\n",
        "    np.random.shuffle(shuffled_indices)\n",
        "    X = X[shuffled_indices]\n",
        "    y= y[shuffled_indices]\n",
        "\n",
        "    X_train = X[:train_size, :]\n",
        "    y_train = y[:train_size,]\n",
        "    X_test = X[train_size:]\n",
        "    y_test = y[train_size:]\n",
        "\n",
        "    return X_train, y_train, X_test, y_test"
      ],
      "metadata": {
        "id": "fQo6YdzuK3sk"
      },
      "execution_count": 487,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# X_train, y_train, X_test, y_test = train_test_split(X, y)"
      ],
      "metadata": {
        "id": "DTUH6FEGOrcz"
      },
      "execution_count": 488,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def initialize_weights_and_biases(m_inputs, layer_sizes:list, initialization='scaled'):\n",
        "    weights = {}\n",
        "    biases = {}\n",
        "\n",
        "    layers = [m_inputs] + layer_sizes\n",
        "\n",
        "    if initialization == 'scaled':\n",
        "        for i in range(len(layers)-1):\n",
        "            weights[\"W\" + str(i+1)] = np.random.randn(layers[i], layers[i+1]) * 0.01\n",
        "            biases[\"b\" + str(i+1)] = np.zeros((1, layers[i+1]))\n",
        "\n",
        "    elif initialization == 'xavier':\n",
        "        for i in range(len(layers)-1):\n",
        "            variance = 2 / (layers[i] + layers[i+1])\n",
        "            weights[\"W\" + str(i+1)] = np.random.randn(layers[i], layers[i+1]) * np.sqrt(variance)\n",
        "            biases[\"b\" + str(i+1)] = np.zeros((1, layers[i+1]))\n",
        "\n",
        "    elif initialization == 'he':\n",
        "        for i in range(len(layers)-1):\n",
        "            variance = 2 / (layers[i])\n",
        "            weights[\"W\" + str(i+1)] = np.random.randn(layers[i], layers[i+1]) * np.sqrt(variance)\n",
        "            biases[\"b\" + str(i+1)] = np.zeros((1, layers[i+1]))\n",
        "\n",
        "    else:\n",
        "        for i in range(len(layers)-1):\n",
        "            weights[\"W\" + str(i+1)] = np.random.randn(layers[i], layers[i+1])\n",
        "            biases[\"b\" + str(i+1)] = np.zeros((1, layers[i+1]))\n",
        "\n",
        "    # print(f\"Successfully initialized weights and biases for {len(layer_sizes)} layers\")\n",
        "    return weights, biases\n"
      ],
      "metadata": {
        "id": "pOIC9U5BfNo3"
      },
      "execution_count": 489,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sigmoid(z):\n",
        "    return 1 / (1 + np.exp(-z))\n",
        "\n",
        "def relu(z):\n",
        "    return np.maximum(0,z)\n",
        "\n",
        "def softmax(z):\n",
        "    exponent_values = np.exp(z - np.max(z, axis=1, keepdims=True))\n",
        "    return exponent_values / np.sum(exponent_values, axis=1, keepdims=True)"
      ],
      "metadata": {
        "id": "9NQVMamKbrlu"
      },
      "execution_count": 490,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def forward(A, weights, biases, activation_function):\n",
        "    Z_dict = {}\n",
        "    A_dict = {}\n",
        "    A_dict[\"A0\"] = A\n",
        "    l_dict = {}\n",
        "\n",
        "    if activation_function == 'relu':\n",
        "        activation_function = relu\n",
        "    else:\n",
        "        activation_function = sigmoid\n",
        "\n",
        "\n",
        "    for i in range(len(weights)-1): #loop through hidden layers\n",
        "        a_prev = A\n",
        "        Z = np.dot(a_prev, weights[\"W\" + str(i+1)]) + biases[\"b\" + str(i+1)]\n",
        "        Z_dict[\"Z\" + str(i+1)] = Z\n",
        "        A = activation_function(Z)\n",
        "        A_dict[\"A\" + str(i+1)] = A\n",
        "        l_dict['layer' + str(i+1)] = activation_function.__name__\n",
        "\n",
        "    last_index = len(weights)\n",
        "\n",
        "    if weights[list(weights.keys())[-1]].shape[1] == 1:\n",
        "        output_activation = sigmoid\n",
        "    else:\n",
        "        output_activation = softmax\n",
        "\n",
        "    a_prev = A\n",
        "    Z = np.dot(a_prev, weights[\"W\" + str(last_index)]) + biases[\"b\" + str(last_index)]\n",
        "    Z_dict[\"Z\" + str(last_index)] = Z\n",
        "    A = output_activation(Z)\n",
        "    A_dict[\"A\" + str(last_index)] = A\n",
        "    l_dict['layer' + str(last_index)] = output_activation.__name__\n",
        "\n",
        "\n",
        "    cache = {\"Z\":Z_dict,\n",
        "             \"A\":A_dict,\n",
        "             'layer_activations':l_dict}\n",
        "\n",
        "    # print(\"Successfully computed a forward pass\")\n",
        "    return cache"
      ],
      "metadata": {
        "id": "A_sdeVp1fNq3"
      },
      "execution_count": 491,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_loss(y_pred, y_true, weights, loss='binary_cross_entropy', regularization='l2', reg_lambda=0):\n",
        "    epsilon = 1e-8\n",
        "    num_samples = y_pred.shape[0]\n",
        "    weight_loss = 0\n",
        "\n",
        "    if regularization == 'l2':\n",
        "        weight_loss = (reg_lambda / (2*num_samples))* np.sum([np.sum(weight ** 2) for _, weight in weights.items()])\n",
        "\n",
        "    if loss == 'cross_entropy':\n",
        "        return - np.mean(np.sum(y_true * np.log(y_pred + epsilon), axis=1)) + weight_loss\n",
        "    else:\n",
        "        return - np.mean(y_true * np.log(y_pred + epsilon) + (1-y_true)*np.log(1-y_pred + epsilon)) + weight_loss # added 1e-8 to avoid log(0)"
      ],
      "metadata": {
        "id": "11iGNgXdoPaN"
      },
      "execution_count": 492,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sigmoid_derivative(z):\n",
        "    s = sigmoid(z)\n",
        "    return s * (1 - s)\n",
        "\n",
        "def relu_derivative(z):\n",
        "    return (z > 0).astype(float)"
      ],
      "metadata": {
        "id": "Cpa39xURvtTr"
      },
      "execution_count": 493,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def backpropagation(X, y, weights, biases, cache, regularization, reg_lambda):\n",
        "\n",
        "    activation_derivative = sigmoid_derivative\n",
        "\n",
        "    A_cache = cache['A']\n",
        "    Z_cache = cache['Z']\n",
        "    L_cache = cache['layer_activations']\n",
        "\n",
        "    Z_gradients = {}\n",
        "    A_gradients = {}\n",
        "    W_gradients = {}\n",
        "    b_gradients = {}\n",
        "\n",
        "    m = X.shape[0]\n",
        "\n",
        "    for i in reversed(range(len(weights))):\n",
        "        if L_cache['layer' + str(i+1)] == 'relu':\n",
        "            activation_derivative = relu_derivative\n",
        "        if L_cache['layer' + str(i+1)] == 'sigmoid':\n",
        "            activation_derivative = sigmoid_derivative\n",
        "\n",
        "\n",
        "        if i+1 == len(weights): #special case for first dZ\n",
        "            dZ = A_cache[\"A\" + str(i+1)] - y\n",
        "            Z_gradients[\"dZ\" + str(i+1)] = dZ\n",
        "            W_gradients[\"dW\" + str(i+1)] = np.dot(A_cache[\"A\" + str(i)].T,dZ) / m\n",
        "\n",
        "            #adding regularization gradient\n",
        "            if regularization == 'l2':\n",
        "                W_gradients[\"dW\" + str(i+1)] += (reg_lambda / m) * weights['W' + str(i+1)]\n",
        "\n",
        "            b_gradients[\"db\" + str(i+1)] = np.sum(dZ, axis=0, keepdims=True) / m\n",
        "        else:\n",
        "            dZ = np.dot(Z_gradients[\"dZ\" + str(i+2)], weights[\"W\" + str(i+2)].T) * activation_derivative(Z_cache[\"Z\" + str(i+1)])\n",
        "            Z_gradients[\"dZ\" + str(i+1)] = dZ\n",
        "            W_gradients[\"dW\" + str(i+1)] = np.dot(A_cache[\"A\" + str(i)].T, dZ) / m\n",
        "\n",
        "            #adding regularization gradient\n",
        "            if regularization == 'l2':\n",
        "                W_gradients[\"dW\" + str(i+1)] += (reg_lambda / m) * weights['W' + str(i+1)]\n",
        "\n",
        "            b_gradients[\"db\" + str(i+1)] = np.sum(dZ, axis=0, keepdims=True) / m\n",
        "\n",
        "        # print(f\"Layer {i+1} dW magnitude: {np.linalg.norm(W_gradients['dW' + str(i+1)])}\")\n",
        "        # print(f\"Layer {i+1} db magnitude: {np.linalg.norm(b_gradients['db' + str(i+1)])}\")\n",
        "\n",
        "    grads = {\"dW\" : W_gradients,\n",
        "             \"db\" : b_gradients}\n",
        "\n",
        "    return grads"
      ],
      "metadata": {
        "id": "oBO-AJcSpSct"
      },
      "execution_count": 494,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "weights, biases = initialize_weights_and_biases(m_inputs=784, layer_sizes=[256, 10], initialization='xavier')"
      ],
      "metadata": {
        "id": "h6yc6ghG8j84"
      },
      "execution_count": 495,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Vdw = {}\n",
        "Vdb = {}\n",
        "Sdw = {}\n",
        "Sdb = {}\n",
        "Vdw_corrected = {}\n",
        "Vdb_corrected = {}\n",
        "Sdw_corrected = {}\n",
        "Sdb_corrected = {}\n",
        "\n",
        "t = 1\n",
        "\n",
        "for i in range(len(weights)):\n",
        "    Vdw['w' + str(i+1)] = np.zeros_like(weights['W' + str(i+1)])\n",
        "    Vdb['b' + str(i+1)] = np.zeros_like(biases['b' + str(i+1)])\n",
        "\n",
        "    Sdw['w' + str(i+1)] = np.zeros_like(weights['W' + str(i+1)])\n",
        "    Sdb['b' + str(i+1)] = np.zeros_like(biases['b' + str(i+1)])\n",
        "\n",
        "\n",
        "def update_params(grads, weights, biases, learning_rate, optimizer='gd', beta1=0.9, beta2=0.999, epsilon=1e-8):\n",
        "\n",
        "    dw = grads['dW']\n",
        "    db = grads['db']\n",
        "\n",
        "    global t\n",
        "\n",
        "    if optimizer == 'momentum':\n",
        "      for i in range(len(weights)):\n",
        "        Vdw['w' + str(i+1)] = beta1 * Vdw['w' + str(i+1)] + ((1-beta1) * dw['dW' + str(i+1)])\n",
        "        weights[\"W\" + str(i+1)] = weights[\"W\" + str(i+1)] - learning_rate * Vdw['w' + str(i+1)]\n",
        "\n",
        "        Vdb['b' + str(i+1)] = beta1 * Vdb['b' + str(i+1)] + ((1-beta1) * db[\"db\" + str(i+1)])\n",
        "        biases[\"b\" + str(i+1)] = biases[\"b\" + str(i+1)] - learning_rate * Vdb['b' + str(i+1)]\n",
        "\n",
        "    elif optimizer == 'rmsprop':\n",
        "        for i in range(len(weights)):\n",
        "            Sdw['w' + str(i+1)] = beta2 * Sdw['w' + str(i+1)] + ((1-beta2) * (dw['dW' + str(i+1)])**2)\n",
        "            weights[\"W\" + str(i+1)] = weights[\"W\" + str(i+1)] - learning_rate * ((dw['dW' + str(i+1)])/(np.sqrt(Sdw['w' + str(i+1)] + epsilon)))\n",
        "\n",
        "            # print(np.sqrt(Sdw['w1'] + epsilon))\n",
        "\n",
        "            Sdb['b' + str(i+1)] = beta2 * Sdb['b' + str(i+1)] + ((1-beta2) * (db['db' + str(i+1)])**2)\n",
        "            biases[\"b\" + str(i+1)] = biases[\"b\" + str(i+1)] - learning_rate * ((db['db' + str(i+1)])/(np.sqrt(Sdb['b' + str(i+1)] + epsilon)))\n",
        "\n",
        "    elif optimizer == 'adam':\n",
        "        for i in range(len(weights)):\n",
        "            Vdw['w' + str(i+1)] = beta1 * Vdw['w' + str(i+1)] + ((1-beta1) * dw['dW' + str(i+1)])\n",
        "            Sdw['w' + str(i+1)] = beta2 * Sdw['w' + str(i+1)] + ((1-beta2) * (dw['dW' + str(i+1)])**2)\n",
        "\n",
        "            Vdb['b' + str(i+1)] = beta1 * Vdb['b' + str(i+1)] + ((1-beta1) * db[\"db\" + str(i+1)])\n",
        "            Sdb['b' + str(i+1)] = beta2 * Sdb['b' + str(i+1)] + ((1-beta2) * (db['db' + str(i+1)])**2)\n",
        "\n",
        "\n",
        "            #bias correction\n",
        "            Vdw_corrected['w' + str(i+1)] = Vdw['w' + str(i+1)] / (1-beta1**t)\n",
        "            Vdb_corrected['b' + str(i+1)] = Vdb['b' + str(i+1)] / (1-beta1**t)\n",
        "\n",
        "            Sdw_corrected['w' + str(i+1)] = Sdw['w' + str(i+1)] / (1-beta2**t)\n",
        "            Sdb_corrected['b' + str(i+1)] = Sdb['b' + str(i+1)] / (1-beta2**t)\n",
        "\n",
        "\n",
        "            weights[\"W\" + str(i+1)] = weights[\"W\" + str(i+1)] - learning_rate * (Vdw_corrected['w' + str(i+1)] / np.sqrt(Sdw_corrected['w' + str(i+1)] + epsilon))\n",
        "            biases['b' + str(i+1)] = biases['b' + str(i+1)] - learning_rate * (Vdb_corrected['b' + str(i+1)] / np.sqrt(Sdb_corrected['b' + str(i+1)] + epsilon))\n",
        "\n",
        "        t += 1\n",
        "\n",
        "    else: #normal gd\n",
        "        for i in range(len(weights)):\n",
        "            weights[\"W\" + str(i+1)] = weights[\"W\" + str(i+1)] - learning_rate * dw[\"dW\" + str(i+1)]\n",
        "            biases[\"b\" + str(i+1)] = biases[\"b\" + str(i+1)] - learning_rate * db[\"db\" + str(i+1)]\n",
        "\n",
        "    # print(\"Successfully updated params\")\n",
        "    return weights, biases"
      ],
      "metadata": {
        "id": "djF7hwUtxlyr"
      },
      "execution_count": 496,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(X, weights, biases):\n",
        "    cache = forward(X, weights, biases, activation_function='relu')\n",
        "    prediction = cache['A'][list(cache['A'].keys())[-1]]\n",
        "    return prediction"
      ],
      "metadata": {
        "id": "uLU5V7b0y80T"
      },
      "execution_count": 497,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if len(np.unique(y)) > 2:\n",
        "    y = one_hot_encoding(y)\n",
        "    y_test = one_hot_encoding(y_test)\n",
        "    classification_type = 'multi'\n",
        "else:\n",
        "    classification_type = 'single'\n",
        "\n",
        "\n",
        "def accuracy(prediction, labels):\n",
        "    total = len(labels)\n",
        "\n",
        "    if classification_type == 'single':\n",
        "        acc = np.sum((prediction > 0.5).astype(int) == labels) / total\n",
        "    else:\n",
        "        predicted_class = np.argmax(prediction, axis=1)\n",
        "        true_class = np.argmax(labels, axis=1)\n",
        "        acc = np.mean(predicted_class == true_class)\n",
        "    return acc\n"
      ],
      "metadata": {
        "id": "YAN6QKh0HlhD"
      },
      "execution_count": 498,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run(epochs, learning_rate, optimizer='gd', beta1=0.9, beta2=0.999, regularization='l2', reg_lambda=0):\n",
        "    for i in range(epochs):\n",
        "        cache = forward(X, weights, biases, activation_function='relu')\n",
        "        prediction = cache['A'][list(cache['A'].keys())[-1]]\n",
        "        grads = backpropagation(X, y, weights, biases, cache, regularization=regularization, reg_lambda=reg_lambda)\n",
        "\n",
        "\n",
        "        if i % 100 == 0:\n",
        "            dev_predictions = predict(X_test, weights, biases)\n",
        "            print(f\"epoch: {i}, loss= {calculate_loss(prediction, y, loss='cross_entropy' if classification_type=='multi' else 'binary_cross_entropy', weights=weights, regularization=regularization, reg_lambda=reg_lambda)}, training-set accuracy= {accuracy(prediction, y)}, dev-set accuracy= {accuracy(dev_predictions, y_test)}\")\n",
        "\n",
        "        update_params(grads, weights, biases, learning_rate, optimizer=optimizer, beta1=beta1, beta2=beta2)"
      ],
      "metadata": {
        "id": "bE-obYbZv2Lb"
      },
      "execution_count": 499,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run_mini_batches(epochs, learning_rate, mini_batch_size=64, optimizer='gd', beta1=0.9, beta2=0.999, regularization='l2', reg_lambda=0):\n",
        "    num_samples = X.shape[0]\n",
        "    div = int(num_samples / mini_batch_size)\n",
        "\n",
        "    divisible_by_mini_batch_size = mini_batch_size * div\n",
        "    not_divisible = num_samples - divisible_by_mini_batch_size\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        shuffled_indices = np.arange(num_samples)\n",
        "        np.random.shuffle(shuffled_indices)\n",
        "        X_shuffled = X[shuffled_indices]\n",
        "        y_shuffled = y[shuffled_indices]\n",
        "\n",
        "        start = 0\n",
        "        end = 0\n",
        "        for batch in range(start, divisible_by_mini_batch_size, mini_batch_size):\n",
        "            start = end\n",
        "            end = start + mini_batch_size\n",
        "            X_batch = X_shuffled[start:end, :]\n",
        "            y_batch = y_shuffled[start:end]\n",
        "            #forward\n",
        "            cache = forward(X_batch, weights, biases, activation_function='relu')\n",
        "            prediction = cache['A'][list(cache['A'].keys())[-1]]\n",
        "            #backward\n",
        "            grads = backpropagation(X_batch, y_batch, weights, biases, cache, regularization=regularization, reg_lambda=reg_lambda)\n",
        "            #update\n",
        "            update_params(grads, weights, biases, learning_rate, optimizer=optimizer, beta1=beta1, beta2=beta2)\n",
        "\n",
        "        if not_divisible != 0:\n",
        "            X_batch = X_shuffled[divisible_by_mini_batch_size:, :]\n",
        "            y_batch = y_shuffled[divisible_by_mini_batch_size:]\n",
        "            #forward\n",
        "            cache = forward(X_batch, weights, biases, activation_function='relu')\n",
        "            prediction = cache['A'][list(cache['A'].keys())[-1]]\n",
        "            #backward\n",
        "            grads = backpropagation(X_batch, y_batch, weights, biases, cache, regularization=regularization, reg_lambda=reg_lambda)\n",
        "            #update\n",
        "            update_params(grads, weights, biases, learning_rate, optimizer=optimizer)\n",
        "\n",
        "        cache = forward(X, weights, biases, activation_function='relu')\n",
        "        full_prediction = cache['A'][list(cache['A'].keys())[-1]]\n",
        "        dev_predictions = predict(X_test, weights, biases)\n",
        "        print(f\"epoch: {epoch+1}, loss= {calculate_loss(full_prediction, y, loss='cross_entropy' if classification_type=='multi' else 'binary_cross_entropy', weights=weights, regularization=regularization, reg_lambda=reg_lambda)}, training-set accuracy= {accuracy(full_prediction, y)}, dev-set accuracy= {accuracy(dev_predictions, y_test)}\")\n"
      ],
      "metadata": {
        "id": "AgzrO6SZBrIw"
      },
      "execution_count": 500,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# run(epochs=10000, learning_rate=0.005)"
      ],
      "metadata": {
        "id": "4oMThHvuwDdK"
      },
      "execution_count": 501,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "run_mini_batches(epochs=20, learning_rate=0.001, mini_batch_size=50, optimizer='adam', beta1=0.9, beta2=0.999, regularization='l2', reg_lambda=0.01)"
      ],
      "metadata": {
        "id": "zq_460UVTJVT",
        "outputId": "6bbd1340-ace4-4157-f47e-ecb488be9a02",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 502,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 1, loss= 0.1220269156932028, training-set accuracy= 0.9658166666666667, dev-set accuracy= 0.9625\n",
            "epoch: 2, loss= 0.08079591554778584, training-set accuracy= 0.9769166666666667, dev-set accuracy= 0.9676\n",
            "epoch: 3, loss= 0.06537177881158564, training-set accuracy= 0.9815666666666667, dev-set accuracy= 0.9739\n",
            "epoch: 4, loss= 0.05297875590324728, training-set accuracy= 0.9849333333333333, dev-set accuracy= 0.9754\n",
            "epoch: 5, loss= 0.04651763522040023, training-set accuracy= 0.9867833333333333, dev-set accuracy= 0.9756\n",
            "epoch: 6, loss= 0.03918227986256402, training-set accuracy= 0.9892, dev-set accuracy= 0.9771\n",
            "epoch: 7, loss= 0.03713601230988398, training-set accuracy= 0.9901666666666666, dev-set accuracy= 0.9776\n",
            "epoch: 8, loss= 0.034044406789961394, training-set accuracy= 0.9917333333333334, dev-set accuracy= 0.9802\n",
            "epoch: 9, loss= 0.0268911302923308, training-set accuracy= 0.9937666666666667, dev-set accuracy= 0.9805\n",
            "epoch: 10, loss= 0.028570079515727178, training-set accuracy= 0.9923666666666666, dev-set accuracy= 0.9793\n",
            "epoch: 11, loss= 0.03183272807167327, training-set accuracy= 0.9912833333333333, dev-set accuracy= 0.9786\n",
            "epoch: 12, loss= 0.02786254052770609, training-set accuracy= 0.9927166666666667, dev-set accuracy= 0.98\n",
            "epoch: 13, loss= 0.024730548439222982, training-set accuracy= 0.9939166666666667, dev-set accuracy= 0.981\n",
            "epoch: 14, loss= 0.025564272567038526, training-set accuracy= 0.9933666666666666, dev-set accuracy= 0.9793\n",
            "epoch: 15, loss= 0.0216749629489231, training-set accuracy= 0.99545, dev-set accuracy= 0.9806\n",
            "epoch: 16, loss= 0.02790853001325893, training-set accuracy= 0.9930333333333333, dev-set accuracy= 0.9801\n",
            "epoch: 17, loss= 0.02691066306222537, training-set accuracy= 0.9933333333333333, dev-set accuracy= 0.9794\n",
            "epoch: 18, loss= 0.025065765986117643, training-set accuracy= 0.9937166666666667, dev-set accuracy= 0.9788\n",
            "epoch: 19, loss= 0.02320685725924866, training-set accuracy= 0.9944833333333334, dev-set accuracy= 0.9795\n",
            "epoch: 20, loss= 0.02498147576100412, training-set accuracy= 0.99365, dev-set accuracy= 0.9814\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "A1 = forward(X_test, weights, biases, activation_function='relu')['A']['A1']\n",
        "print(f\"A1 variance = {np.var(A1)}\")"
      ],
      "metadata": {
        "id": "4dm8WTHgItOn",
        "outputId": "74b95b7f-3bcf-4942-a147-2d8244c74445",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 503,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A1 variance = 0.5136402490260025\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# np.savez('best_trained_model_params[32,16,10].npz', **weights, **biases)\n",
        "# data = np.load('trained_model_params.npz')"
      ],
      "metadata": {
        "id": "PDZUH2uAUaeD"
      },
      "execution_count": 504,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#visualize mnist\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_predictions(X, y, num_images=10):\n",
        "    num_samples = X.shape[0]\n",
        "    shuffled_indices = np.arange(num_samples)\n",
        "    np.random.shuffle(shuffled_indices)\n",
        "    X_shuffled = X[shuffled_indices]\n",
        "    y_shuffled = y[shuffled_indices]\n",
        "\n",
        "    random_picks = np.random.choice(np.arange(num_samples), size=num_images)\n",
        "\n",
        "    images = X_shuffled[random_picks]\n",
        "    labels = y_shuffled[random_picks]\n",
        "    predictions_probability_distribution = predict(images, weights, biases)\n",
        "    predicted_labels = np.argmax(predictions_probability_distribution, axis=1)\n",
        "\n",
        "\n",
        "    fig, axes = plt.subplots(2, num_images, figsize=(20,6))\n",
        "    for i in range(len(images)):\n",
        "        axes[0,i].imshow(images[i].reshape(28,28), cmap='gray')\n",
        "        axes[0,i].set_title(\"true: \" + str(labels[i]) + \"\\npredicted: \" + str(predicted_labels[i]))\n",
        "        axes[0,i].axis('off')\n",
        "        axes[1,i].bar(x=np.arange(10), height=predictions_probability_distribution[i])\n",
        "        axes[1,i].set_ylim(0,1)\n",
        "        axes[1,i].set_xticks(np.arange(10))\n",
        "\n",
        "plot_predictions(X_test_copy, y_test_copy, num_images=5)"
      ],
      "metadata": {
        "id": "U2S_jh2B9N5O",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "98a02340-2273-4c47-c939-81a2409fa9e8"
      },
      "execution_count": 505,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 2000x600 with 10 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import numpy as np\n",
        "# import matplotlib.pyplot as plt\n",
        "\n",
        "# h = 0.05\n",
        "# x_min, x_max = X[:,0].min() - 1, X[:,0].max() + 1\n",
        "# y_min, y_max = X[:,1].min() - 1, X[:,1].max() + 1\n",
        "\n",
        "# xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n",
        "#                      np.arange(y_min, y_max, h))\n",
        "\n",
        "# grid_points = np.c_[xx.ravel(), yy.ravel()]\n",
        "\n",
        "# preds = predict(grid_points, weights, biases)\n",
        "\n",
        "# Z = (preds > 0.5).astype(int)\n",
        "# Z = Z.reshape(xx.shape)\n",
        "\n",
        "\n",
        "# plt.figure(figsize=(8,6))\n",
        "# plt.contourf(xx, yy, Z, alpha=0.3, cmap=plt.cm.RdBu)\n",
        "\n",
        "# plt.scatter(class0_points[:, 0], class0_points[:, 1], c='blue', label='Class 0 (Inner)', alpha=0.7)\n",
        "# plt.scatter(class1_points[:, 0], class1_points[:, 1], c='red', label='Class 1 (Outer)', alpha=0.7)\n",
        "\n",
        "# plt.title(\"Decision Boundary\")\n",
        "# plt.xlabel(\"Feature 1\")\n",
        "# plt.ylabel(\"Feature 2\")\n",
        "# plt.legend()\n",
        "# plt.grid(True)\n",
        "# plt.gca().set_aspect('equal', adjustable='box')\n",
        "# plt.show()\n"
      ],
      "metadata": {
        "id": "yoUkunx185nD"
      },
      "execution_count": 506,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2BUbd2vyiFKN"
      },
      "execution_count": 506,
      "outputs": []
    }
  ]
}