{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 592,
      "metadata": {
        "id": "pGGkE4BAep1f"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "np.set_printoptions(suppress=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# #Binary classification\n",
        "# import matplotlib.pyplot as plt\n",
        "\n",
        "# # random dataset\n",
        "\n",
        "# NUM_SAMPLES_PER_CLASS = 200\n",
        "# INNER_RADIUS = 2\n",
        "# OUTER_RADIUS = 5\n",
        "# NOISE_STD_DEV = 0.5\n",
        "\n",
        "# theta_inner = 2 * np.pi * np.random.rand(NUM_SAMPLES_PER_CLASS)\n",
        "\n",
        "# radius_inner = INNER_RADIUS * np.random.rand(NUM_SAMPLES_PER_CLASS) + np.random.normal(0, NOISE_STD_DEV, NUM_SAMPLES_PER_CLASS)\n",
        "# x0 = radius_inner * np.cos(theta_inner)\n",
        "# y0 = radius_inner * np.sin(theta_inner)\n",
        "# class0_points = np.vstack([x0, y0]).T\n",
        "# class0_labels = np.zeros(NUM_SAMPLES_PER_CLASS)\n",
        "\n",
        "# theta_outer = 2 * np.pi * np.random.rand(NUM_SAMPLES_PER_CLASS)\n",
        "\n",
        "# radius_outer = np.random.uniform(INNER_RADIUS + 1, OUTER_RADIUS, NUM_SAMPLES_PER_CLASS) + np.random.normal(0, NOISE_STD_DEV, NUM_SAMPLES_PER_CLASS)\n",
        "# x1 = radius_outer * np.cos(theta_outer)\n",
        "# y1 = radius_outer * np.sin(theta_outer)\n",
        "# class1_points = np.vstack([x1, y1]).T\n",
        "# class1_labels = np.ones(NUM_SAMPLES_PER_CLASS)\n",
        "\n",
        "\n",
        "# X = np.vstack([class0_points, class1_points])\n",
        "# y = np.hstack([class0_labels, class1_labels])\n",
        "# y = y.reshape(-1, 1) # stupid broadcasting bug that i spent an hour on -.-\n",
        "\n",
        "\n",
        "# plt.figure(figsize=(8, 6))\n",
        "\n",
        "# plt.scatter(class0_points[:, 0], class0_points[:, 1], c='blue', label='Class 0 (Inner)', alpha=0.7)\n",
        "\n",
        "# plt.scatter(class1_points[:, 0], class1_points[:, 1], c='red', label='Class 1 (Outer)', alpha=0.7)\n",
        "# plt.title('Concentric Rings Dataset')\n",
        "# plt.xlabel('Feature 1')\n",
        "# plt.ylabel('Feature 2')\n",
        "# plt.legend()\n",
        "# plt.grid(True)\n",
        "# plt.gca().set_aspect('equal', adjustable='box')\n",
        "# plt.show()"
      ],
      "metadata": {
        "id": "0Wsu6mPtfNcy"
      },
      "execution_count": 593,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Mnist dataset\n",
        "import copy\n",
        "from tensorflow.keras.datasets import mnist\n",
        "\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "\n",
        "X_train = (X_train.astype('float64') / 255.0).reshape(-1,28*28)\n",
        "X_test = (X_test.astype('float64') / 255.0).reshape(-1,28*28)\n",
        "\n",
        "X_test_copy = copy.deepcopy(X_test)\n",
        "y_test_copy = copy.deepcopy(y_test)\n",
        "\n",
        "X = X_train#[:2000,:]\n",
        "y = y_train.reshape(60000, -1)#[:2000,:]\n",
        "X_test = X_test#[:1000,:]\n",
        "y_test = y_test.reshape(-1,1)#[:1000, :]"
      ],
      "metadata": {
        "id": "_rV-2-fY5Ske"
      },
      "execution_count": 594,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X.shape, y.shape, X_test.shape, y_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Z1MPju7fNj6",
        "outputId": "cca67c70-5e76-4b7d-e106-b143cb1b8d55"
      },
      "execution_count": 595,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((60000, 784), (60000, 1), (10000, 784), (10000, 1))"
            ]
          },
          "metadata": {},
          "execution_count": 595
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def one_hot_encoding(vector):\n",
        "    vector = np.array(vector).astype(int).flatten()\n",
        "    # if vector.ndim == 1:\n",
        "    #     return vector\n",
        "    size=len(vector)\n",
        "    num_classes = max(np.max(vector) + 1, 10)\n",
        "\n",
        "    encoded_matrix = np.zeros((size, num_classes))\n",
        "    encoded_matrix[np.arange(size), vector] = 1\n",
        "    return encoded_matrix"
      ],
      "metadata": {
        "id": "wsCbSo0pwQ_l"
      },
      "execution_count": 596,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_test_split(X, y, test_size=0.2):\n",
        "    num_samples = X.shape[0]\n",
        "    train_size = int(np.ceil(num_samples * (1-test_size)))\n",
        "    test_size = int(np.floor(num_samples * test_size))\n",
        "\n",
        "    shuffled_indices = np.arange(num_samples)\n",
        "    np.random.shuffle(shuffled_indices)\n",
        "    X = X[shuffled_indices]\n",
        "    y= y[shuffled_indices]\n",
        "\n",
        "    X_train = X[:train_size, :]\n",
        "    y_train = y[:train_size,]\n",
        "    X_test = X[train_size:]\n",
        "    y_test = y[train_size:]\n",
        "\n",
        "    return X_train, y_train, X_test, y_test"
      ],
      "metadata": {
        "id": "fQo6YdzuK3sk"
      },
      "execution_count": 597,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# X_train, y_train, X_test, y_test = train_test_split(X, y)"
      ],
      "metadata": {
        "id": "DTUH6FEGOrcz"
      },
      "execution_count": 598,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def initialize_weights_and_biases(m_inputs, layer_sizes:list):\n",
        "    weights = {}\n",
        "    biases = {}\n",
        "\n",
        "    layers = [m_inputs] + layer_sizes\n",
        "\n",
        "    for i in range(len(layers)-1):\n",
        "        weights[\"W\" + str(i+1)] = np.random.randn(layers[i], layers[i+1])# * 0.01 left out due to vanishing gradients\n",
        "        biases[\"b\" + str(i+1)] = np.zeros((1, layers[i+1]))\n",
        "\n",
        "    # print(f\"Successfully initialized weights and biases for {len(layer_sizes)} layers\")\n",
        "    return weights, biases\n"
      ],
      "metadata": {
        "id": "pOIC9U5BfNo3"
      },
      "execution_count": 599,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sigmoid(z):\n",
        "    return 1 / (1 + np.exp(-z))\n",
        "\n",
        "def relu(z):\n",
        "    return np.maximum(0,z)\n",
        "\n",
        "def softmax(z):\n",
        "    exponent_values = np.exp(z - np.max(z, axis=1, keepdims=True))\n",
        "    return exponent_values / np.sum(exponent_values, axis=1, keepdims=True)"
      ],
      "metadata": {
        "id": "9NQVMamKbrlu"
      },
      "execution_count": 600,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def forward(A, weights, biases, activation_function):\n",
        "    Z_dict = {}\n",
        "    A_dict = {}\n",
        "    A_dict[\"A0\"] = A\n",
        "    l_dict = {}\n",
        "\n",
        "    if activation_function == 'relu':\n",
        "        activation_function = relu\n",
        "    else:\n",
        "        activation_function = sigmoid\n",
        "\n",
        "\n",
        "    for i in range(len(weights)-1): #loop through hidden layers\n",
        "        a_prev = A\n",
        "        Z = np.dot(a_prev, weights[\"W\" + str(i+1)]) + biases[\"b\" + str(i+1)]\n",
        "        Z_dict[\"Z\" + str(i+1)] = Z\n",
        "        A = activation_function(Z)\n",
        "        A_dict[\"A\" + str(i+1)] = A\n",
        "        l_dict['layer' + str(i+1)] = activation_function.__name__\n",
        "\n",
        "    last_index = len(weights)\n",
        "\n",
        "    if weights[list(weights.keys())[-1]].shape[1] == 1:\n",
        "        output_activation = sigmoid\n",
        "    else:\n",
        "        output_activation = softmax\n",
        "\n",
        "    a_prev = A\n",
        "    Z = np.dot(a_prev, weights[\"W\" + str(last_index)]) + biases[\"b\" + str(last_index)]\n",
        "    Z_dict[\"Z\" + str(last_index)] = Z\n",
        "    A = output_activation(Z)\n",
        "    A_dict[\"A\" + str(last_index)] = A\n",
        "    l_dict['layer' + str(last_index)] = output_activation.__name__\n",
        "\n",
        "\n",
        "    cache = {\"Z\":Z_dict,\n",
        "             \"A\":A_dict,\n",
        "             'layer_activations':l_dict}\n",
        "\n",
        "    # print(\"Successfully computed a forward pass\")\n",
        "    return cache"
      ],
      "metadata": {
        "id": "A_sdeVp1fNq3"
      },
      "execution_count": 601,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_loss(y_pred, y_true, loss='binary_cross_entropy'):\n",
        "    epsilon = 1e-8\n",
        "\n",
        "    if loss == 'cross_entropy':\n",
        "        return - np.mean(np.sum(y_true * np.log(y_pred + epsilon), axis=1))\n",
        "    else:\n",
        "        return - np.mean(y_true * np.log(y_pred + epsilon) + (1-y_true)*np.log(1-y_pred + epsilon)) # added 1e-8 to avoid log(0)"
      ],
      "metadata": {
        "id": "11iGNgXdoPaN"
      },
      "execution_count": 602,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sigmoid_derivative(z):\n",
        "    s = sigmoid(z)\n",
        "    return s * (1 - s)\n",
        "\n",
        "def relu_derivative(z):\n",
        "    return (z > 0).astype(float)"
      ],
      "metadata": {
        "id": "Cpa39xURvtTr"
      },
      "execution_count": 603,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def backpropagation(X, y, weights, biases, cache):\n",
        "\n",
        "    activation_derivative = sigmoid_derivative\n",
        "\n",
        "    A_cache = cache['A']\n",
        "    Z_cache = cache['Z']\n",
        "    L_cache = cache['layer_activations']\n",
        "\n",
        "    Z_gradients = {}\n",
        "    A_gradients = {}\n",
        "    W_gradients = {}\n",
        "    b_gradients = {}\n",
        "\n",
        "    m = X.shape[0]\n",
        "\n",
        "    for i in reversed(range(len(weights))):\n",
        "        if L_cache['layer' + str(i+1)] == 'relu':\n",
        "            activation_derivative = relu_derivative\n",
        "        if L_cache['layer' + str(i+1)] == 'sigmoid':\n",
        "            activation_derivative = sigmoid_derivative\n",
        "\n",
        "\n",
        "        if i+1 == len(weights): #special case for first dZ\n",
        "            dZ = A_cache[\"A\" + str(i+1)] - y\n",
        "            Z_gradients[\"dZ\" + str(i+1)] = dZ\n",
        "            W_gradients[\"dW\" + str(i+1)] = np.dot(A_cache[\"A\" + str(i)].T,dZ) / m\n",
        "            b_gradients[\"db\" + str(i+1)] = np.sum(dZ, axis=0, keepdims=True) / m\n",
        "        else:\n",
        "            dZ = np.dot(Z_gradients[\"dZ\" + str(i+2)], weights[\"W\" + str(i+2)].T ) * activation_derivative(Z_cache[\"Z\" + str(i+1)])\n",
        "            Z_gradients[\"dZ\" + str(i+1)] = dZ\n",
        "            W_gradients[\"dW\" + str(i+1)] = np.dot(A_cache[\"A\" + str(i)].T,dZ) / m\n",
        "            b_gradients[\"db\" + str(i+1)] = np.sum(dZ, axis=0, keepdims=True) / m\n",
        "\n",
        "        # print(f\"Layer {i+1} dW magnitude: {np.linalg.norm(W_gradients['dW' + str(i+1)])}\")\n",
        "        # print(f\"Layer {i+1} db magnitude: {np.linalg.norm(b_gradients['db' + str(i+1)])}\")\n",
        "\n",
        "    grads = {\"dW\" : W_gradients,\n",
        "             \"db\" : b_gradients}\n",
        "\n",
        "    return grads"
      ],
      "metadata": {
        "id": "oBO-AJcSpSct"
      },
      "execution_count": 604,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "weights, biases = initialize_weights_and_biases(m_inputs=784, layer_sizes=[256,10])"
      ],
      "metadata": {
        "id": "h6yc6ghG8j84"
      },
      "execution_count": 605,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Vdw = {}\n",
        "Vdb = {}\n",
        "Sdw = {}\n",
        "Sdb = {}\n",
        "Vdw_corrected = {}\n",
        "Vdb_corrected = {}\n",
        "Sdw_corrected = {}\n",
        "Sdb_corrected = {}\n",
        "\n",
        "t = 1\n",
        "\n",
        "for i in range(len(weights)):\n",
        "    Vdw['w' + str(i+1)] = np.zeros_like(weights['W' + str(i+1)])\n",
        "    Vdb['b' + str(i+1)] = np.zeros_like(biases['b' + str(i+1)])\n",
        "\n",
        "    Sdw['w' + str(i+1)] = np.zeros_like(weights['W' + str(i+1)])\n",
        "    Sdb['b' + str(i+1)] = np.zeros_like(biases['b' + str(i+1)])\n",
        "\n",
        "\n",
        "def update_params(grads, weights, biases, learning_rate, optimizer='gd', beta1=0.9, beta2=0.999, epsilon=1e-8):\n",
        "\n",
        "    dw = grads['dW']\n",
        "    db = grads['db']\n",
        "\n",
        "    global t\n",
        "\n",
        "    if optimizer == 'momentum':\n",
        "      for i in range(len(weights)):\n",
        "        Vdw['w' + str(i+1)] = beta1 * Vdw['w' + str(i+1)] + ((1-beta1) * dw['dW' + str(i+1)])\n",
        "        weights[\"W\" + str(i+1)] = weights[\"W\" + str(i+1)] - learning_rate * Vdw['w' + str(i+1)]\n",
        "\n",
        "        Vdb['b' + str(i+1)] = beta1 * Vdb['b' + str(i+1)] + ((1-beta1) * db[\"db\" + str(i+1)])\n",
        "        biases[\"b\" + str(i+1)] = biases[\"b\" + str(i+1)] - learning_rate * Vdb['b' + str(i+1)]\n",
        "\n",
        "    elif optimizer == 'rmsprop':\n",
        "        for i in range(len(weights)):\n",
        "            Sdw['w' + str(i+1)] = beta2 * Sdw['w' + str(i+1)] + ((1-beta2) * (dw['dW' + str(i+1)])**2)\n",
        "            weights[\"W\" + str(i+1)] = weights[\"W\" + str(i+1)] - learning_rate * ((dw['dW' + str(i+1)])/(np.sqrt(Sdw['w' + str(i+1)] + epsilon)))\n",
        "\n",
        "            # print(np.sqrt(Sdw['w1'] + epsilon))\n",
        "\n",
        "            Sdb['b' + str(i+1)] = beta2 * Sdb['b' + str(i+1)] + ((1-beta2) * (db['db' + str(i+1)])**2)\n",
        "            biases[\"b\" + str(i+1)] = biases[\"b\" + str(i+1)] - learning_rate * ((db['db' + str(i+1)])/(np.sqrt(Sdb['b' + str(i+1)] + epsilon)))\n",
        "\n",
        "    elif optimizer == 'adam':\n",
        "        for i in range(len(weights)):\n",
        "            Vdw['w' + str(i+1)] = beta1 * Vdw['w' + str(i+1)] + ((1-beta1) * dw['dW' + str(i+1)])\n",
        "            Sdw['w' + str(i+1)] = beta2 * Sdw['w' + str(i+1)] + ((1-beta2) * (dw['dW' + str(i+1)])**2)\n",
        "\n",
        "            Vdb['b' + str(i+1)] = beta1 * Vdb['b' + str(i+1)] + ((1-beta1) * db[\"db\" + str(i+1)])\n",
        "            Sdb['b' + str(i+1)] = beta2 * Sdb['b' + str(i+1)] + ((1-beta2) * (db['db' + str(i+1)])**2)\n",
        "\n",
        "\n",
        "            #bias correction\n",
        "            Vdw_corrected['w' + str(i+1)] = Vdw['w' + str(i+1)] / (1-beta1**t)\n",
        "            Vdb_corrected['b' + str(i+1)] = Vdb['b' + str(i+1)] / (1-beta1**t)\n",
        "\n",
        "            Sdw_corrected['w' + str(i+1)] = Sdw['w' + str(i+1)] / (1-beta2**t)\n",
        "            Sdb_corrected['b' + str(i+1)] = Sdb['b' + str(i+1)] / (1-beta2**t)\n",
        "\n",
        "\n",
        "            weights[\"W\" + str(i+1)] = weights[\"W\" + str(i+1)] - learning_rate * (Vdw_corrected['w' + str(i+1)] / np.sqrt(Sdw_corrected['w' + str(i+1)] + epsilon))\n",
        "            biases['b' + str(i+1)] = biases['b' + str(i+1)] - learning_rate * (Vdb_corrected['b' + str(i+1)] / np.sqrt(Sdb_corrected['b' + str(i+1)] + epsilon))\n",
        "\n",
        "        t += 1\n",
        "\n",
        "    else: #normal gd\n",
        "        for i in range(len(weights)):\n",
        "            weights[\"W\" + str(i+1)] = weights[\"W\" + str(i+1)] - learning_rate * dw[\"dW\" + str(i+1)]\n",
        "            biases[\"b\" + str(i+1)] = biases[\"b\" + str(i+1)] - learning_rate * db[\"db\" + str(i+1)]\n",
        "\n",
        "    # print(\"Successfully updated params\")\n",
        "    return weights, biases"
      ],
      "metadata": {
        "id": "djF7hwUtxlyr"
      },
      "execution_count": 606,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(X, weights, biases):\n",
        "    cache = forward(X, weights, biases, activation_function='relu')\n",
        "    prediction = cache['A'][list(cache['A'].keys())[-1]]\n",
        "    return prediction"
      ],
      "metadata": {
        "id": "uLU5V7b0y80T"
      },
      "execution_count": 607,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if len(np.unique(y)) > 2:\n",
        "    y = one_hot_encoding(y)\n",
        "    y_test = one_hot_encoding(y_test)\n",
        "    classification_type = 'multi'\n",
        "else:\n",
        "    classification_type = 'single'\n",
        "\n",
        "\n",
        "def accuracy(prediction, labels):\n",
        "    total = len(labels)\n",
        "\n",
        "    if classification_type == 'single':\n",
        "        acc = np.sum((prediction > 0.5).astype(int) == labels) / total\n",
        "    else:\n",
        "        predicted_class = np.argmax(prediction, axis=1)\n",
        "        true_class = np.argmax(labels, axis=1)\n",
        "        acc = np.mean(predicted_class == true_class)\n",
        "    return acc\n"
      ],
      "metadata": {
        "id": "YAN6QKh0HlhD"
      },
      "execution_count": 608,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run(epochs, learning_rate, optimizer='gd', beta1=0.9, beta2=0.999):\n",
        "    for i in range(epochs):\n",
        "        cache = forward(X, weights, biases, activation_function='relu')\n",
        "        prediction = cache['A'][list(cache['A'].keys())[-1]]\n",
        "        grads = backpropagation(X, y, weights, biases, cache)\n",
        "\n",
        "\n",
        "        if i % 100 == 0:\n",
        "            dev_predictions = predict(X_test, weights, biases)\n",
        "            print(f\"epoch: {i}, loss= {calculate_loss(prediction, y, loss='cross_entropy' if classification_type=='multi' else 'binary_cross_entropy')}, training-set accuracy= {accuracy(prediction, y)}, dev-set accuracy= {accuracy(dev_predictions, y_test)}\")\n",
        "\n",
        "        update_params(grads, weights, biases, learning_rate, optimizer=optimizer, beta1=beta1, beta2=beta2)"
      ],
      "metadata": {
        "id": "bE-obYbZv2Lb"
      },
      "execution_count": 609,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run_mini_batches(epochs, learning_rate, mini_batch_size=64, optimizer='gd', beta1=0.9, beta2=0.999):\n",
        "    num_samples = X.shape[0]\n",
        "    div = int(num_samples / mini_batch_size)\n",
        "\n",
        "    divisible_by_mini_batch_size = mini_batch_size * div\n",
        "    not_divisible = num_samples - divisible_by_mini_batch_size\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        shuffled_indices = np.arange(num_samples)\n",
        "        np.random.shuffle(shuffled_indices)\n",
        "        X_shuffled = X[shuffled_indices]\n",
        "        y_shuffled = y[shuffled_indices]\n",
        "\n",
        "        start = 0\n",
        "        end = 0\n",
        "        for batch in range(start, divisible_by_mini_batch_size, mini_batch_size):\n",
        "            start = end\n",
        "            end = start + mini_batch_size\n",
        "            X_batch = X_shuffled[start:end, :]\n",
        "            y_batch = y_shuffled[start:end]\n",
        "            #forward\n",
        "            cache = forward(X_batch, weights, biases, activation_function='relu')\n",
        "            prediction = cache['A'][list(cache['A'].keys())[-1]]\n",
        "            #backward\n",
        "            grads = backpropagation(X_batch, y_batch, weights, biases, cache)\n",
        "            #update\n",
        "            update_params(grads, weights, biases, learning_rate, optimizer=optimizer, beta1=beta1, beta2=beta2)\n",
        "\n",
        "        if not_divisible != 0:\n",
        "            X_batch = X_shuffled[divisible_by_mini_batch_size:, :]\n",
        "            y_batch = y_shuffled[divisible_by_mini_batch_size:]\n",
        "            #forward\n",
        "            cache = forward(X_batch, weights, biases, activation_function='relu')\n",
        "            prediction = cache['A'][list(cache['A'].keys())[-1]]\n",
        "            #backward\n",
        "            grads = backpropagation(X_batch, y_batch, weights, biases, cache)\n",
        "            #update\n",
        "            update_params(grads, weights, biases, learning_rate, optimizer=optimizer)\n",
        "\n",
        "        cache = forward(X, weights, biases, activation_function='relu')\n",
        "        full_prediction = cache['A'][list(cache['A'].keys())[-1]]\n",
        "        dev_predictions = predict(X_test, weights, biases)\n",
        "        print(f\"epoch: {epoch+1}, loss= {calculate_loss(full_prediction, y, loss='cross_entropy' if classification_type=='multi' else 'binary_cross_entropy')}, training-set accuracy= {accuracy(full_prediction, y)}, dev-set accuracy= {accuracy(dev_predictions, y_test)}\")\n"
      ],
      "metadata": {
        "id": "AgzrO6SZBrIw"
      },
      "execution_count": 610,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# run(epochs=10000, learning_rate=0.005)"
      ],
      "metadata": {
        "id": "4oMThHvuwDdK"
      },
      "execution_count": 611,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "run_mini_batches(epochs=20, learning_rate=0.005, mini_batch_size=32, optimizer='adam', beta1=0.9, beta2=0.999)"
      ],
      "metadata": {
        "id": "zq_460UVTJVT",
        "outputId": "8c3c0a36-8033-4605-a3c9-331bb1a7a606",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 612,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 1, loss= 0.8255342541003391, training-set accuracy= 0.93735, dev-set accuracy= 0.9292\n",
            "epoch: 2, loss= 0.4766131215350713, training-set accuracy= 0.95785, dev-set accuracy= 0.9447\n",
            "epoch: 3, loss= 0.44484899986337817, training-set accuracy= 0.9571666666666667, dev-set accuracy= 0.9414\n",
            "epoch: 4, loss= 0.2707630222584417, training-set accuracy= 0.9697166666666667, dev-set accuracy= 0.9493\n",
            "epoch: 5, loss= 0.1713941333516799, training-set accuracy= 0.97945, dev-set accuracy= 0.9597\n",
            "epoch: 6, loss= 0.15401865246800608, training-set accuracy= 0.98155, dev-set accuracy= 0.9579\n",
            "epoch: 7, loss= 0.1378584357184495, training-set accuracy= 0.98285, dev-set accuracy= 0.9616\n",
            "epoch: 8, loss= 0.11246101768806548, training-set accuracy= 0.9838833333333333, dev-set accuracy= 0.9606\n",
            "epoch: 9, loss= 0.08106594154015023, training-set accuracy= 0.9874, dev-set accuracy= 0.9656\n",
            "epoch: 10, loss= 0.16933342718654162, training-set accuracy= 0.9788166666666667, dev-set accuracy= 0.9577\n",
            "epoch: 11, loss= 0.06510508121974136, training-set accuracy= 0.9902166666666666, dev-set accuracy= 0.9662\n",
            "epoch: 12, loss= 0.10111275199325712, training-set accuracy= 0.9864833333333334, dev-set accuracy= 0.9654\n",
            "epoch: 13, loss= 0.07627380533107289, training-set accuracy= 0.9897, dev-set accuracy= 0.9671\n",
            "epoch: 14, loss= 0.06857248756395254, training-set accuracy= 0.9906833333333334, dev-set accuracy= 0.9701\n",
            "epoch: 15, loss= 0.0553012222336969, training-set accuracy= 0.99255, dev-set accuracy= 0.9704\n",
            "epoch: 16, loss= 0.04983809540764805, training-set accuracy= 0.99295, dev-set accuracy= 0.9713\n",
            "epoch: 17, loss= 0.06593526322285545, training-set accuracy= 0.9918333333333333, dev-set accuracy= 0.9677\n",
            "epoch: 18, loss= 0.06253879475349258, training-set accuracy= 0.9916166666666667, dev-set accuracy= 0.971\n",
            "epoch: 19, loss= 0.07237012398092603, training-set accuracy= 0.9911166666666666, dev-set accuracy= 0.9704\n",
            "epoch: 20, loss= 0.06340086858473817, training-set accuracy= 0.9928, dev-set accuracy= 0.9713\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# np.savez('best_trained_model_params[32,16,10].npz', **weights, **biases)\n",
        "# data = np.load('trained_model_params.npz')"
      ],
      "metadata": {
        "id": "PDZUH2uAUaeD"
      },
      "execution_count": 613,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#visualize mnist\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_predictions(X, y, num_images=10):\n",
        "    num_samples = X.shape[0]\n",
        "    shuffled_indices = np.arange(num_samples)\n",
        "    np.random.shuffle(shuffled_indices)\n",
        "    X_shuffled = X[shuffled_indices]\n",
        "    y_shuffled = y[shuffled_indices]\n",
        "\n",
        "    random_picks = np.random.choice(np.arange(num_samples), size=num_images)\n",
        "\n",
        "    images = X_shuffled[random_picks]\n",
        "    labels = y_shuffled[random_picks]\n",
        "    predictions_probability_distribution = predict(images, weights, biases)\n",
        "    predicted_labels = np.argmax(predictions_probability_distribution, axis=1)\n",
        "\n",
        "\n",
        "    fig, axes = plt.subplots(2, num_images, figsize=(20,6))\n",
        "    for i in range(len(images)):\n",
        "        axes[0,i].imshow(images[i].reshape(28,28), cmap='gray')\n",
        "        axes[0,i].set_title(\"true: \" + str(labels[i]) + \"\\npredicted: \" + str(predicted_labels[i]))\n",
        "        axes[0,i].axis('off')\n",
        "        axes[1,i].bar(x=np.arange(10), height=predictions_probability_distribution[i])\n",
        "        axes[1,i].set_ylim(0,1)\n",
        "        axes[1,i].set_xticks(np.arange(10))\n",
        "\n",
        "plot_predictions(X_test_copy, y_test_copy, num_images=5)"
      ],
      "metadata": {
        "id": "U2S_jh2B9N5O",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "50e8f650-54a4-4aa6-8281-a4698502fdfc"
      },
      "execution_count": 614,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 2000x600 with 10 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAABkEAAAIkCAYAAACp5IzGAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAWW1JREFUeJzt3XuY3PPZP/B7c9pISBo2Z5uDQ6VOQSKxVNUjFRpBK0QVqTq0GhpCiacl1CHqIaIEpXUsJaW0DxolaKmoilOjxDESaXNqJEtoQvb7++P52VrJTHYnM7sz33m9rmuuy849n8/nnpB3vpPbzFQkSZIEAAAAAABAyrRq6QYAAAAAAAAKwRAEAAAAAABIJUMQAAAAAAAglQxBAAAAAACAVDIEAQAAAAAAUskQBAAAAAAASCVDEAAAAAAAIJUMQQAAAAAAgFQyBAEAAAAAAFLJEAQAAAAAAEglQxDy7sknn4xzzz03li9f3tKtNMnrr78eo0aNii5dukSHDh3ii1/8Yjz66KMt3RZQQko1/z7ttttui4qKith4441buhWgxJRiBr7yyitxxhlnxE477RSbbLJJ9OzZM0aMGBHPPPNMS7cGlJhSzMC5c+dGRUXFOm933HFHS7cHlIhSzL9//OMfceSRR8Y222wTm2yySXzuc5+LIUOGxM033xxJkrR0exSAIQh59+STT8Z5551XUuE3f/78qKmpiSeeeCJ+8IMfxKRJk+L999+PfffdN/70pz+1dHtAiSjF/Pu0999/P84444zo2LFjS7cClKBSzMCf//zncf3118fgwYPjsssui/Hjx8ecOXNit912i4cffril2wNKSClm4Ce+8Y1vxK233trgVlNT09JtASWiFPNv6dKl8c4778SoUaPi0ksvjQsuuCB69uwZ3/rWt+KHP/xhS7dHAbRp6QYob3V1dbF69epo3759i/Zx8cUXx/Lly2P27NmxzTbbRETE8ccfHwMGDIhTTz01Zs2a1aL9AelTLPn3aRdccEFssskmsffee8e9997b0u0AKVYsGfiNb3wjzj333Abvfvv2t78dX/jCF+Lcc8+NYcOGtWB3QFoVSwZ+YpdddokjjzyypdsAykCx5N+OO+4Yjz32WIP7TjrppBg5cmT89Kc/jfPPPz9at27dMs1REN4JQl6de+658YMf/CAiIvr371//Vtq5c+dGRERFRUWcdNJJcdttt8V2220XlZWVMX369HjssceioqJirQD65O25N910U4P7X3nllRg1alRsuumm0b59+xg8eHD87ne/W6ufN954I95444319v3444/HzjvvXD8AiYjo0KFDHHjggfHss8/Ga6+91rRfCKDslGr+feK1116Lyy+/PCZPnhxt2vh/JICmKdUMHDRo0Fof/7fZZpvFnnvuGS+//HLjfwGAslaqGfhpK1eujNWrVzdpDUAa8u/T+vXrFx988IE8TCF/y0Feff3rX49XX301fvWrX8Xll18eVVVVERHRtWvX+sc88sgjMW3atDjppJOiqqoq+vXr16S3zL300kuxxx57RO/evWPChAnRsWPHmDZtWhx88MFx9913x9e+9rX6x+6zzz4REfXhm8mqVauiS5cua93foUOHiIiYNWtWbL311o3uESg/pZp/nzjllFNi7733jq9+9asxbdq0RvcEEFH6GfhZCxcurH8OAOtT6hl43nnnxQ9+8IOoqKiIQYMGxYUXXhj77rtvo3sDylep59+HH34YK1eujPfffz/++Mc/xo033hg1NTWx0UYbNbo/SoMhCHm14447xi677BK/+tWv4uCDD45+/fqt9Zg5c+bE3/72t9h2223r7/vs5DebcePGRZ8+feKvf/1rVFZWRkTE9773vfjiF78YZ555ZoPwa6xtttkmHn/88Xjvvfdik002qb//iSeeiIiIBQsWNHlPoLyUav5FRNx///3xhz/8IV544YWc1gOUcgZ+1uOPPx4zZ86MH/3oR3nZD0i/Us3AVq1axb777htf+9rXonfv3vHmm2/G5MmTY//994/f/e53MWLEiCbvCZSXUs2/T1xxxRVx1lln1f+8zz77xI033pjzfhQvH4dFs9trr70aBF9TLFu2LB555JE47LDD4r333oulS5fG0qVL41//+lcMHz48XnvttQYDi7lz5zZq+nviiSfG8uXLY/To0fHcc8/Fq6++Gqeccko888wzEfF/k2GADVWM+bd69eo49dRT47vf/W7OvQE0RjFm4GctXrw4jjjiiOjfv3+cccYZOfUKsC7FmIF9+vSJBx98ML773e/GyJEjY9y4cfHcc89F165d47TTTsupV4DPKsb8+8Q3vvGNeOihh+L222+PI444IiL8HWBaeScIza5///45r3399dcjSZI4++yz4+yzz17nYxYvXhy9e/du0r77779/XHnllTFhwoTYZZddIiJiq622igsvvDDOOOOMtT4rGiAXxZh/l19+eSxdujTOO++8nHsDaIxizMBPW7lyZRxwwAHx3nvvxRNPPOH6D8irYs/AT2y66aZxzDHHxMUXXxzvvPNObL755hu8J1Deijn/+vbtG3379o2I/xuInHDCCTFs2LCYM2eOj8RKGUMQmt26QqSiomKdj12zZk2Dn+vq6iIi4vTTT4/hw4evc81WW22VU18nnXRSHHPMMfHiiy9Gu3btYqeddopf/OIXERHx+c9/Pqc9AT6t2PJvxYoVccEFF8T3vve9qK2tjdra2oiIeP/99yNJkpg7d2506NAhunXr1qR9Adal2DLw01avXh1f//rX48UXX4wHH3wwtt9++5z3AliXYs7Az6quro6I//s/sA1BgA1VSvk3atSouP766+NPf/pTxvMoTYYg5F2mIMvmky8l/+wXI7399tsNft5iiy0iIqJt27YxbNiw3BrMomPHjlFTU1P/88MPPxwbbbRR7LHHHnk/C0ifUsu/d999N95///245JJL4pJLLlmr3r9//zjooIPi3nvvzct5QLqVWgZ+oq6uLo4++uiYMWNGTJs2Lfbaa6+87g+Uh1LNwHV58803I6LhFxsDZJKm/Pvko7BWrFhR8LNoXr4ThLzr2LFjRKwdZNn07ds3WrduHX/6058a3H/11Vc3+Llbt27x5S9/OX72s5/FP//5z7X2WbJkSYOf33jjjXjjjTca3cenPfnkk/Gb3/wmjj322OjcuXNOewDlpdTyr1u3bnHPPfesddt7772jffv2cc899zT4kjiAbEotAz9x8sknx5133hlXX311fP3rX2907wCfVooZ+Nl1ERELFiyIG264IXbcccfo2bNnY54GUObSkn8REb/4xS+ioqKi/qPySQ/vBCHvBg0aFBERP/zhD+Pwww+Ptm3bxsiRI+tDcV06d+4chx56aFx55ZVRUVERW265Zdx3332xePHitR47derU+OIXvxg77LBDHH/88bHFFlvEokWLYubMmfHOO+/ECy+8UP/YffbZJyJivV+K9Pbbb8dhhx0WBx54YPTo0SNeeumluPbaa2PHHXeMiy66KIdfBaAclVr+dejQIQ4++OC17r/33nvj6aefXmcNIJNSy8CIiClTpsTVV18dNTU10aFDh/jlL3/ZoP61r30ta/8AnyjFDDzjjDPijTfeiH322Sd69eoVc+fOjZ/97GexcuXKuOKKK3L4VQDKUSnm34UXXhh//vOfY7/99os+ffrEsmXL4u67746//vWvcfLJJ+f1I7YoEgkUwPnnn5/07t07adWqVRIRyVtvvZUkSZJERDJ27Nh1rlmyZElyyCGHJB06dEi6dOmSfOc730lmz56dRERy4403NnjsG2+8kRx99NFJjx49krZt2ya9e/dODjjggOSuu+5q8Li+ffsmffv2XW+/y5YtSw466KCkR48eSbt27ZL+/fsnZ555ZlJbW5vL0wfKWKnl37qMGTMm6dixY05rgfJWahk4ZsyYJCIy3j7pH6AxSi0Db7/99uRLX/pS0rVr16RNmzZJVVVV8rWvfS2ZNWtWLk8fKGOlln9/+MMfkgMOOCDp1atX0rZt22STTTZJ9thjj+TGG29M6urqcvkloMhVJEmSNOfQBQAAAAAAoDn4ThAAAAAAACCVDEEAAAAAAIBUMgQBAAAAAABSyRAEAAAAAABIJUMQAAAAAAAglQxBAAAAAACAVDIEocU89thjUVFREY899lj9fd/61reiX79+LdbTZ62rR4B8kIFAOZOBQLmSf0A5k4G0FEMQUuGiiy6Ke++9t6XbWKc77rgjdtlll2jfvn107do1jj322Fi6dGlLtwWkSDFn4Kd95StfiYqKijjppJNauhUgRYo1A3/zm9/E6NGjY4sttogOHTrENttsE6eddlosX768pVsDUqJY8+/cc8+NioqKtW7t27dv6daAFCnWDLznnnti+PDh0atXr6isrIzNN988Ro0aFbNnz27p1spam5ZuAD7t+uuvj7q6uiavu+iii2LUqFFx8MEH57+pDXDNNdfE9773vdhnn31i8uTJ8c4778QVV1wRzzzzTPzlL39xEQg0kLYM/LTf/OY3MXPmzJZuAyhiacvAE044IXr16hVHHnlk9OnTJ/72t7/FVVddFQ888EA8++yzsdFGG7V0i0CRSFv+feKaa66JjTfeuP7n1q1bt2A3QLFKWwb+7W9/iy5dusS4ceOiqqoqFi5cGDfccEMMGTIkZs6cGQMHDmzpFsuSIQhNVldXF6tXry7IX+C3bds273u2lNWrV8d///d/x5e+9KV46KGHoqKiIiIidt999xg5cmRcf/31cfLJJ7dwl0BTycCm+/e//x2nnXZanHnmmXHOOee0dDvABpCBjXfXXXfFl7/85Qb3DRo0KMaMGRO33XZbHHfccS3TGJAT+dd0o0aNiqqqqpZuA8gDGdh463rNe9xxx8Xmm28e11xzTVx77bUt0BU+DqtMffL21FdeeSUOO+yw6NSpU2y22WYxbty4+Pe//93gsZ98dMltt90W2223XVRWVsb06dMjImLBggXx7W9/O7p37x6VlZWx3XbbxQ033LDWee+8804cfPDB0bFjx+jWrVuceuqpsWrVqrUet67PAayrq4srrrgidthhh/qPlNpvv/3imWeeqe9v5cqVcfPNN9e/zfZb3/pW/fp89/jBBx/EK6+8st6PtJo9e3YsX748Ro8eXT8AiYg44IADYuONN4477rgj63qgcGRg4TPw0y655JKoq6uL008/vdFrgMKRgc2TgZ8dgEREfO1rX4uIiJdffnm964H8k3/New2YJEnU1tZGkiSNXgMUjgxs3gz8tG7dukWHDh18LGoL8k6QMnfYYYdFv379YtKkSfHUU0/FT3/603j33XfjlltuafC4Rx55JKZNmxYnnXRSVFVVRb9+/WLRokWx22671Qdj165d4/e//30ce+yxUVtbG6ecckpERHz44Yexzz77xLx58+L73/9+9OrVK2699dZ45JFHGtXjscceGzfddFPsv//+cdxxx8XHH38cjz/+eDz11FMxePDguPXWW+O4446LIUOGxAknnBAREVtuuWVEREF6fPrpp2PvvfeOiRMnxrnnnpux709Cc10fdbDRRhvFc889F3V1ddGqlVkktBQZ2PQeG5uBn5g3b15cfPHFccMNN/joFygyMrDpPTY1Az9r4cKFERH+z2hoYfKv6T3mkn9bbLFFvP/++9GxY8c4+OCD47LLLovu3bs3ai1QODKw6T3mkoHLly+Pjz76KBYuXBhTpkyJ2tra2GeffRq1lgJIKEsTJ05MIiI58MADG9z/ve99L4mI5IUXXqi/LyKSVq1aJS+99FKDxx577LFJz549k6VLlza4//DDD086d+6cfPDBB0mSJMmUKVOSiEimTZtW/5iVK1cmW221VRIRyaOPPlp//5gxY5K+ffvW//zII48kEZF8//vfX+s51NXV1f9zx44dkzFjxqz1mEL0+OijjyYRkUycOHGt8z5tyZIlSUVFRXLsscc2uP+VV15JIiKJiLX6ApqHDCx8Bn5i1KhRye67717/c0QkY8eObdRaoDBkYPNl4Lp6at26dfLqq6/mtB7YMPKvefJvypQpyUknnZTcdtttyV133ZWMGzcuadOmTbL11lsnK1asWO96oDBkYPNeA26zzTb1f/+38cYbJz/60Y+SNWvWNHo9+eV/QS9zY8eObfDzJ99R8cADDzS4f6+99optt922/uckSeLuu++OkSNHRpIksXTp0vrb8OHDY8WKFfHss8/W79WzZ88YNWpU/foOHTrUT2qzufvuu6OioiImTpy4Vu3THzG1LoXq8ctf/nIkSbLeyW9VVVUcdthhcfPNN8dll10Wb775Zjz++OMxevTo+s87/PDDD9f3SwAUkAwsXAZGRDz66KNx9913x5QpU9b7WKD5ycDCZuBn3X777fGLX/wiTjvttNh6662bvB7IH/lX2PwbN25cXHnllXHEEUfEIYccElOmTImbb745Xnvttbj66qvXux4oLBnYPNeAN954Y0yfPj2uvvrq+MIXvhAffvhhrFmzptHryS8fh1XmPvsCbMstt4xWrVrF3LlzG9zfv3//Bj8vWbIkli9fHtddd11cd91169x78eLFERHx9ttvx1ZbbbVWUG2zzTbr7e+NN96IXr16xaabbrrex35Wc/WYzc9+9rP48MMP4/TTT6//LPwjjzwyttxyy/jNb34TG2+88QbtD2wYGVi4DPz444/j+9//fhx11FGx66675rwPUDgysLDXgZ/2+OOPx7HHHhvDhw+PCy+8MG/7ArmRf82Xf5844ogj4rTTTouHH344JkyYkPf9gcaTgc2TgTU1NfX/fPjhh8cXvvCFiIi49NJL87I/TWMIQgOZJqqf/Rz3urq6iPi/v9AfM2bMOtfsuOOO+W2uiYqhx86dO8dvf/vbmDdvXsydOzf69u0bffv2jd133z26du0an/vc5wp6PtA0MjB/brnllpgzZ0787Gc/W+ti+r333ou5c+fWfzkcUBxkYGG88MILceCBB8b2228fd911V7Rp4yUYFBv51zyqq6tj2bJlLXI2kJkMLLwuXbrEf/3Xf8Vtt91mCNJCXIGXuddee63BZPf111+Purq66NevX9Z1Xbt2jU022STWrFkTw4YNy/rYvn37xuzZsyNJkgbBOmfOnPX2t+WWW8aDDz4Yy5YtyzoBXldgN1ePjdGnT5/o06dPRPzfFyPNmjUrDjnkkLzsDeROBm54j5nMmzcvPvroo9hjjz3Wqt1yyy1xyy23xD333BMHH3xwzmcAG0YGbniP6/PGG2/EfvvtF926dYsHHnjAu4ChSMi/De+xqZIkiblz58bOO++c972BppGBG95jLj788MNYsWJFQfZm/XwnSJmbOnVqg5+vvPLKiIjYf//9s65r3bp1HHLIIXH33XfH7Nmz16ovWbKk/p+/+tWvxj/+8Y+466676u/74IMPMr4t7dMOOeSQSJIkzjvvvLVqSZLU/3PHjh1j+fLlzdLjBx98EK+88kosXbp0vf2vy1lnnRUff/xxnHrqqTmtB/JHBja9x8Zm4OGHHx733HPPWrdPzrvnnnti6NChWfcACksGNr3HplwHLly4MPbdd99o1apVPPjgg9G1a9f1rgGah/xreo9Nyb9Pn/GJa665JpYsWRL77bffetcDhSUDm95jUzLwk4/b+rS5c+fGjBkzYvDgwetdT2F4J0iZe+utt+LAAw+M/fbbL2bOnBm//OUv44gjjoiBAweud+3FF18cjz76aAwdOjSOP/742HbbbWPZsmXx7LPPxsMPP1z/Ntfjjz8+rrrqqjj66KNj1qxZ0bNnz7j11lsb9REoe++9dxx11FHx05/+NF577bXYb7/9oq6uLh5//PHYe++946STToqIiEGDBsXDDz8ckydPjl69ekX//v1j6NChBenx6aefjr333jsmTpy43i9Euvjii2P27NkxdOjQaNOmTdx7773xhz/8IS644AKfkQ9FQAYWLgMHDBgQAwYMWGetf//+3gECRUAGFvY6cL/99os333wzzjjjjHjiiSfiiSeeqK917949vvKVr6z31wAoDPlX2Pzr27dvjB49OnbYYYdo3759PPHEE3HHHXfETjvtFN/5znfW+/yBwpKBhc3AHXbYIfbZZ5/YaaedokuXLvHaa6/FL37xi/joo4/i4osvXu/zp0ASytLEiROTiEj+/ve/J6NGjUo22WSTpEuXLslJJ52UfPjhhw0eGxHJ2LFj17nPokWLkrFjxybV1dVJ27Ztkx49eiT77LNPct111zV43Ntvv50ceOCBSYcOHZKqqqpk3LhxyfTp05OISB599NH6x40ZMybp27dvg7Uff/xx8j//8z/JgAEDknbt2iVdu3ZN9t9//2TWrFn1j3nllVeSL33pS8lGG22UREQyZsyYgvX46KOPJhGRTJw4cb2/zvfdd18yZMiQZJNNNkk6dOiQ7Lbbbsm0adPWuw4oLBnYPBm4Ltl+PYHmIQObJwMjIuNtr732Wu96IP/kX/Pk33HHHZdsu+22ySabbJK0bds22WqrrZIzzzwzqa2tXe9aoHBkYPNk4MSJE5PBgwcnXbp0Sdq0aZP06tUrOfzww5MXX3xxvWspnIok+dT7iCgb5557bpx33nmxZMmSqKqqaul2AJqVDATKmQwEypX8A8qZDKSc+U4QAAAAAAAglQxBAAAAAACAVDIEAQAAAAAAUsl3ggAAAAAAAKnknSAAAAAAAEAqGYIAAAAAAACp1KalGyhWFRUVLd0ClDyftle6ZCBsOBlYumQg5IccLD3yDzac7CtdMhA2XLFmoHeCAAAAAAAAqWQIAgAAAAAApJIhCAAAAAAAkEqGIAAAAAAAQCoZggAAAAAAAKlkCAIAAAAAAKSSIQgAAAAAAJBKhiAAAAAAAEAqGYIAAAAAAACpZAgCAAAAAACkkiEIAAAAAACQSoYgAAAAAABAKhmCAAAAAAAAqWQIAgAAAAAApJIhCAAAAAAAkEqGIAAAAAAAQCoZggAAAAAAAKlkCAIAAAAAAKSSIQgAAAAAAJBKhiAAAAAAAEAqGYIAAAAAAACp1KalGwAAAAAAoPSddtppWeuXXnppznvfcsstGWuPPPJI1rW33357xtpHH32Uc0+UBu8EAQAAAAAAUskQBAAAAAAASCVDEAAAAAAAIJUMQQAAAAAAgFQyBAEAAAAAAFLJEAQAAAAAAEglQxAAAAAAACCV2rR0AwBA8Zg2bVrW+m677Zax1qdPn3y3AzSD7bffPmt9+fLlOe9dVVWVsbZ06dKc17766qtZ11ZXV2etz5kzJ2sdAIDcrFq1Kms9SZKc9z7qqKNyqkVEfP3rX89YO/zww7Ou/fDDD7M3RtHzThAAAAAAACCVDEEAAAAAAIBUMgQBAAAAAABSyRAEAAAAAABIJUMQAAAAAAAglQxBAAAAAACAVGrT0g0AAM2ruro6Y+3QQw/Nunb8+PH5bgfIgxNPPDFr/aijjspYGzx4cNa1//rXv3LqKSKie/fuGWuLFi3Kee2Pf/zjrGsPOeSQrPXTTjstY23p0qVZ1z777LNZ6wAbYtttt81aP+CAAzLWjjvuuKxrt95664y13/72t1nXPvnkk1nrLeGBBx7IWp89e3YzdQJ8WuvWrVu6hXUaOXJkxtpzzz2Xde2ee+6ZsbZkyZKce6L5eCcIAAAAAACQSoYgAAAAAABAKhmCAAAAAAAAqWQIAgAAAAAApJIhCAAAAAAAkEqGIAAAAAAAQCoZggAAAAAAAKlUkSRJ0tJNFKOKioqWbgFKnngpXTIw3U499dSMtcmTJ2ddW1NTk7H21FNP5dxTGsnA0tVSGbjttttmrf/kJz/JWBsxYkS+26mX7dejpf47X7NmTdZ6q1bZ/1+vjz76KGNt4cKFWddut912GWsrV67MurbcyMHS4xqw5a3vWmzcuHHN1Enxe//997PW//u//ztjberUqflup57sK10yMD+6du2atf79738/Y23rrbfOunbPPffMWKuqqsq6tm3btlnr2Xz+85/PWHv99ddz3jeNijUDvRMEAAAAAABIJUMQAAAAAAAglQxBAAAAAACAVDIEAQAAAAAAUskQBAAAAAAASCVDEAAAAAAAIJUqkiRJWrqJYlRRUdHSLZSF/fffP2Nt6tSpWdfOmzcvY+2Xv/xl1rU///nPszeWxde+9rWMtb59+2ZdO2XKlJzPLUXipXTJwMarrq7OWOvdu3fWtU899VS+22mUDfm96b+NxpOBpaul/jt/8MEHs9a/8pWvZKwtWLAg69pvfetbGWuHHnpo1rW//vWvs9Zztd1222Wtv/TSSxlrhxxySNa13/nOd7LWN+Tf8YgRIzLWfv/73+e8bxrJwdLjz/n8GDBgQNb6mDFjMtbGjx+fdW2bNm1y6imNXnjhhaz1888/P2PtnnvuyXc79WRf6ZKBpe2HP/xh1nq2TFif0047LWPt8ssvz3nfNCrWDPROEAAAAAAAIJUMQQAAAAAAgFQyBAEAAAAAAFLJEAQAAAAAAEglQxAAAAAAACCVDEEAAAAAAIBUMgQBAAAAAABSqSJJkqSlmyhGFRUVLd1CyRgwYEDG2h/+8Iesa3v27Jmx1qZNm6xrs/2nu77/rJ977rmMtQsuuCDr2nPOOSdjrWvXrlnXVldXZ62njXgpXTKw8Z588smMtZqamqxrC/XrvL6smTdvXs57+2+j8WRg6Wqp/84POeSQrPVtt902Y+3aa6/NunbJkiU59VSqttpqq6z1hx56KGOtb9++Wdeee+65GWs//vGPs64tN3Kw9PhzvvH69euXsXb22WdnXfutb30rv838f6effnrW+l//+teCnLu+a95XX301Y+1f//pXzue+9tprWeuLFi3Kee8NIftKlwwsftle61544YVZ1x555JE5n3vFFVdkrJ166qk575tGxZqB3gkCAAAAAACkkiEIAAAAAACQSoYgAAAAAABAKhmCAAAAAAAAqWQIAgAAAAAApJIhCAAAAAAAkEptWroBit8VV1yRtX7CCSdkrFVWVmZd+/bbb2estWvXLuvanj17ZqxVVFTkvHbixIlZ1w4cODBjbcGCBVnXAqXn1FNPzVqvqanJWJs/f36+22mUUaNG5bx25syZeewEaIq77757g+r8x+uvv561Pm/evIy1vn37Zl27yy675NQTUFratm2btX7hhRdmrB1++OH5bqfeo48+mrF22223ZV27ePHifLcTERFPPPFEQfYF0qlDhw4Za3vvvXfWtTfeeGPGWlVVVc49rc/UqVMLtjfNwztBAAAAAACAVDIEAQAAAAAAUskQBAAAAAAASCVDEAAAAAAAIJUMQQAAAAAAgFQyBAEAAAAAAFLJEAQAAAAAAEilNi3dAMXhyCOPzFgbO3Zs1rWtWmWepU2bNi3r2htuuCFj7Zprrsm6duHChRlr3/nOd7KuveSSSzLWBg4cmHXte++9l7H2rW99K+taoDhVV1dnrE2ePDnnfU8//fSc126ImpqanNe+8847eewEoGWMHj06a33IkCE57/3lL385Y61r165Z1y5ZsiTnc4H869OnT8ba+eefn3Xt4Ycfnu92IiLivPPOy1qfOnVqxtq//vWvfLcDsE5Dhw7NWJswYULWtV26dMlY+9KXvpRzTxvirrvuylrP9neQlAbvBAEAAAAAAFLJEAQAAAAAAEglQxAAAAAAACCVDEEAAAAAAIBUMgQBAAAAAABSyRAEAAAAAABIpTYt3QDNY8yYMVnrU6ZMyVh76623sq69+uqrM9auuuqqrGsffPDBjLX27dtnXXvggQdmrJ155plZ126zzTZZ69n861//ylibMWNGzvsCLefPf/5zzmvnz5+fsTZt2rSc990Qm2++ec5rZ86cmcdOAAqjZ8+eWevnnntu1nplZWXG2qpVq7KuHTt2bMbakiVLsq4FikuSJBlru+66azN28h/re/2d7fUoQHM59dRTM9YOOuigZuwkP7p37561vu2222asPf300/luhwLwThAAAAAAACCVDEEAAAAAAIBUMgQBAAAAAABSyRAEAAAAAABIJUMQAAAAAAAglQxBAAAAAACAVDIEAQAAAAAAUqlNSzdA8+jQoUPWeufOnTPW/vd//zfr2ssvvzynniIibrzxxoy1999/P+vaX//61xlr3bt3z7mn9bnssssKtjdQGLvttlvWenV1dc57n3766TmvLZSampqc195111157ASgMG655Zas9W222SbnvR988MGs9dtuuy3nvYHiMnr06Iy1DcmRDXH99ddvUL1QHnrooYy1yZMnZ1376KOP5rsdoMA233zzrPUvf/nLzdNIM9lzzz2z1u+9996MtV/+8pdZ1/7oRz/KWFu9enXWteSPd4IAAAAAAACpZAgCAAAAAACkkiEIAAAAAACQSoYgAAAAAABAKhmCAAAAAAAAqWQIAgAAAAAApFKblm6A4nfQQQdlrZ944okZa926dcu6dvHixRlrF154Yda1m2++edZ6oSxfvrxFzgVy16dPn4LtPW3atILtnc1uu+1WkH3nz59fkH0Bmqpfv34ZazvttNMG7X3fffdlrB122GEbtDdQOg444ICWbmEtbdu2bekW1umrX/1qxtpee+2Vde3222+fsTZv3rycewIKp0OHDlnr6/v7vrTp0aNHxtrpp5+ede1GG22UsTZ+/Pisaz/66KPsjdFo3gkCAAAAAACkkiEIAAAAAACQSoYgAAAAAABAKhmCAAAAAAAAqWQIAgAAAAAApJIhCAAAAAAAkEqGIAAAAAAAQCq1aekGaB7Tpk3LWj/88MMz1vbcc8+sa6dOnZqx9t5772Vd27Zt24y19u3bZ127bNmyjLU777wz69ptt902Y22vvfbKuvakk07KWLvtttuyrgXIl0MPPbRFzq2urs5YO+WUU7KuPe200/LcDZBm2a5BN9tssw3a+9JLL81YW7169QbtDZSO1157LWNtfa+DN8S8efMy1ubMmVOwc7O9xt6Q59uxY8es9TZt/NUTlJr58+dnrdfU1DRTJ/kzYMCAjLXvf//7WdfuvPPOOZ87duzYjLW5c+dmXXvZZZflfC4NeScIAAAAAACQSoYgAAAAAABAKhmCAAAAAAAAqWQIAgAAAAAApJIhCAAAAAAAkEqGIAAAAAAAQCpVJEmStHQTxaiioqKlW2hWVVVVGWt33XVX1rVf+tKX8t1ORET85S9/yVr/8Y9/nLH25JNPZl07ffr0jLWhQ4dmXTt37tyMtS222CLr2nIjXkpX2jKwuro6a33evHk5711TU5Ox9tRTT+W87/pky7lsPa3P+v7dH3bYYRlrd955Z9a1ffr0yVibP39+9sZKkAwsXWnLwGLVrl27rPUPP/wwY219/46uv/76rPUTTzwxY62uri7rWhpPDpaecsu/zp07Z6ztuuuuBTs323XPnDlzCnZu9+7dM9ZeeOGFrGu7du2a87lbb711xtqbb76Z877FSvaVrnLLQP6jS5cuWet33HFHxtpXvvKVnM+dMmVK1vr48eNz3rulFGsGeicIAAAAAACQSoYgAAAAAABAKhmCAAAAAAAAqWQIAgAAAAAApJIhCAAAAAAAkEqGIAAAAAAAQCoZggAAAAAAAKnUpqUboDgsXbo0Y+3QQw/NunbrrbfOdzsRETF79uys9dra2oy1wYMHZ107dOjQnHoCStP8+fNzrldXV2ddO23atIy1PfbYY4P6yqampibntRvyfC+99NKczwX4tNNOOy1rvaKiIue913cdWVdXl/PeQHqsWLEiY+3hhx9uxk6aR7bX/ffdd1/Wtcccc0zO5371q1/NWLvqqqty3hcgX959992s9eeeey5j7Stf+Uq+26EAvBMEAAAAAABIJUMQAAAAAAAglQxBAAAAAACAVDIEAQAAAAAAUskQBAAAAAAASCVDEAAAAAAAIJXatHQDFL8lS5ZsUD1tbrjhhpZuAcizPfbYI2Nt3rx5WddWV1fnvPbXv/51xtrMmTOzrt0Q2Xr+85//nPPayZMnZ107f/787I0BqbPffvtlrJ1//vk57/vMM89krV9//fU57w2UlsrKypzXJkmSsbZ69eqc9y1WPXv2zFg75phjCnbuAw88ULC9odxly8DRo0dnXfvkk09mrL3++us591Ss+vTpk7H2q1/9KuvawYMH57sdmpl3ggAAAAAAAKlkCAIAAAAAAKSSIQgAAAAAAJBKhiAAAAAAAEAqGYIAAAAAAACpZAgCAAAAAACkkiEIAAAAAACQSm1augEoNXvuuWdLtwDk2fz58zPW+vTpk3XtZZddlrF26KGHZl2brb6+tYVSXV2dtT558uSMtdNOOy3f7QBFbuONN85av+GGGzLWWrXK/f/HmjRpUtb6v//975z3LlabbrppxtoVV1yRde1RRx2V73agaGS7jttss82yrv3LX/6Ssbb77rvn3BNAc8n2d1Q33XRT1rVTp07NWDv55JNzbWmD9OzZM2t9xIgRGWvf/va3s67daqutMtaqqqqyN7YBXn755Yy1Sy+9tGDn0pB3ggAAAAAAAKlkCAIAAAAAAKSSIQgAAAAAAJBKhiAAAAAAAEAqGYIAAAAAAACpZAgCAAAAAACkUpuWbgBKzdZbb93SLQDNaP78+Vnrhx12WMZadXV11rU1NTUZa0OHDs26dvz48Vnrua69/PLLc94XKD9jx47NWu/Ro0fOe99www0Za/fff3/O+26oysrKjLVOnTrlvO+///3vrPVsfy5885vfzLr2qKOOyqknKAY77bRT1nr79u1z3nvw4MEZawceeGDWtb/73e9yPrdQqqqqstaPPPLIgpz797//PWt9zz33zFh78803890OlJUDDjgg57Xf/e53M9Z22WWXrGtnz56dsba+/Mymbdu2Weubbrppznu3lIMOOihj7R//+EczdlLevBMEAAAAAABIJUMQAAAAAAAglQxBAAAAAACAVDIEAQAAAAAAUskQBAAAAAAASCVDEAAAAAAAIJUMQQAAAAAAgFRq09INQCG8+eabWeuzZs3KWBs0aFC+2wHK1Pz58zeoXiiXX355i5wLlKaqqqqMtVNPPbVg5+60004Za7fffnvBzl2fnj17ZqzV1NTkvO9bb72Vtd6/f/+c94ZStu+++2atd+zYMee9W7dunVOtWF111VVZ64ceemhBzr366quz1m+++eaCnAtsmGw5N3To0Kxrs/3dWbt27XLuqVjddNNNGWuPPfZY1rXr+ztKmod3ggAAAAAAAKlkCAIAAAAAAKSSIQgAAAAAAJBKhiAAAAAAAEAqGYIAAAAAAACpZAgCAAAAAACkUpuWbgAKYdmyZVnr//jHPzLWBg0alO92AABK1uWXX56x1q1bt4Kdu8suu+RUK1X9+/fPee2///3vPHYCxeXWW2/NWj/ssMMy1nbeeeecz91uu+2y1p966qmMtX/+859Z1/bu3TtjbdSoUVnXHn744RlrAwYMyLo2m7q6uqz1H//4xxlr1113Xc7nAhvmJz/5Scba97///Zz3bdUq+/83365du5z3LpQ33ngja/3uu+/OWHvppZeyrr3tttsy1taXnxQH7wQBAAAAAABSyRAEAAAAAABIJUMQAAAAAAAglQxBAAAAAACAVDIEAQAAAAAAUskQBAAAAAAASCVDEAAAAAAAIJXatHQD0BJqa2tbugUAgJLwj3/8I2Nt3rx5Wdf26dMnYy1Jkqxrn3rqqYy1bt26ZV27ZMmSrPXtttsuY+3ll1/OunbNmjVZ69m88847GWvz58/PuvbDDz/MWJs8eXLOPUGx++c//5m1fuGFF2as3X777VnXtmvXLmPtvPPOy7r20EMPzVhbXzb269cvY23bbbfNunZDfPzxxxlrl1xySda1559/fr7bAfJg4cKFGWtHHXVU1rW33nprzuc+/vjjGWt77rln1rV33HFHxtrrr7+ede3NN9+csfb2229nXZstA0k/7wQBAAAAAABSyRAEAAAAAABIJUMQAAAAAAAglQxBAAAAAACAVDIEAQAAAAAAUskQBAAAAAAASKWKJEmSlm6iGFVUVLR0CxTQwIEDM9aee+65rGvnzp2bsbbFFlvk2lIqiZfSJQOLX7bfX/Pnz8+6tk+fPvluh3WQgaVLBjZet27dstZ79OiR894vvvhixtqmm26ade27776btZ7tmi3btV5ExJo1a7LW+Q85WHrSln9nnXVW1vrEiRMz1tq2bZvvdgpuxYoVWetTp07NWDv77LPz3U7Zkn2lK20ZCC2hWDPQO0EAAAAAAIBUMgQBAAAAAABSyRAEAAAAAABIJUMQAAAAAAAglQxBAAAAAACAVDIEAQAAAAAAUskQBAAAAAAASKU2Ld0AtIS2bdu2dAsAG6SioqKlWwCIxYsXb1A9V8uWLdug9W+88UaeOgGK2aRJk7LW6+rqMtYuuuiifLeTF1OmTMlY++lPf5p17dtvv53nbgCgNHgnCAAAAAAAkEqGIAAAAAAAQCoZggAAAAAAAKlkCAIAAAAAAKSSIQgAAAAAAJBKhiAAAAAAAEAqVSRJkrR0E8WooqKipVuggH77299mrI0cOTLr2rlz52asbbHFFrm2lEripXTJQNhwMrB0yUDIDzlYeuQfbDjZV7pkIGy4Ys1A7wQBAAAAAABSyRAEAAAAAABIJUMQAAAAAAAglQxBAAAAAACAVDIEAQAAAAAAUskQBAAAAAAASCVDEAAAAAAAIJXatHQD0BJmzJiRsTZy5Mhm7AQAAAAAgELxThAAAAAAACCVDEEAAAAAAIBUMgQBAAAAAABSyRAEAAAAAABIJUMQAAAAAAAglQxBAAAAAACAVKpIkiRp6SaKUUVFRUu3ACVPvJQuGQgbTgaWLhkI+SEHS4/8gw0n+0qXDIQNV6wZ6J0gAAAAAABAKhmCAAAAAAAAqWQIAgAAAAAApJIhCAAAAAAAkEqGIAAAAAAAQCoZggAAAAAAAKlkCAIAAAAAAKRSRZIkSUs3AQAAAAAAkG/eCQIAAAAAAKSSIQgAAAAAAJBKhiAAAAAAAEAqGYIAAAAAAACpZAgCAAAAAACkkiEIAAAAAACQSoYgAAAAAABAKhmCAAAAAAAAqWQIAgAAAAAApJIhCAAAAAAAkEqGIAAAAAAAQCoZggAAAAAAAKlkCAIAAAAAAKSSIQgAAAAAAJBKhiAAAAAAAEAqGYIAAAAAAACpZAgCAAAAAACkkiEIAAAAAACQSoYgAAAAAABAKhmCAAAAAAAAqWQIAgAAAAAApJIhCAAAAAAAkEqGIAAAAAAAQCoZggAAAAAAAKlkCAIAAAAAAKSSIQgAAAAAAJBKhiAAAAAAAEAqGYIAAAAAAACpZAgCAAAAAACkkiEIAAAAAACQSoYgAAAAAABAKhmCAAAAAAAAqWQIAgAAAAAApJIhCAAAAAAAkEqGIAAAAAAAQCoZggAAAAAAAKlkCAIAAAAAAKSSIQgAAAAAAJBKTR6C/OlPf4qRI0dGr169oqKiIu699971rnnsscdil112icrKythqq63ipptuyqFVgJYl/4ByJgOBciYDgXIl/4A0aPIQZOXKlTFw4MCYOnVqox7/1ltvxYgRI2LvvfeO559/Pk455ZQ47rjj4sEHH2xyswAtSf4B5UwGAuVMBgLlSv4BaVCRJEmS8+KKirjnnnvi4IMPzviYM888M+6///6YPXt2/X2HH354LF++PKZPn77ONatWrYpVq1bV/1xXVxfLli2LzTbbLCoqKnJtF0i5JEnivffei169ekWrVoX9tD/5BxQbGQiUq+bMvwgZCBQX14BAOWtsBrYpdCMzZ86MYcOGNbhv+PDhccopp2RcM2nSpDjvvPMK3BmQVvPnz4/NN9+8pduQf0CLkIFAuSqW/IuQgUDzK5YMlH9AS1hfBhZ8CLJw4cLo3r17g/u6d+8etbW18eGHH8ZGG2201pqzzjorxo8fX//zihUrok+fPjF//vzo1KlToVsGNsD2E/P7FtfZ5w1v9GNra2ujuro6Ntlkk7z2kCv5R0TL/p6gvMjAdJEd0HjFln8RMpDm4c8KIoovA+Vf8ZMdpEljM7DgQ5BcVFZWRmVl5Vr3d+rUSfhBkWtV2SGv++Xye76U3y4r/9KnGH5PUF5kYDrIDmi6Us6/CBlI0/mzgk8r5QyUf81LdpBG68vAgn9gao8ePWLRokUN7lu0aFF06tRpndNfgLSQf0A5k4FAOZOBQLmSf0AxKvgQpKamJmbMmNHgvoceeihqamoKfTRAi5J/QDmTgUA5k4FAuZJ/QDFq8hDk/fffj+effz6ef/75iIh466234vnnn4958+ZFxP99jt/RRx9d//jvfve78eabb8YZZ5wRr7zySlx99dUxbdq0OPXUU/PzDACaifwDypkMBMqZDATKlfwD0qDJQ5Bnnnkmdt5559h5550jImL8+PGx8847xznnnBMREf/85z/rgzAion///nH//ffHQw89FAMHDozLLrssfv7zn8fw4b40Bygt8g8oZzIQKGcyEChX8g9Ig4okSZKWbmJ9amtro3PnzrFixQpftgNFrt+E+/O639yLRzT6sWnMijQ+p3LTkr8nKC9pzIs0PqfGkh3QeGnNirQ+L/LHnxVEpDMr0vicionsIE0amxcF/04QAAAAAACAlmAIAgAAAAAApJIhCAAAAAAAkEqGIAAAAAAAQCoZggAAAAAAAKlkCAIAAAAAAKSSIQgAAAAAAJBKhiAAAAAAAEAqGYIAAAAAAACpZAgCAAAAAACkkiEIAAAAAACQSoYgAAAAAABAKhmCAAAAAAAAqWQIAgAAAAAApJIhCAAAAAAAkEqGIAAAAAAAQCoZggAAAAAAAKlkCAIAAAAAAKSSIQgAAAAAAJBKhiAAAAAAAEAqGYIAAAAAAACpZAgCAAAAAACkkiEIAAAAAACQSoYgAAAAAABAKhmCAAAAAAAAqWQIAgAAAAAApJIhCAAAAAAAkEqGIAAAAAAAQCoZggAAAAAAAKlkCAIAAAAAAKSSIQgAAAAAAJBKOQ1Bpk6dGv369Yv27dvH0KFD4+mnn876+ClTpsQ222wTG220UVRXV8epp54a//73v3NqGKClyUCgXMk/oJzJQKCcyUCglDV5CHLnnXfG+PHjY+LEifHss8/GwIEDY/jw4bF48eJ1Pv7222+PCRMmxMSJE+Pll1+OX/ziF3HnnXfGf//3f29w8wDNTQYC5Ur+AeVMBgLlTAYCpa7JQ5DJkyfH8ccfH8ccc0xsu+22ce2110aHDh3ihhtuWOfjn3zyydhjjz3iiCOOiH79+sW+++4b3/jGN7JOjFetWhW1tbUNbgDFoNAZKP+AYuUaEChnMhAoZ14HA6WuSUOQ1atXx6xZs2LYsGH/2aBVqxg2bFjMnDlznWt23333mDVrVn3Qvfnmm/HAAw/EV7/61YznTJo0KTp37lx/q66ubkqbAAXRHBko/4Bi5BoQKGcyEChnXgcDadCmKQ9eunRprFmzJrp3797g/u7du8crr7yyzjVHHHFELF26NL74xS9GkiTx8ccfx3e/+92sb4E766yzYvz48fU/19bWCkCgxTVHBso/oBi5BgTKmQwEypnXwUAa5PTF6E3x2GOPxUUXXRRXX311PPvss/Gb3/wm7r///jj//PMzrqmsrIxOnTo1uAGUoqZmoPwD0sI1IFDOZCBQzrwOBopNk94JUlVVFa1bt45FixY1uH/RokXRo0ePda45++yz46ijjorjjjsuIiJ22GGHWLlyZZxwwgnxwx/+MFq1KvgcBiAvZCBQruQfUM5kIFDOZCCQBk1KnXbt2sWgQYNixowZ9ffV1dXFjBkzoqamZp1rPvjgg7XCrXXr1hERkSRJU/sFaDEyEChX8g8oZzIQKGcyEEiDJr0TJCJi/PjxMWbMmBg8eHAMGTIkpkyZEitXroxjjjkmIiKOPvro6N27d0yaNCkiIkaOHBmTJ0+OnXfeOYYOHRqvv/56nH322TFy5Mj6AAQoFTIQKFfyDyhnMhAoZzIQKHVNHoKMHj06lixZEuecc04sXLgwdtppp5g+fXr9FyTNmzevwbT3Rz/6UVRUVMSPfvSjWLBgQXTt2jVGjhwZF154Yf6eBUAzkYFAuZJ/QDmTgUA5k4FAqatISuB9aLW1tdG5c+dYsWKFL0eCItdvwv153W/uxSMa/dg0ZkUan1O5acnfE5SXNOZFGp9TY8kOaLy0ZkVanxf5488KItKZFWl8TsVEdpAmjc0L30QEAAAAAACkkiEIAAAAAACQSoYgAAAAAABAKhmCAAAAAAAAqWQIAgAAAAAApJIhCAAAAAAAkEqGIAAAAAAAQCoZggAAAAAAAKlkCAIAAAAAAKSSIQgAAAAAAJBKhiAAAAAAAEAqGYIAAAAAAACpZAgCAAAAAACkkiEIAAAAAACQSoYgAAAAAABAKhmCAAAAAAAAqWQIAgAAAAAApJIhCAAAAAAAkEqGIAAAAAAAQCoZggAAAAAAAKlkCAIAAAAAAKSSIQgAAAAAAJBKhiAAAAAAAEAqGYIAAAAAAACpZAgCAAAAAACkkiEIAAAAAACQSoYgAAAAAABAKhmCAAAAAAAAqWQIAgAAAAAApJIhCAAAAAAAkEqGIAAAAAAAQCrlNASZOnVq9OvXL9q3bx9Dhw6Np59+Ouvjly9fHmPHjo2ePXtGZWVlfP7zn48HHnggp4YBWpoMBMqV/APKmQwEypkMBEpZm6YuuPPOO2P8+PFx7bXXxtChQ2PKlCkxfPjwmDNnTnTr1m2tx69evTq+8pWvRLdu3eKuu+6K3r17x9tvvx2f+9zn8tE/QLOSgUC5kn9AOZOBQDmTgUCpa/IQZPLkyXH88cfHMcccExER1157bdx///1xww03xIQJE9Z6/A033BDLli2LJ598Mtq2bRsREf369ct6xqpVq2LVqlX1P9fW1ja1TYCCKHQGyj+gWLkGBMqZDATKmdfBQKlr0sdhrV69OmbNmhXDhg37zwatWsWwYcNi5syZ61zzu9/9LmpqamLs2LHRvXv32H777eOiiy6KNWvWZDxn0qRJ0blz5/pbdXV1U9oEKIjmyED5BxQj14BAOZOBQDnzOhhIgyYNQZYuXRpr1qyJ7t27N7i/e/fusXDhwnWuefPNN+Ouu+6KNWvWxAMPPBBnn312XHbZZXHBBRdkPOess86KFStW1N/mz5/flDYBCqI5MlD+AcXINSBQzmQgUM68DgbSoMkfh9VUdXV10a1bt7juuuuidevWMWjQoFiwYEH8z//8T0ycOHGdayorK6OysrLQrQEUXFMzUP4BaeEaEChnMhAoZ14HA8WmSUOQqqqqaN26dSxatKjB/YsWLYoePXqsc03Pnj2jbdu20bp16/r7vvCFL8TChQtj9erV0a5duxzaBmh+MhAoV/IPKGcyEChnMhBIgyZ9HFa7du1i0KBBMWPGjPr76urqYsaMGVFTU7PONXvssUe8/vrrUVdXV3/fq6++Gj179hR6QEmRgUC5kn9AOZOBQDmTgUAaNGkIEhExfvz4uP766+Pmm2+Ol19+OU488cRYuXJlHHPMMRERcfTRR8dZZ51V//gTTzwxli1bFuPGjYtXX3017r///rjoooti7Nix+XsWAM1EBgLlSv4B5UwGAuVMBgKlrsnfCTJ69OhYsmRJnHPOObFw4cLYaaedYvr06fVfkDRv3rxo1eo/s5Xq6up48MEH49RTT40dd9wxevfuHePGjYszzzwzf88CoJnIQKBcyT+gnMlAoJzJQKDUVSRJkrR0E+tTW1sbnTt3jhUrVkSnTp1auh0gi34T7s/rfnMvHtHox6YxK9L4nMpNS/6eoLykMS/S+JwaS3ZA46U1K9L6vMgff1YQkc6sSONzKiaygzRpbF40+eOwAAAAAAAASoEhCAAAAAAAkEqGIAAAAAAAQCoZggAAAAAAAKlkCAIAAAAAAKSSIQgAAAAAAJBKhiAAAAAAAEAqGYIAAAAAAACpZAgCAAAAAACkkiEIAAAAAACQSoYgAAAAAABAKhmCAAAAAAAAqWQIAgAAAAAApJIhCAAAAAAAkEqGIAAAAAAAQCoZggAAAAAAAKlkCAIAAAAAAKSSIQgAAAAAAJBKhiAAAAAAAEAqGYIAAAAAAACpZAgCAAAAAACkkiEIAAAAAACQSoYgAAAAAABAKhmCAAAAAAAAqWQIAgAAAAAApJIhCAAAAAAAkEqGIAAAAAAAQCoZggAAAAAAAKlkCAIAAAAAAKSSIQgAAAAAAJBKhiAAAAAAAEAq5TQEmTp1avTr1y/at28fQ4cOjaeffrpR6+64446oqKiIgw8+OJdjAYqCDATKlfwDypkMBMqZDARKWZOHIHfeeWeMHz8+Jk6cGM8++2wMHDgwhg8fHosXL866bu7cuXH66afHnnvumXOzAC1NBgLlSv4B5UwGAuVMBgKlrslDkMmTJ8fxxx8fxxxzTGy77bZx7bXXRocOHeKGG27IuGbNmjXxzW9+M84777zYYost1nvGqlWrora2tsENoBgUOgPlH1CsXAMC5UwGAuXM62Cg1DVpCLJ69eqYNWtWDBs27D8btGoVw4YNi5kzZ2Zc9+Mf/zi6desWxx57bKPOmTRpUnTu3Ln+Vl1d3ZQ2AQqiOTJQ/gHFyDUgUM5kIFDOvA4G0qBJQ5ClS5fGmjVronv37g3u7969eyxcuHCda5544on4xS9+Eddff32jzznrrLNixYoV9bf58+c3pU2AgmiODJR/QDFyDQiUMxkIlDOvg4E0aFPIzd9777046qij4vrrr4+qqqpGr6usrIzKysoCdgZQeLlkoPwD0sA1IFDOZCBQzrwOBopRk4YgVVVV0bp161i0aFGD+xctWhQ9evRY6/FvvPFGzJ07N0aOHFl/X11d3f8d3KZNzJkzJ7bccstc+gZodjIQKFfyDyhnMhAoZzIQSIMmfRxWu3btYtCgQTFjxoz6++rq6mLGjBlRU1Oz1uMHDBgQf/vb3+L555+vvx144IGx9957x/PPP+8z/oCSIgOBciX/gHImA4FyJgOBNGjyx2GNHz8+xowZE4MHD44hQ4bElClTYuXKlXHMMcdERMTRRx8dvXv3jkmTJkX79u1j++23b7D+c5/7XETEWvcDlAIZCJQr+QeUMxkIlDMZCJS6Jg9BRo8eHUuWLIlzzjknFi5cGDvttFNMnz69/guS5s2bF61aNekNJgAlQwYC5Ur+AeVMBgLlTAYCpa4iSZKkpZtYn9ra2ujcuXOsWLEiOnXq1NLtAFn0m3B/Xvebe/GIRj82jVmRxudUblry9wTlJY15kcbn1FiyAxovrVmR1udF/vizgoh0ZkUan1MxkR2kSWPzwpgWAAAAAABIJUMQAAAAAAAglQxBAAAAAACAVDIEAQAAAAAAUskQBAAAAAAASCVDEAAAAAAAIJUMQQAAAAAAgFQyBAEAAAAAAFLJEAQAAAAAAEglQxAAAAAAACCVDEEAAAAAAIBUMgQBAAAAAABSyRAEAAAAAABIJUMQAAAAAAAglQxBAAAAAACAVDIEAQAAAAAAUskQBAAAAAAASCVDEAAAAAAAIJUMQQAAAAAAgFQyBAEAAAAAAFLJEAQAAAAAAEglQxAAAAAAACCVDEEAAAAAAIBUMgQBAAAAAABSyRAEAAAAAABIJUMQAAAAAAAglQxBAAAAAACAVDIEAQAAAAAAUskQBAAAAAAASCVDEAAAAAAAIJUMQQAAAAAAgFTKaQgyderU6NevX7Rv3z6GDh0aTz/9dMbHXn/99bHnnntGly5dokuXLjFs2LCsjwcodjIQKFfyDyhnMhAoZzIQKGVNHoLceeedMX78+Jg4cWI8++yzMXDgwBg+fHgsXrx4nY9/7LHH4hvf+EY8+uijMXPmzKiuro599903FixYsMHNAzQ3GQiUK/kHlDMZCJQzGQiUuookSZKmLBg6dGjsuuuucdVVV0VERF1dXVRXV8fJJ58cEyZMWO/6NWvWRJcuXeKqq66Ko48+ep2PWbVqVaxatar+59ra2qiuro4VK1ZEp06dmtIu0Mz6Tbg/r/vNvXhEox9bW1sbnTt3LmhWFDoD5V/6tOTvCcpLoTPQNWDzkh3QeGm4BoyQgTSdPyuISEcGyr/mJTtIk8ZmYJPeCbJ69eqYNWtWDBs27D8btGoVw4YNi5kzZzZqjw8++CA++uij2HTTTTM+ZtKkSdG5c+f6W3V1dVPaBCiI5shA+QcUI9eAQDmTgUA58zoYSIMmDUGWLl0aa9asie7duze4v3v37rFw4cJG7XHmmWdGr169GoTnZ5111lmxYsWK+tv8+fOb0iZAQTRHBso/oBi5BgTKmQwEypnXwUAatGnOwy6++OK444474rHHHov27dtnfFxlZWVUVlY2Y2cAhdeYDJR/QBq5BgTKmQwEypnXwUAxaNIQpKqqKlq3bh2LFi1qcP+iRYuiR48eWddeeumlcfHFF8fDDz8cO+64Y9M7BWhhMhAoV/IPKGcyEChnMhBIgyZ9HFa7du1i0KBBMWPGjPr76urqYsaMGVFTU5Nx3SWXXBLnn39+TJ8+PQYPHpx7twAtSAYC5Ur+AeVMBgLlTAYCadDkj8MaP358jBkzJgYPHhxDhgyJKVOmxMqVK+OYY46JiIijjz46evfuHZMmTYqIiJ/85CdxzjnnxO233x79+vWr/7zAjTfeODbeeOM8PhWAwpOBQLmSf0A5k4FAOZOBQKlr8hBk9OjRsWTJkjjnnHNi4cKFsdNOO8X06dPrvyBp3rx50arVf95gcs0118Tq1atj1KhRDfaZOHFinHvuuRvWPUAzk4FAuZJ/QDmTgUA5k4FAqatIkiRp6SbWp7a2Njp37hwrVqyITp06tXQ7QBb9Jtyf1/3mXjyi0Y9NY1ak8TmVm5b8PUF5SWNepPE5NZbsgMZLa1ak9XmRP/6sICKdWZHG51RMZAdp0ti8aNJ3ggAAAAAAAJQKQxAAAAAAACCVDEEAAAAAAIBUMgQBAAAAAABSyRAEAAAAAABIJUMQAAAAAAAglQxBAAAAAACAVDIEAQAAAAAAUskQBAAAAAAASCVDEAAAAAAAIJUMQQAAAAAAgFQyBAEAAAAAAFLJEAQAAAAAAEglQxAAAAAAACCVDEEAAAAAAIBUMgQBAAAAAABSyRAEAAAAAABIJUMQAAAAAAAglQxBAAAAAACAVDIEAQAAAAAAUskQBAAAAAAASCVDEAAAAAAAIJUMQQAAAAAAgFQyBAEAAAAAAFLJEAQAAAAAAEglQxAAAAAAACCVDEEAAAAAAIBUMgQBAAAAAABSyRAEAAAAAABIJUMQAAAAAAAglQxBAAAAAACAVMppCDJ16tTo169ftG/fPoYOHRpPP/101sf/+te/jgEDBkT79u1jhx12iAceeCCnZgGKgQwEypX8A8qZDATKmQwESlmThyB33nlnjB8/PiZOnBjPPvtsDBw4MIYPHx6LFy9e5+OffPLJ+MY3vhHHHntsPPfcc3HwwQfHwQcfHLNnz97g5gGamwwEypX8A8qZDATKmQwESl1FkiRJUxYMHTo0dt1117jqqqsiIqKuri6qq6vj5JNPjgkTJqz1+NGjR8fKlSvjvvvuq79vt912i5122imuvfbadZ6xatWqWLVqVf3PK1asiD59+sT8+fOjU6dOTWkXaGbbT3wwr/vNPm94ox9bW1sb1dXVsXz58ujcuXNe+/hEoTNQ/qVPS/6eoLwUOgNdAzYv2QGNl4ZrwAgZSNP5s4KIdGSg/GtesoM0aXQGJk2watWqpHXr1sk999zT4P6jjz46OfDAA9e5prq6Orn88ssb3HfOOeckO+64Y8ZzJk6cmESEm5ubW063+fPnNyXaGq05MlD+ubm5beitEBnoGtDNza0UbqV8DZgkMtDNzW3DbqWcgfLPzc1tQ2/ry8A20QRLly6NNWvWRPfu3Rvc371793jllVfWuWbhwoXrfPzChQsznnPWWWfF+PHj63+uq6uLZcuWxWabbRYVFRVNaTmrTyZFhZwsF/qMNDwHZxTP/qV+RpIk8d5770WvXr3ytuenNUcGyj9nyA5n5KqQGega0BnyKf1nlPJzSMM1YIQMLKb9nVFcZ6ThORTyjDRkYHPlX4T/XsvpjDQ8B2esX2MzsElDkOZSWVkZlZWVDe773Oc+V7DzOnXqVPC31xX6jDQ8B2cUz/6lfEah3v7bXOSfM2SHMzaEDGyaUv33nMYz0vAc0nJGqT6HUs+/CBlYjPs7o7jOSMNzKNQZpZ6BzZ1/Ef57Lacz0vAcnJFdYzKwSV+MXlVVFa1bt45FixY1uH/RokXRo0ePda7p0aNHkx4PUKxkIFCu5B9QzmQgUM5kIJAGTRqCtGvXLgYNGhQzZsyov6+uri5mzJgRNTU161xTU1PT4PEREQ899FDGxwMUKxkIlCv5B5QzGQiUMxkIpEGTPw5r/PjxMWbMmBg8eHAMGTIkpkyZEitXroxjjjkmIiKOPvro6N27d0yaNCkiIsaNGxd77bVXXHbZZTFixIi444474plnnonrrrsuv88kB5WVlTFx4sS13nJXSmek4Tk4o3j2T9MZhZKWDEzLv2dnFMf+zii+MwohLfkXkZ5/z2k4Iw3PIS1npOE5FJIMLK4z0vAcnFE8+6fpjEKRgcWzvzOKZ39nFN8ZWWX92vQMrrzyyqRPnz5Ju3btkiFDhiRPPfVUfW2vvfZKxowZ0+Dx06ZNSz7/+c8n7dq1S7bbbrvk/vvvz+VYgKIgA4FyJf+AciYDgXImA4FSVpEkSdIy4xcAAAAAAIDCadJ3ggAAAAAAAJQKQxAAAAAAACCVDEEAAAAAAIBUMgQBAAAAAABSqWyHIFOnTo1+/fpF+/btY+jQofH000/ndf8//elPMXLkyOjVq1dUVFTEvffem9f9J02aFLvuumtssskm0a1btzj44INjzpw5eT3jmmuuiR133DE6deoUnTp1ipqamvj973+f1zM+7eKLL46Kioo45ZRT8rbnueeeGxUVFQ1uAwYMyNv+n1iwYEEceeSRsdlmm8VGG20UO+ywQzzzzDN5279fv35rPY+KiooYO3Zs3s5Ys2ZNnH322dG/f//YaKONYsstt4zzzz8/kiTJ2xnvvfdenHLKKdG3b9/YaKONYvfdd4+//vWvedufxitkBhY6/yJkYGPJwMZpjvyLkIHFpJQzMI35F1G6GVjq+RchA8uN18Hr5xqw8WRg48i/4lHK14ARMrCxZGDjlNs1YFkOQe68884YP358TJw4MZ599tkYOHBgDB8+PBYvXpy3M1auXBkDBw6MqVOn5m3PT/vjH/8YY8eOjaeeeioeeuih+Oijj2LfffeNlStX5u2MzTffPC6++OKYNWtWPPPMM/Ff//VfcdBBB8VLL72UtzM+8de//jV+9rOfxY477pj3vbfbbrv45z//WX974okn8rr/u+++G3vssUe0bds2fv/738ff//73uOyyy6JLly55O+Ovf/1rg+fw0EMPRUTEoYcemrczfvKTn8Q111wTV111Vbz88svxk5/8JC655JK48sor83bGcccdFw899FDceuut8be//S323XffGDZsWCxYsCBvZ7B+hc7AQudfhAxsChm4fs2RfxEysFiUegamLf8iSjcD05B/ETKwnHgd3DiuARtHBjae/CsOpX4NGCEDm0IGrl/ZXQMmZWjIkCHJ2LFj639es2ZN0qtXr2TSpEkFOS8iknvuuacge39i8eLFSUQkf/zjHwt6TpcuXZKf//zned3zvffeS7beeuvkoYceSvbaa69k3Lhxedt74sSJycCBA/O237qceeaZyRe/+MWCnvFZ48aNS7bccsukrq4ub3uOGDEi+fa3v93gvq9//evJN7/5zbzs/8EHHyStW7dO7rvvvgb377LLLskPf/jDvJxB4zRnBjZH/iWJDMxEBjZOofMvSWRgMUlbBpZy/iVJaWdgGvIvSWRgOfE6OHeuAdcmAxtH/hWPtF0DJokMzEQGNk65XQOW3TtBVq9eHbNmzYphw4bV39eqVasYNmxYzJw5swU72zArVqyIiIhNN920IPuvWbMm7rjjjli5cmXU1NTkde+xY8fGiBEjGvw7yafXXnstevXqFVtssUV885vfjHnz5uV1/9/97ncxePDgOPTQQ6Nbt26x8847x/XXX5/XMz5t9erV8ctf/jK+/e1vR0VFRd723X333WPGjBnx6quvRkTECy+8EE888UTsv//+edn/448/jjVr1kT79u0b3L/RRhvlfSJPZjIwNzIwszRkYKHzL0IGFos0ZmAp519EaWdgGvIvQgaWizTmX0RpZ2Ap51+EDGws+VccZGBuZGBmacjAsrsGbNaRSxFYsGBBEhHJk08+2eD+H/zgB8mQIUMKcmYUeAK8Zs2aZMSIEckee+yR971ffPHFpGPHjknr1q2Tzp07J/fff39e9//Vr36VbL/99smHH36YJEmS9+nvAw88kEybNi154YUXkunTpyc1NTVJnz59ktra2rydUVlZmVRWViZnnXVW8uyzzyY/+9nPkvbt2yc33XRT3s74tDvvvDNp3bp1smDBgrzuu2bNmuTMM89MKioqkjZt2iQVFRXJRRddlNczampqkr322itZsGBB8vHHHye33npr0qpVq+Tzn/98Xs8hs+bOwELnX5LIwGxkYOM0R/4liQwsBmnLwFLOvyQp/QxMQ/4liQwsF14HN41rwPWTgY0n/1pe2q4Bk0QGZiMDG6fcrgENQf6/Ur74++53v5v07ds3mT9/ft73XrVqVfLaa68lzzzzTDJhwoSkqqoqeemll/Ky97x585Ju3bolL7zwQv19+Q6+z3r33XeTTp065fVtfG3btk1qamoa3HfyyScnu+22W97O+LR99903OeCAA/K+769+9atk8803T371q18lL774YnLLLbckm266aV4D/PXXX0++9KUvJRGRtG7dOtl1112Tb37zm8mAAQPydgbZpfHiTwY2ngxct+bIvySRgcUgbRlYqvmXJOnIwDTkX5LIwHLhdXDTuAZcPxnYePKv5aXtGjBJZGBTyMB1K7drwLIbgqxatSpp3br1WmF09NFHJwceeGBBzixk+I0dOzbZfPPNkzfffLMg+3/WPvvsk5xwwgl52euee+6p/w3wyS0ikoqKiqR169bJxx9/nJdzPmvw4MHJhAkT8rZfnz59kmOPPbbBfVdffXXSq1evvJ3xiblz5yatWrVK7r333rzvvfnmmydXXXVVg/vOP//8ZJtttsn7We+//37yj3/8I0mSJDnssMOSr371q3k/g3Vr7gws9MWfDGw6Gbi25sy/JJGBLSlNGVjK+Zck6cjANORfksjAcuF18IZxDbg2Gdh08q/lpOkaMElkYC5k4NrK7Rqw7L4TpF27djFo0KCYMWNG/X11dXUxY8aMgnzOcaEkSRInnXRS3HPPPfHII49E//79m+Xcurq6WLVqVV722meffeJvf/tbPP/88/W3wYMHxze/+c14/vnno3Xr1nk559Pef//9eOONN6Jnz55523OPPfaIOXPmNLjv1Vdfjb59++btjE/ceOON0a1btxgxYkTe9/7ggw+iVauGkdC6deuoq6vL+1kdO3aMnj17xrvvvhsPPvhgHHTQQXk/g3WTgRtGBq4tDRnYnPkXIQNbUhoyMA35F5GODExD/kXIwHKRhvyLSEcGpiH/ImRgLuRfy5GBG0YGri0NGVh214DNOnIpEnfccUdSWVmZ3HTTTcnf//735IQTTkg+97nPJQsXLszbGe+9917y3HPPJc8991wSEcnkyZOT5557Lnn77bfzsv+JJ56YdO7cOXnssceSf/7zn/W3Dz74IC/7J0mSTJgwIfnjH/+YvPXWW8mLL76YTJgwIamoqEj+8Ic/5O2Mz8r3W+BOO+205LHHHkveeuut5M9//nMybNiwpKqqKlm8eHHeznj66aeTNm3aJBdeeGHy2muvJbfddlvSoUOH5Je//GXezkiS//usvj59+iRnnnlmXvf9xJgxY5LevXsn9913X/LWW28lv/nNb5KqqqrkjDPOyNsZ06dPT37/+98nb775ZvKHP/whGThwYDJ06NBk9erVeTuD9St0BhY6/5JEBjaWDGyc5si/JJGBxaLUMzCt+ZckpZeBaci/JJGB5cTr4MZxDdg4MrDx5F9xKPVrwCSRgY0lAxun3K4By3IIkiRJcuWVVyZ9+vRJ2rVrlwwZMiR56qmn8rr/o48+mkTEWrcxY8bkZf917R0RyY033piX/ZMkSb797W8nffv2Tdq1a5d07do12WeffUruxe/o0aOTnj17Ju3atUt69+6djB49Onn99dfztv8n/vd//zfZfvvtk8rKymTAgAHJddddl/czHnzwwSQikjlz5uR97yRJktra2mTcuHFJnz59kvbt2ydbbLFF8sMf/jBZtWpV3s648847ky222CJp165d0qNHj2Ts2LHJ8uXL87Y/jVfIDCx0/iWJDGwsGdg4zZF/SSIDi0kpZ2Ba8y9JSjMDSz3/kkQGlhuvg9fPNWDjycDGkX/Fo5SvAZNEBjaWDGyccrsGrEiSJNngt5MAAAAAAAAUmbL7ThAAAAAAAKA8GIIAAAAAAACpZAgCAAAAAACkkiEIAAAAAACQSoYgAAAAAABAKhmCAAAAAAAAqWQIAgAAAAAApJIhCAAAAAAAkEqGIAAAAAAAQCoZggAAAAAAAKlkCAIAAAAAAKTS/wN9S66c4gZfvAAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import numpy as np\n",
        "# import matplotlib.pyplot as plt\n",
        "\n",
        "# h = 0.05\n",
        "# x_min, x_max = X[:,0].min() - 1, X[:,0].max() + 1\n",
        "# y_min, y_max = X[:,1].min() - 1, X[:,1].max() + 1\n",
        "\n",
        "# xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n",
        "#                      np.arange(y_min, y_max, h))\n",
        "\n",
        "# grid_points = np.c_[xx.ravel(), yy.ravel()]\n",
        "\n",
        "# preds = predict(grid_points, weights, biases)\n",
        "\n",
        "# Z = (preds > 0.5).astype(int)\n",
        "# Z = Z.reshape(xx.shape)\n",
        "\n",
        "\n",
        "# plt.figure(figsize=(8,6))\n",
        "# plt.contourf(xx, yy, Z, alpha=0.3, cmap=plt.cm.RdBu)\n",
        "\n",
        "# plt.scatter(class0_points[:, 0], class0_points[:, 1], c='blue', label='Class 0 (Inner)', alpha=0.7)\n",
        "# plt.scatter(class1_points[:, 0], class1_points[:, 1], c='red', label='Class 1 (Outer)', alpha=0.7)\n",
        "\n",
        "# plt.title(\"Decision Boundary\")\n",
        "# plt.xlabel(\"Feature 1\")\n",
        "# plt.ylabel(\"Feature 2\")\n",
        "# plt.legend()\n",
        "# plt.grid(True)\n",
        "# plt.gca().set_aspect('equal', adjustable='box')\n",
        "# plt.show()\n"
      ],
      "metadata": {
        "id": "yoUkunx185nD"
      },
      "execution_count": 615,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2BUbd2vyiFKN"
      },
      "execution_count": 615,
      "outputs": []
    }
  ]
}